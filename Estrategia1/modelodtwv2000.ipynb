{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from tslearn.clustering import TimeSeriesKMeans\n",
    "from tslearn.preprocessing import TimeSeriesScalerMinMax\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import Sequential\n",
    "import joblib\n",
    "import warnings\n",
    "import tensorflow as tf\n",
    "from tslearn.preprocessing import TimeSeriesScalerMeanVariance\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module='keras')\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv1D, MaxPooling1D, Flatten, Reshape, Bidirectional, LSTM, Dense, Dropout, Activation\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from tensorflow.keras.callbacks import EarlyStopping  # Importa EarlyStopping desde callbacks\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>periodo</th>\n",
       "      <th>plan_precios_cuidados</th>\n",
       "      <th>cust_request_qty</th>\n",
       "      <th>cust_request_tn</th>\n",
       "      <th>tn</th>\n",
       "      <th>cat1</th>\n",
       "      <th>cat2</th>\n",
       "      <th>cat3</th>\n",
       "      <th>brand</th>\n",
       "      <th>sku_size</th>\n",
       "      <th>descripcion</th>\n",
       "      <th>quarter</th>\n",
       "      <th>month</th>\n",
       "      <th>close_quarter</th>\n",
       "      <th>age</th>\n",
       "      <th>mes_inicial</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10001</td>\n",
       "      <td>20001</td>\n",
       "      <td>201812</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>254.62373</td>\n",
       "      <td>254.62373</td>\n",
       "      <td>HC</td>\n",
       "      <td>ROPA LAVADO</td>\n",
       "      <td>Liquido</td>\n",
       "      <td>ARIEL</td>\n",
       "      <td>3000</td>\n",
       "      <td>genoma</td>\n",
       "      <td>Q4</td>\n",
       "      <td>12</td>\n",
       "      <td>1.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>2018-12-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10001</td>\n",
       "      <td>20001</td>\n",
       "      <td>201901</td>\n",
       "      <td>0.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>393.26092</td>\n",
       "      <td>386.60688</td>\n",
       "      <td>HC</td>\n",
       "      <td>ROPA LAVADO</td>\n",
       "      <td>Liquido</td>\n",
       "      <td>ARIEL</td>\n",
       "      <td>3000</td>\n",
       "      <td>genoma</td>\n",
       "      <td>Q1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>2018-12-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10001</td>\n",
       "      <td>20001</td>\n",
       "      <td>201902</td>\n",
       "      <td>0.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>309.90610</td>\n",
       "      <td>309.90610</td>\n",
       "      <td>HC</td>\n",
       "      <td>ROPA LAVADO</td>\n",
       "      <td>Liquido</td>\n",
       "      <td>ARIEL</td>\n",
       "      <td>3000</td>\n",
       "      <td>genoma</td>\n",
       "      <td>Q1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>2018-12-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10001</td>\n",
       "      <td>20001</td>\n",
       "      <td>201903</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>142.87158</td>\n",
       "      <td>130.54927</td>\n",
       "      <td>HC</td>\n",
       "      <td>ROPA LAVADO</td>\n",
       "      <td>Liquido</td>\n",
       "      <td>ARIEL</td>\n",
       "      <td>3000</td>\n",
       "      <td>genoma</td>\n",
       "      <td>Q1</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>2018-12-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10001</td>\n",
       "      <td>20001</td>\n",
       "      <td>201904</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>364.37071</td>\n",
       "      <td>364.37071</td>\n",
       "      <td>HC</td>\n",
       "      <td>ROPA LAVADO</td>\n",
       "      <td>Liquido</td>\n",
       "      <td>ARIEL</td>\n",
       "      <td>3000</td>\n",
       "      <td>genoma</td>\n",
       "      <td>Q2</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>2018-12-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10001</td>\n",
       "      <td>20001</td>\n",
       "      <td>201905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>439.90647</td>\n",
       "      <td>439.90647</td>\n",
       "      <td>HC</td>\n",
       "      <td>ROPA LAVADO</td>\n",
       "      <td>Liquido</td>\n",
       "      <td>ARIEL</td>\n",
       "      <td>3000</td>\n",
       "      <td>genoma</td>\n",
       "      <td>Q2</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>2018-12-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10001</td>\n",
       "      <td>20001</td>\n",
       "      <td>201906</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>65.92436</td>\n",
       "      <td>65.92436</td>\n",
       "      <td>HC</td>\n",
       "      <td>ROPA LAVADO</td>\n",
       "      <td>Liquido</td>\n",
       "      <td>ARIEL</td>\n",
       "      <td>3000</td>\n",
       "      <td>genoma</td>\n",
       "      <td>Q2</td>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>2018-12-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10001</td>\n",
       "      <td>20001</td>\n",
       "      <td>201907</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>144.78714</td>\n",
       "      <td>144.78714</td>\n",
       "      <td>HC</td>\n",
       "      <td>ROPA LAVADO</td>\n",
       "      <td>Liquido</td>\n",
       "      <td>ARIEL</td>\n",
       "      <td>3000</td>\n",
       "      <td>genoma</td>\n",
       "      <td>Q3</td>\n",
       "      <td>7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>2018-12-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10001</td>\n",
       "      <td>20001</td>\n",
       "      <td>201908</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>33.63991</td>\n",
       "      <td>33.63991</td>\n",
       "      <td>HC</td>\n",
       "      <td>ROPA LAVADO</td>\n",
       "      <td>Liquido</td>\n",
       "      <td>ARIEL</td>\n",
       "      <td>3000</td>\n",
       "      <td>genoma</td>\n",
       "      <td>Q3</td>\n",
       "      <td>8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>2018-12-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10001</td>\n",
       "      <td>20001</td>\n",
       "      <td>201909</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>111.51691</td>\n",
       "      <td>109.05244</td>\n",
       "      <td>HC</td>\n",
       "      <td>ROPA LAVADO</td>\n",
       "      <td>Liquido</td>\n",
       "      <td>ARIEL</td>\n",
       "      <td>3000</td>\n",
       "      <td>genoma</td>\n",
       "      <td>Q3</td>\n",
       "      <td>9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>2018-12-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10001</td>\n",
       "      <td>20001</td>\n",
       "      <td>201910</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>178.49426</td>\n",
       "      <td>176.02980</td>\n",
       "      <td>HC</td>\n",
       "      <td>ROPA LAVADO</td>\n",
       "      <td>Liquido</td>\n",
       "      <td>ARIEL</td>\n",
       "      <td>3000</td>\n",
       "      <td>genoma</td>\n",
       "      <td>Q4</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>2018-12-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>10001</td>\n",
       "      <td>20001</td>\n",
       "      <td>201911</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>240.59870</td>\n",
       "      <td>236.65556</td>\n",
       "      <td>HC</td>\n",
       "      <td>ROPA LAVADO</td>\n",
       "      <td>Liquido</td>\n",
       "      <td>ARIEL</td>\n",
       "      <td>3000</td>\n",
       "      <td>genoma</td>\n",
       "      <td>Q4</td>\n",
       "      <td>11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>2018-12-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    customer_id  product_id  periodo  plan_precios_cuidados  cust_request_qty  \\\n",
       "0         10001       20001   201812                    0.0              20.0   \n",
       "1         10001       20001   201901                    0.0              53.0   \n",
       "2         10001       20001   201902                    0.0              39.0   \n",
       "3         10001       20001   201903                    0.0              23.0   \n",
       "4         10001       20001   201904                    0.0              33.0   \n",
       "5         10001       20001   201905                    0.0              31.0   \n",
       "6         10001       20001   201906                    0.0               7.0   \n",
       "7         10001       20001   201907                    0.0              14.0   \n",
       "8         10001       20001   201908                    0.0               9.0   \n",
       "9         10001       20001   201909                    0.0              18.0   \n",
       "10        10001       20001   201910                    0.0              21.0   \n",
       "11        10001       20001   201911                    0.0              21.0   \n",
       "\n",
       "    cust_request_tn         tn cat1         cat2     cat3  brand  sku_size  \\\n",
       "0         254.62373  254.62373   HC  ROPA LAVADO  Liquido  ARIEL      3000   \n",
       "1         393.26092  386.60688   HC  ROPA LAVADO  Liquido  ARIEL      3000   \n",
       "2         309.90610  309.90610   HC  ROPA LAVADO  Liquido  ARIEL      3000   \n",
       "3         142.87158  130.54927   HC  ROPA LAVADO  Liquido  ARIEL      3000   \n",
       "4         364.37071  364.37071   HC  ROPA LAVADO  Liquido  ARIEL      3000   \n",
       "5         439.90647  439.90647   HC  ROPA LAVADO  Liquido  ARIEL      3000   \n",
       "6          65.92436   65.92436   HC  ROPA LAVADO  Liquido  ARIEL      3000   \n",
       "7         144.78714  144.78714   HC  ROPA LAVADO  Liquido  ARIEL      3000   \n",
       "8          33.63991   33.63991   HC  ROPA LAVADO  Liquido  ARIEL      3000   \n",
       "9         111.51691  109.05244   HC  ROPA LAVADO  Liquido  ARIEL      3000   \n",
       "10        178.49426  176.02980   HC  ROPA LAVADO  Liquido  ARIEL      3000   \n",
       "11        240.59870  236.65556   HC  ROPA LAVADO  Liquido  ARIEL      3000   \n",
       "\n",
       "   descripcion quarter  month  close_quarter   age mes_inicial  \n",
       "0       genoma      Q4     12            1.0  23.0  2018-12-01  \n",
       "1       genoma      Q1      1            0.0  24.0  2018-12-01  \n",
       "2       genoma      Q1      2            0.0  25.0  2018-12-01  \n",
       "3       genoma      Q1      3            1.0  26.0  2018-12-01  \n",
       "4       genoma      Q2      4            0.0  27.0  2018-12-01  \n",
       "5       genoma      Q2      5            0.0  28.0  2018-12-01  \n",
       "6       genoma      Q2      6            1.0  29.0  2018-12-01  \n",
       "7       genoma      Q3      7            0.0  30.0  2018-12-01  \n",
       "8       genoma      Q3      8            0.0  31.0  2018-12-01  \n",
       "9       genoma      Q3      9            1.0  32.0  2018-12-01  \n",
       "10      genoma      Q4     10            0.0  33.0  2018-12-01  \n",
       "11      genoma      Q4     11            0.0  34.0  2018-12-01  "
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cargar y preprocesar los datos\n",
    "file_path = \"C:/Users/Usuario/desktop/vero2/final_dataset_completo_con_ceros.csv\"\n",
    "df = pd.read_csv(file_path, sep='\\t')\n",
    "\n",
    "df = df.drop('Unnamed: 0', axis=1)\n",
    "df.head(12)\n",
    "\n",
    "# filtered_df = df[df['product_id'].between(20001, 20012)]\n",
    "\n",
    "# Opcional: Ver las primeras filas del DataFrame filtrado\n",
    "# print(filtered_df.head())\n",
    "\n",
    "# df=filtered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['customer_id', 'product_id', 'periodo', 'plan_precios_cuidados',\n",
       "       'cust_request_qty', 'cust_request_tn', 'tn', 'cat1', 'cat2', 'cat3',\n",
       "       'brand', 'sku_size', 'descripcion', 'quarter', 'month', 'close_quarter',\n",
       "       'age', 'mes_inicial'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establecer las semillas para numpy, random y tensorflow/keras\n",
    "seed_value = 42\n",
    "np.random.seed(seed_value)\n",
    "random.seed(seed_value)\n",
    "tf.random.set_seed(seed_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reemplazar 082019 por promedio 07 y 09\n",
    "df['periodo'] = df['periodo'].astype(str).str.strip()\n",
    "df_filtered = df[df['periodo'].isin(['201907', '201908', '201909'])]\n",
    "pivoted_sales = df_filtered.pivot_table(index=['product_id', 'customer_id'], columns='periodo', values='tn').reset_index()\n",
    "pivoted_sales = pivoted_sales.reindex(columns=['product_id', 'customer_id', '201907', '201908', '201909'])\n",
    "pivoted_sales['201908'] = pivoted_sales[['201907', '201909']].mean(axis=1)\n",
    "updated_sales = pivoted_sales.melt(id_vars=['product_id', 'customer_id'], value_vars=['201907', '201908', '201909'], var_name='periodo', value_name='tn')\n",
    "df.set_index(['product_id', 'customer_id', 'periodo'], inplace=True)\n",
    "df.update(updated_sales.set_index(['product_id', 'customer_id', 'periodo']))\n",
    "df.reset_index(inplace=True)\n",
    "\n",
    "# Aplicar LabelEncoder a las columnas categóricas\n",
    "categorical_cols = ['cat1', 'cat2', 'cat3', 'brand', 'descripcion']\n",
    "label_encoders = {}\n",
    "for col in categorical_cols:\n",
    "    le = LabelEncoder()\n",
    "    df[col] = le.fit_transform(df[col])\n",
    "    label_encoders[col] = le\n",
    "\n",
    "# Agrupar las ventas por periodo, cat1, cat2, cat3, brand y customer_id\n",
    "df['periodo'] = pd.to_datetime(df['periodo'], format='%Y%m', errors='coerce')\n",
    "grouped_df = df.groupby(['periodo', 'cat1', 'cat2', 'cat3', 'brand', 'customer_id']).agg({'tn': 'sum'}).reset_index()\n",
    "\n",
    "\n",
    "# Paso 2: Calcular los ratios incluyendo customer_id\n",
    "df_diciembre_2019 = df[(df['periodo'].dt.year == 2019) & (df['periodo'].dt.month == 12)]\n",
    "grouped_sales_2019 = df_diciembre_2019.groupby(['cat1', 'cat2', 'cat3', 'brand', 'customer_id', 'product_id'])['tn'].sum().reset_index()\n",
    "group_totals_2019 = df_diciembre_2019.groupby(['cat1', 'cat2', 'cat3', 'brand', 'customer_id'])['tn'].sum().reset_index()\n",
    "ratios_2019 = pd.merge(grouped_sales_2019, group_totals_2019, on=['cat1', 'cat2', 'cat3', 'brand', 'customer_id'], suffixes=('', '_total'))\n",
    "ratios_2019['ratio'] = ratios_2019['tn'] / ratios_2019['tn_total']\n",
    "ratio_dict = ratios_2019.set_index(['cat1', 'cat2', 'cat3', 'brand', 'customer_id', 'product_id'])['ratio'].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['scalers.pkl']"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#pivotear el df\n",
    "pivoted_df = grouped_df.pivot_table(index=['cat1', 'cat2', 'cat3', 'brand', 'customer_id'], columns='periodo', values='tn').fillna(0)\n",
    "\n",
    "# Escalar las series temporales\n",
    "scaler = TimeSeriesScalerMeanVariance(mu=0., std=1.)  # normalizar las series temporales\n",
    "scaled_series = scaler.fit_transform(pivoted_df.values)\n",
    "inertia = []\n",
    "max_clusters = 15\n",
    "\n",
    "# Crear un diccionario para almacenar los scalers\n",
    "scalers = {}\n",
    "scaled_df = grouped_df.copy()\n",
    "\n",
    "# Aplicar StandardScaler a cada columna de interés\n",
    "for col in ['tn']:\n",
    "    scaler = StandardScaler()\n",
    "    scaled_df[col] = scaler.fit_transform(scaled_df[[col]])\n",
    "    scalers[col] = scaler\n",
    "\n",
    "# Guardar los scalers para su uso posterior\n",
    "joblib.dump(scalers, 'scalers.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>periodo</th>\n",
       "      <th>cat1</th>\n",
       "      <th>cat2</th>\n",
       "      <th>cat3</th>\n",
       "      <th>brand</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>tn</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-12-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>22</td>\n",
       "      <td>10001</td>\n",
       "      <td>0.87535</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-12-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>22</td>\n",
       "      <td>10002</td>\n",
       "      <td>0.27780</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-12-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>22</td>\n",
       "      <td>10003</td>\n",
       "      <td>0.27256</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-12-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>22</td>\n",
       "      <td>10004</td>\n",
       "      <td>0.13628</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-12-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>22</td>\n",
       "      <td>10005</td>\n",
       "      <td>0.06290</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>434443</th>\n",
       "      <td>2019-12-01</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>82</td>\n",
       "      <td>32</td>\n",
       "      <td>10363</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>434444</th>\n",
       "      <td>2019-12-01</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>82</td>\n",
       "      <td>32</td>\n",
       "      <td>10367</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>434445</th>\n",
       "      <td>2019-12-01</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>82</td>\n",
       "      <td>32</td>\n",
       "      <td>10482</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>434446</th>\n",
       "      <td>2019-12-01</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>82</td>\n",
       "      <td>32</td>\n",
       "      <td>10513</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>434447</th>\n",
       "      <td>2019-12-01</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>82</td>\n",
       "      <td>32</td>\n",
       "      <td>10552</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>434448 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          periodo  cat1  cat2  cat3  brand  customer_id       tn  cluster\n",
       "0      2018-12-01     0     0     4     22        10001  0.87535        0\n",
       "1      2018-12-01     0     0     4     22        10002  0.27780       11\n",
       "2      2018-12-01     0     0     4     22        10003  0.27256       11\n",
       "3      2018-12-01     0     0     4     22        10004  0.13628        7\n",
       "4      2018-12-01     0     0     4     22        10005  0.06290       12\n",
       "...           ...   ...   ...   ...    ...          ...      ...      ...\n",
       "434443 2019-12-01     3    13    82     32        10363  0.00000        5\n",
       "434444 2019-12-01     3    13    82     32        10367  0.00000       14\n",
       "434445 2019-12-01     3    13    82     32        10482  0.00000        6\n",
       "434446 2019-12-01     3    13    82     32        10513  0.00000        6\n",
       "434447 2019-12-01     3    13    82     32        10552  0.00000       12\n",
       "\n",
       "[434448 rows x 8 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Crear el modelo TimeSeriesKMeans\n",
    "n_clusters = 15\n",
    "model = TimeSeriesKMeans(n_clusters=n_clusters, metric=\"dtw\", random_state=0)\n",
    "\n",
    "# Ajustar el modelo usando las series temporales escaladas\n",
    "model.fit(scaled_series)\n",
    "\n",
    "# Obtener los clusters asignados a cada serie temporal\n",
    "clusters = model.labels_\n",
    "\n",
    "# Añadir los clusters al DataFrame original\n",
    "pivoted_df['cluster'] = clusters\n",
    "\n",
    "# Unir el número de grupo con grouped_df\n",
    "grouped_df = grouped_df.merge(pivoted_df['cluster'], left_on=['cat1', 'cat2', 'cat3', 'brand', 'customer_id'], right_index=True)\n",
    "\n",
    "\n",
    "# Mostrar el DataFrame final con los números de grupo\n",
    "display(grouped_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_df.to_csv(\"C:/Users/Usuario/desktop/vero2/grouped_df.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       cat1  cat2  cat3  brand  customer_id  cluster\n",
      "0         0     0     4     22        10001        0\n",
      "1         0     0     4     22        10002       11\n",
      "2         0     0     4     22        10003       11\n",
      "3         0     0     4     22        10004        7\n",
      "4         0     0     4     22        10005       12\n",
      "...     ...   ...   ...    ...          ...      ...\n",
      "40378     3    13    82     32        10363        5\n",
      "40379     3    13    82     32        10367       14\n",
      "40380     3    13    82     32        10482        6\n",
      "40381     3    13    82     32        10513        6\n",
      "40382     3    13    82     32        10552       12\n",
      "\n",
      "[40383 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "#control\n",
    "# Dropear la columna 'periodo'\n",
    "check = grouped_df.drop(columns=['periodo'])\n",
    "\n",
    "# Agrupar por 'cat1', 'cat2', 'cat3', 'brand', 'customer_id' y obtener el cluster asignado\n",
    "result_df = check.groupby(['cat1', 'cat2', 'cat3', 'brand', 'customer_id']).agg({\n",
    "    'cluster': 'first'\n",
    "}).reset_index()\n",
    "\n",
    "print(result_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [cat1, cat2, cat3, brand, customer_id, cluster]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# Agrupar por 'cat1', 'cat2', 'cat3', 'brand', 'customer_id' y contar clusters únicos\n",
    "cluster_counts = check.groupby(['cat1', 'cat2', 'cat3', 'brand', 'customer_id']).agg({\n",
    "    'cluster': 'nunique'\n",
    "}).reset_index()\n",
    "\n",
    "# Filtrar combinaciones con más de un cluster\n",
    "multiple_clusters = cluster_counts[cluster_counts['cluster'] > 1]\n",
    "\n",
    "# Mostrar combinaciones con más de un cluster\n",
    "print(multiple_clusters)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "hasta aca ok con grouped_df guardado en vero2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista para acumular las filas de resultados\n",
    "resultados_por_producto = []\n",
    "\n",
    "# Elegir un número de pasos de tiempo\n",
    "n_steps = 13  # Ventana de tiempo de 18 meses\n",
    "n_features = 6 # Cambia esto si tienes más características\n",
    "step_ahead= 2\n",
    "\n",
    "def crear_secuencias(datos, n_steps, step_ahead=1):\n",
    "    X, y = [], []\n",
    "    for i in range(len(datos) - n_steps - step_ahead + 1):\n",
    "        end_ix = i + n_steps\n",
    "        out_end_ix = end_ix + step_ahead - 1\n",
    "        seq_x, seq_y = datos[i:end_ix], datos[out_end_ix]\n",
    "        X.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "\n",
    "\n",
    "# Definir la función para construir el modelo\n",
    "def build_model(input_shape):\n",
    "    model = Sequential()\n",
    "    model.add(Bidirectional(LSTM(units=256, return_sequences=True), input_shape=(n_steps, n_features)))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Bidirectional(LSTM(units=128)))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(64))\n",
    "    model.add(Activation('tanh'))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3), loss='mse')\n",
    "    return model\n",
    "\n",
    "# Inicializar EarlyStopping\n",
    "early_stopping = EarlyStopping(monitor='loss', patience=10, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reescalar 'tn' en grouped_df\n",
    "scaler = StandardScaler()\n",
    "grouped_df['tn_scaled'] = scaler.fit_transform(grouped_df[['tn']])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ahora tengo grouped_df con escalado en tn: se agrega columna tn_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>periodo</th>\n",
       "      <th>cat1</th>\n",
       "      <th>cat2</th>\n",
       "      <th>cat3</th>\n",
       "      <th>brand</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>tn</th>\n",
       "      <th>cluster</th>\n",
       "      <th>tn_scaled</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-12-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>22</td>\n",
       "      <td>10001</td>\n",
       "      <td>0.87535</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.003176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-12-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>22</td>\n",
       "      <td>10002</td>\n",
       "      <td>0.27780</td>\n",
       "      <td>11</td>\n",
       "      <td>-0.082939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-12-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>22</td>\n",
       "      <td>10003</td>\n",
       "      <td>0.27256</td>\n",
       "      <td>11</td>\n",
       "      <td>-0.083639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-12-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>22</td>\n",
       "      <td>10004</td>\n",
       "      <td>0.13628</td>\n",
       "      <td>7</td>\n",
       "      <td>-0.101830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-12-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>22</td>\n",
       "      <td>10005</td>\n",
       "      <td>0.06290</td>\n",
       "      <td>12</td>\n",
       "      <td>-0.111625</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     periodo  cat1  cat2  cat3  brand  customer_id       tn  cluster  \\\n",
       "0 2018-12-01     0     0     4     22        10001  0.87535        0   \n",
       "1 2018-12-01     0     0     4     22        10002  0.27780       11   \n",
       "2 2018-12-01     0     0     4     22        10003  0.27256       11   \n",
       "3 2018-12-01     0     0     4     22        10004  0.13628        7   \n",
       "4 2018-12-01     0     0     4     22        10005  0.06290       12   \n",
       "\n",
       "   tn_scaled  \n",
       "0  -0.003176  \n",
       "1  -0.082939  \n",
       "2  -0.083639  \n",
       "3  -0.101830  \n",
       "4  -0.111625  "
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ver de dejar solo la fecha y tn y cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          periodo  tn_scaled  cluster\n",
      "0      2018-12-01  -0.003176        0\n",
      "1      2018-12-01  -0.082939       11\n",
      "2      2018-12-01  -0.083639       11\n",
      "3      2018-12-01  -0.101830        7\n",
      "4      2018-12-01  -0.111625       12\n",
      "...           ...        ...      ...\n",
      "434443 2019-12-01  -0.120021        5\n",
      "434444 2019-12-01  -0.120021       14\n",
      "434445 2019-12-01  -0.120021        6\n",
      "434446 2019-12-01  -0.120021        6\n",
      "434447 2019-12-01  -0.120021       12\n",
      "\n",
      "[434448 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# Seleccionar solo las columnas 'periodo', 'tn' y 'cluster'\n",
    "time_series_df = grouped_df[['periodo', 'tn_scaled', 'cluster']]\n",
    "\n",
    "# Mostrar el resultado\n",
    "print(time_series_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OJO DEJE EPOCHS EN 100!!!!!!!!!!!!!!!!!!!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenando cluster numero: 0\n",
      "Epoch 1/100\n",
      "10/10 - 9s - 948ms/step - loss: 1.4013 - val_loss: 0.5062 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "10/10 - 1s - 133ms/step - loss: 0.8274 - val_loss: 1.6473 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "10/10 - 1s - 103ms/step - loss: 0.7116 - val_loss: 0.9295 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "10/10 - 1s - 91ms/step - loss: 0.7202 - val_loss: 0.9725 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "10/10 - 1s - 87ms/step - loss: 0.7323 - val_loss: 1.4526 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "10/10 - 1s - 101ms/step - loss: 0.7348 - val_loss: 1.0228 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "10/10 - 1s - 87ms/step - loss: 0.6965 - val_loss: 1.3115 - learning_rate: 0.0010\n",
      "Epoch 8/100\n",
      "10/10 - 1s - 89ms/step - loss: 0.7019 - val_loss: 1.0155 - learning_rate: 0.0010\n",
      "Epoch 9/100\n",
      "10/10 - 1s - 86ms/step - loss: 0.6939 - val_loss: 1.5243 - learning_rate: 0.0010\n",
      "Epoch 10/100\n",
      "10/10 - 1s - 79ms/step - loss: 0.7516 - val_loss: 0.8482 - learning_rate: 0.0010\n",
      "Epoch 11/100\n",
      "\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "10/10 - 1s - 77ms/step - loss: 0.7141 - val_loss: 1.4839 - learning_rate: 0.0010\n",
      "Epoch 12/100\n",
      "10/10 - 1s - 94ms/step - loss: 0.7209 - val_loss: 1.3785 - learning_rate: 2.0000e-04\n",
      "Epoch 13/100\n",
      "10/10 - 1s - 75ms/step - loss: 0.6931 - val_loss: 1.0346 - learning_rate: 2.0000e-04\n",
      "Epoch 14/100\n",
      "10/10 - 1s - 76ms/step - loss: 0.6989 - val_loss: 1.0928 - learning_rate: 2.0000e-04\n",
      "Epoch 15/100\n",
      "10/10 - 1s - 73ms/step - loss: 0.6925 - val_loss: 1.2015 - learning_rate: 2.0000e-04\n",
      "Epoch 16/100\n",
      "10/10 - 1s - 73ms/step - loss: 0.6911 - val_loss: 1.2507 - learning_rate: 2.0000e-04\n",
      "Epoch 17/100\n",
      "10/10 - 1s - 75ms/step - loss: 0.6964 - val_loss: 1.1427 - learning_rate: 2.0000e-04\n",
      "Epoch 18/100\n",
      "10/10 - 1s - 73ms/step - loss: 0.6918 - val_loss: 0.9971 - learning_rate: 2.0000e-04\n",
      "Epoch 19/100\n",
      "10/10 - 1s - 74ms/step - loss: 0.6977 - val_loss: 0.9582 - learning_rate: 2.0000e-04\n",
      "Epoch 20/100\n",
      "10/10 - 1s - 73ms/step - loss: 0.6883 - val_loss: 1.1729 - learning_rate: 2.0000e-04\n",
      "Epoch 21/100\n",
      "\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "10/10 - 1s - 80ms/step - loss: 0.6929 - val_loss: 1.1858 - learning_rate: 2.0000e-04\n",
      "Epoch 22/100\n",
      "10/10 - 1s - 82ms/step - loss: 0.7035 - val_loss: 1.2405 - learning_rate: 4.0000e-05\n",
      "Epoch 23/100\n",
      "10/10 - 1s - 75ms/step - loss: 0.6870 - val_loss: 1.1962 - learning_rate: 4.0000e-05\n",
      "Epoch 24/100\n",
      "10/10 - 1s - 73ms/step - loss: 0.6845 - val_loss: 1.1249 - learning_rate: 4.0000e-05\n",
      "Epoch 25/100\n",
      "10/10 - 1s - 75ms/step - loss: 0.7014 - val_loss: 1.0967 - learning_rate: 4.0000e-05\n",
      "Epoch 26/100\n",
      "10/10 - 1s - 80ms/step - loss: 0.6872 - val_loss: 1.1052 - learning_rate: 4.0000e-05\n",
      "Epoch 27/100\n",
      "10/10 - 1s - 75ms/step - loss: 0.6895 - val_loss: 1.1112 - learning_rate: 4.0000e-05\n",
      "Epoch 28/100\n",
      "10/10 - 1s - 73ms/step - loss: 0.6986 - val_loss: 1.1422 - learning_rate: 4.0000e-05\n",
      "Epoch 29/100\n",
      "10/10 - 1s - 75ms/step - loss: 0.6980 - val_loss: 1.1513 - learning_rate: 4.0000e-05\n",
      "Epoch 30/100\n",
      "10/10 - 1s - 73ms/step - loss: 0.6872 - val_loss: 1.1578 - learning_rate: 4.0000e-05\n",
      "Epoch 31/100\n",
      "\n",
      "Epoch 31: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "10/10 - 1s - 74ms/step - loss: 0.6940 - val_loss: 1.1583 - learning_rate: 4.0000e-05\n",
      "Epoch 32/100\n",
      "10/10 - 1s - 74ms/step - loss: 0.6903 - val_loss: 1.1533 - learning_rate: 1.0000e-05\n",
      "Epoch 33/100\n",
      "10/10 - 1s - 73ms/step - loss: 0.6932 - val_loss: 1.1704 - learning_rate: 1.0000e-05\n",
      "Epoch 34/100\n",
      "10/10 - 1s - 74ms/step - loss: 0.6843 - val_loss: 1.1800 - learning_rate: 1.0000e-05\n",
      "Epoch 35/100\n",
      "10/10 - 1s - 73ms/step - loss: 0.6990 - val_loss: 1.1751 - learning_rate: 1.0000e-05\n",
      "Epoch 36/100\n",
      "10/10 - 1s - 74ms/step - loss: 0.6896 - val_loss: 1.1737 - learning_rate: 1.0000e-05\n",
      "Epoch 37/100\n",
      "10/10 - 1s - 76ms/step - loss: 0.6925 - val_loss: 1.1886 - learning_rate: 1.0000e-05\n",
      "Epoch 38/100\n",
      "10/10 - 1s - 72ms/step - loss: 0.6936 - val_loss: 1.1948 - learning_rate: 1.0000e-05\n",
      "Epoch 39/100\n",
      "10/10 - 1s - 73ms/step - loss: 0.6917 - val_loss: 1.1995 - learning_rate: 1.0000e-05\n",
      "Epoch 40/100\n",
      "10/10 - 1s - 74ms/step - loss: 0.6842 - val_loss: 1.1898 - learning_rate: 1.0000e-05\n",
      "Epoch 41/100\n",
      "10/10 - 1s - 74ms/step - loss: 0.6901 - val_loss: 1.1817 - learning_rate: 1.0000e-05\n",
      "Epoch 42/100\n",
      "10/10 - 1s - 76ms/step - loss: 0.6934 - val_loss: 1.1819 - learning_rate: 1.0000e-05\n",
      "Epoch 43/100\n",
      "10/10 - 1s - 73ms/step - loss: 0.6877 - val_loss: 1.1942 - learning_rate: 1.0000e-05\n",
      "Epoch 44/100\n",
      "10/10 - 1s - 78ms/step - loss: 0.6941 - val_loss: 1.2167 - learning_rate: 1.0000e-05\n",
      "Epoch 45/100\n",
      "10/10 - 1s - 74ms/step - loss: 0.6943 - val_loss: 1.2121 - learning_rate: 1.0000e-05\n",
      "Epoch 46/100\n",
      "10/10 - 1s - 73ms/step - loss: 0.6804 - val_loss: 1.2019 - learning_rate: 1.0000e-05\n",
      "Epoch 47/100\n",
      "10/10 - 1s - 76ms/step - loss: 0.7029 - val_loss: 1.1798 - learning_rate: 1.0000e-05\n",
      "Epoch 48/100\n",
      "10/10 - 1s - 74ms/step - loss: 0.6923 - val_loss: 1.1780 - learning_rate: 1.0000e-05\n",
      "Epoch 49/100\n",
      "10/10 - 1s - 73ms/step - loss: 0.6937 - val_loss: 1.1818 - learning_rate: 1.0000e-05\n",
      "Epoch 50/100\n",
      "10/10 - 1s - 78ms/step - loss: 0.6924 - val_loss: 1.1846 - learning_rate: 1.0000e-05\n",
      "Epoch 51/100\n",
      "10/10 - 1s - 73ms/step - loss: 0.6918 - val_loss: 1.1753 - learning_rate: 1.0000e-05\n",
      "Epoch 52/100\n",
      "10/10 - 1s - 77ms/step - loss: 0.6884 - val_loss: 1.1599 - learning_rate: 1.0000e-05\n",
      "Epoch 53/100\n",
      "10/10 - 1s - 75ms/step - loss: 0.6891 - val_loss: 1.1736 - learning_rate: 1.0000e-05\n",
      "Epoch 54/100\n",
      "10/10 - 1s - 73ms/step - loss: 0.6906 - val_loss: 1.1813 - learning_rate: 1.0000e-05\n",
      "Epoch 55/100\n",
      "10/10 - 1s - 84ms/step - loss: 0.7006 - val_loss: 1.1753 - learning_rate: 1.0000e-05\n",
      "Epoch 56/100\n",
      "10/10 - 1s - 78ms/step - loss: 0.6926 - val_loss: 1.1772 - learning_rate: 1.0000e-05\n",
      "Epoch 57/100\n",
      "10/10 - 1s - 73ms/step - loss: 0.6961 - val_loss: 1.1689 - learning_rate: 1.0000e-05\n",
      "Epoch 58/100\n",
      "10/10 - 1s - 73ms/step - loss: 0.6933 - val_loss: 1.1629 - learning_rate: 1.0000e-05\n",
      "Epoch 59/100\n",
      "10/10 - 1s - 78ms/step - loss: 0.6924 - val_loss: 1.1533 - learning_rate: 1.0000e-05\n",
      "Epoch 60/100\n",
      "10/10 - 1s - 76ms/step - loss: 0.6905 - val_loss: 1.1456 - learning_rate: 1.0000e-05\n",
      "Epoch 61/100\n",
      "10/10 - 1s - 83ms/step - loss: 0.6885 - val_loss: 1.1376 - learning_rate: 1.0000e-05\n",
      "Epoch 62/100\n",
      "10/10 - 1s - 74ms/step - loss: 0.6854 - val_loss: 1.1498 - learning_rate: 1.0000e-05\n",
      "Epoch 63/100\n",
      "10/10 - 1s - 74ms/step - loss: 0.6931 - val_loss: 1.1594 - learning_rate: 1.0000e-05\n",
      "Epoch 64/100\n",
      "10/10 - 1s - 75ms/step - loss: 0.6830 - val_loss: 1.1572 - learning_rate: 1.0000e-05\n",
      "Epoch 65/100\n",
      "10/10 - 1s - 73ms/step - loss: 0.6901 - val_loss: 1.1664 - learning_rate: 1.0000e-05\n",
      "Epoch 66/100\n",
      "10/10 - 1s - 75ms/step - loss: 0.6925 - val_loss: 1.1767 - learning_rate: 1.0000e-05\n",
      "Epoch 67/100\n",
      "10/10 - 1s - 72ms/step - loss: 0.6946 - val_loss: 1.1841 - learning_rate: 1.0000e-05\n",
      "Epoch 68/100\n",
      "10/10 - 1s - 72ms/step - loss: 0.6912 - val_loss: 1.1729 - learning_rate: 1.0000e-05\n",
      "Epoch 69/100\n",
      "10/10 - 1s - 73ms/step - loss: 0.6981 - val_loss: 1.1583 - learning_rate: 1.0000e-05\n",
      "Epoch 70/100\n",
      "10/10 - 1s - 73ms/step - loss: 0.7007 - val_loss: 1.1779 - learning_rate: 1.0000e-05\n",
      "Epoch 71/100\n",
      "10/10 - 1s - 73ms/step - loss: 0.6900 - val_loss: 1.1735 - learning_rate: 1.0000e-05\n",
      "Epoch 72/100\n",
      "10/10 - 1s - 73ms/step - loss: 0.6959 - val_loss: 1.1591 - learning_rate: 1.0000e-05\n",
      "Epoch 73/100\n",
      "10/10 - 1s - 76ms/step - loss: 0.6876 - val_loss: 1.1729 - learning_rate: 1.0000e-05\n",
      "Epoch 74/100\n",
      "10/10 - 1s - 74ms/step - loss: 0.6934 - val_loss: 1.1754 - learning_rate: 1.0000e-05\n",
      "Epoch 75/100\n",
      "10/10 - 1s - 74ms/step - loss: 0.6930 - val_loss: 1.1807 - learning_rate: 1.0000e-05\n",
      "Epoch 76/100\n",
      "10/10 - 1s - 73ms/step - loss: 0.6957 - val_loss: 1.1854 - learning_rate: 1.0000e-05\n",
      "Epoch 77/100\n",
      "10/10 - 1s - 74ms/step - loss: 0.6897 - val_loss: 1.1780 - learning_rate: 1.0000e-05\n",
      "Epoch 78/100\n",
      "10/10 - 1s - 73ms/step - loss: 0.6861 - val_loss: 1.1795 - learning_rate: 1.0000e-05\n",
      "Epoch 79/100\n",
      "10/10 - 1s - 73ms/step - loss: 0.6937 - val_loss: 1.1690 - learning_rate: 1.0000e-05\n",
      "Epoch 80/100\n",
      "10/10 - 1s - 75ms/step - loss: 0.7022 - val_loss: 1.1623 - learning_rate: 1.0000e-05\n",
      "Epoch 81/100\n",
      "10/10 - 1s - 73ms/step - loss: 0.6941 - val_loss: 1.1395 - learning_rate: 1.0000e-05\n",
      "Epoch 82/100\n",
      "10/10 - 1s - 74ms/step - loss: 0.6963 - val_loss: 1.1398 - learning_rate: 1.0000e-05\n",
      "Epoch 83/100\n",
      "10/10 - 1s - 74ms/step - loss: 0.6961 - val_loss: 1.1359 - learning_rate: 1.0000e-05\n",
      "Epoch 84/100\n",
      "10/10 - 1s - 73ms/step - loss: 0.6871 - val_loss: 1.1376 - learning_rate: 1.0000e-05\n",
      "Epoch 85/100\n",
      "10/10 - 1s - 72ms/step - loss: 0.6997 - val_loss: 1.1460 - learning_rate: 1.0000e-05\n",
      "Epoch 86/100\n",
      "10/10 - 1s - 74ms/step - loss: 0.6931 - val_loss: 1.1540 - learning_rate: 1.0000e-05\n",
      "Epoch 87/100\n",
      "10/10 - 1s - 78ms/step - loss: 0.6831 - val_loss: 1.1567 - learning_rate: 1.0000e-05\n",
      "Epoch 88/100\n",
      "10/10 - 1s - 86ms/step - loss: 0.6902 - val_loss: 1.1475 - learning_rate: 1.0000e-05\n",
      "Epoch 89/100\n",
      "10/10 - 1s - 76ms/step - loss: 0.6961 - val_loss: 1.1454 - learning_rate: 1.0000e-05\n",
      "Epoch 90/100\n",
      "10/10 - 1s - 73ms/step - loss: 0.6946 - val_loss: 1.1590 - learning_rate: 1.0000e-05\n",
      "Epoch 91/100\n",
      "10/10 - 1s - 73ms/step - loss: 0.6911 - val_loss: 1.1732 - learning_rate: 1.0000e-05\n",
      "Epoch 92/100\n",
      "10/10 - 1s - 74ms/step - loss: 0.6847 - val_loss: 1.1574 - learning_rate: 1.0000e-05\n",
      "Epoch 93/100\n",
      "10/10 - 1s - 73ms/step - loss: 0.6966 - val_loss: 1.1604 - learning_rate: 1.0000e-05\n",
      "Epoch 94/100\n",
      "10/10 - 1s - 75ms/step - loss: 0.6951 - val_loss: 1.1571 - learning_rate: 1.0000e-05\n",
      "Epoch 95/100\n",
      "10/10 - 1s - 72ms/step - loss: 0.6918 - val_loss: 1.1506 - learning_rate: 1.0000e-05\n",
      "Epoch 96/100\n",
      "10/10 - 1s - 73ms/step - loss: 0.6842 - val_loss: 1.1531 - learning_rate: 1.0000e-05\n",
      "Epoch 97/100\n",
      "10/10 - 1s - 73ms/step - loss: 0.7054 - val_loss: 1.1547 - learning_rate: 1.0000e-05\n",
      "Epoch 98/100\n",
      "10/10 - 1s - 73ms/step - loss: 0.6902 - val_loss: 1.1467 - learning_rate: 1.0000e-05\n",
      "Epoch 99/100\n",
      "10/10 - 1s - 76ms/step - loss: 0.6924 - val_loss: 1.1325 - learning_rate: 1.0000e-05\n",
      "Epoch 100/100\n",
      "10/10 - 1s - 85ms/step - loss: 0.6967 - val_loss: 1.1359 - learning_rate: 1.0000e-05\n",
      "Entrenando cluster numero: 1\n",
      "Epoch 1/100\n",
      "22/22 - 11s - 482ms/step - loss: 1.0333 - val_loss: 1.3019 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "22/22 - 2s - 83ms/step - loss: 0.6687 - val_loss: 0.7146 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "22/22 - 2s - 89ms/step - loss: 0.6447 - val_loss: 0.7743 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "22/22 - 2s - 91ms/step - loss: 0.6382 - val_loss: 0.6166 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "22/22 - 2s - 85ms/step - loss: 0.6382 - val_loss: 0.8387 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "22/22 - 2s - 83ms/step - loss: 0.6331 - val_loss: 0.7060 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "22/22 - 2s - 79ms/step - loss: 0.6337 - val_loss: 0.8052 - learning_rate: 0.0010\n",
      "Epoch 8/100\n",
      "22/22 - 2s - 81ms/step - loss: 0.6374 - val_loss: 0.6932 - learning_rate: 0.0010\n",
      "Epoch 9/100\n",
      "22/22 - 2s - 80ms/step - loss: 0.6517 - val_loss: 0.8783 - learning_rate: 0.0010\n",
      "Epoch 10/100\n",
      "22/22 - 2s - 79ms/step - loss: 0.6310 - val_loss: 0.7982 - learning_rate: 0.0010\n",
      "Epoch 11/100\n",
      "22/22 - 2s - 79ms/step - loss: 0.6274 - val_loss: 0.5996 - learning_rate: 0.0010\n",
      "Epoch 12/100\n",
      "22/22 - 2s - 86ms/step - loss: 0.6382 - val_loss: 0.8178 - learning_rate: 0.0010\n",
      "Epoch 13/100\n",
      "22/22 - 2s - 76ms/step - loss: 0.6331 - val_loss: 0.7321 - learning_rate: 0.0010\n",
      "Epoch 14/100\n",
      "22/22 - 2s - 75ms/step - loss: 0.6345 - val_loss: 1.0187 - learning_rate: 0.0010\n",
      "Epoch 15/100\n",
      "22/22 - 2s - 75ms/step - loss: 0.6350 - val_loss: 0.8524 - learning_rate: 0.0010\n",
      "Epoch 16/100\n",
      "22/22 - 2s - 77ms/step - loss: 0.6272 - val_loss: 0.9284 - learning_rate: 0.0010\n",
      "Epoch 17/100\n",
      "22/22 - 2s - 78ms/step - loss: 0.6349 - val_loss: 0.6331 - learning_rate: 0.0010\n",
      "Epoch 18/100\n",
      "22/22 - 2s - 77ms/step - loss: 0.6309 - val_loss: 0.8730 - learning_rate: 0.0010\n",
      "Epoch 19/100\n",
      "22/22 - 2s - 76ms/step - loss: 0.6293 - val_loss: 0.7098 - learning_rate: 0.0010\n",
      "Epoch 20/100\n",
      "22/22 - 2s - 76ms/step - loss: 0.6392 - val_loss: 0.6806 - learning_rate: 0.0010\n",
      "Epoch 21/100\n",
      "\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "22/22 - 2s - 76ms/step - loss: 0.6394 - val_loss: 0.9433 - learning_rate: 0.0010\n",
      "Epoch 22/100\n",
      "22/22 - 2s - 76ms/step - loss: 0.6287 - val_loss: 0.7249 - learning_rate: 2.0000e-04\n",
      "Epoch 23/100\n",
      "22/22 - 2s - 82ms/step - loss: 0.6260 - val_loss: 0.7653 - learning_rate: 2.0000e-04\n",
      "Epoch 24/100\n",
      "22/22 - 2s - 76ms/step - loss: 0.6290 - val_loss: 0.7599 - learning_rate: 2.0000e-04\n",
      "Epoch 25/100\n",
      "22/22 - 2s - 75ms/step - loss: 0.6272 - val_loss: 0.8251 - learning_rate: 2.0000e-04\n",
      "Epoch 26/100\n",
      "22/22 - 2s - 75ms/step - loss: 0.6287 - val_loss: 0.7900 - learning_rate: 2.0000e-04\n",
      "Epoch 27/100\n",
      "22/22 - 2s - 77ms/step - loss: 0.6247 - val_loss: 0.8419 - learning_rate: 2.0000e-04\n",
      "Epoch 28/100\n",
      "22/22 - 2s - 78ms/step - loss: 0.6242 - val_loss: 0.7503 - learning_rate: 2.0000e-04\n",
      "Epoch 29/100\n",
      "22/22 - 2s - 77ms/step - loss: 0.6279 - val_loss: 0.8006 - learning_rate: 2.0000e-04\n",
      "Epoch 30/100\n",
      "22/22 - 2s - 81ms/step - loss: 0.6264 - val_loss: 0.7532 - learning_rate: 2.0000e-04\n",
      "Epoch 31/100\n",
      "\n",
      "Epoch 31: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "22/22 - 2s - 77ms/step - loss: 0.6275 - val_loss: 0.7466 - learning_rate: 2.0000e-04\n",
      "Epoch 32/100\n",
      "22/22 - 2s - 76ms/step - loss: 0.6265 - val_loss: 0.7356 - learning_rate: 4.0000e-05\n",
      "Epoch 33/100\n",
      "22/22 - 2s - 75ms/step - loss: 0.6244 - val_loss: 0.7801 - learning_rate: 4.0000e-05\n",
      "Epoch 34/100\n",
      "22/22 - 2s - 76ms/step - loss: 0.6259 - val_loss: 0.7894 - learning_rate: 4.0000e-05\n",
      "Epoch 35/100\n",
      "22/22 - 2s - 76ms/step - loss: 0.6232 - val_loss: 0.7650 - learning_rate: 4.0000e-05\n",
      "Epoch 36/100\n",
      "22/22 - 2s - 78ms/step - loss: 0.6236 - val_loss: 0.7820 - learning_rate: 4.0000e-05\n",
      "Epoch 37/100\n",
      "22/22 - 2s - 75ms/step - loss: 0.6233 - val_loss: 0.7862 - learning_rate: 4.0000e-05\n",
      "Epoch 38/100\n",
      "22/22 - 2s - 79ms/step - loss: 0.6244 - val_loss: 0.7834 - learning_rate: 4.0000e-05\n",
      "Epoch 39/100\n",
      "22/22 - 2s - 81ms/step - loss: 0.6237 - val_loss: 0.7927 - learning_rate: 4.0000e-05\n",
      "Epoch 40/100\n",
      "22/22 - 2s - 76ms/step - loss: 0.6271 - val_loss: 0.7794 - learning_rate: 4.0000e-05\n",
      "Epoch 41/100\n",
      "\n",
      "Epoch 41: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "22/22 - 2s - 76ms/step - loss: 0.6249 - val_loss: 0.7872 - learning_rate: 4.0000e-05\n",
      "Epoch 42/100\n",
      "22/22 - 2s - 75ms/step - loss: 0.6273 - val_loss: 0.7894 - learning_rate: 1.0000e-05\n",
      "Epoch 43/100\n",
      "22/22 - 2s - 75ms/step - loss: 0.6240 - val_loss: 0.7897 - learning_rate: 1.0000e-05\n",
      "Epoch 44/100\n",
      "22/22 - 2s - 76ms/step - loss: 0.6229 - val_loss: 0.7851 - learning_rate: 1.0000e-05\n",
      "Epoch 45/100\n",
      "22/22 - 2s - 76ms/step - loss: 0.6259 - val_loss: 0.7841 - learning_rate: 1.0000e-05\n",
      "Epoch 46/100\n",
      "22/22 - 2s - 76ms/step - loss: 0.6247 - val_loss: 0.7900 - learning_rate: 1.0000e-05\n",
      "Epoch 47/100\n",
      "22/22 - 2s - 76ms/step - loss: 0.6255 - val_loss: 0.7871 - learning_rate: 1.0000e-05\n",
      "Epoch 48/100\n",
      "22/22 - 2s - 76ms/step - loss: 0.6255 - val_loss: 0.7814 - learning_rate: 1.0000e-05\n",
      "Epoch 49/100\n",
      "22/22 - 2s - 77ms/step - loss: 0.6232 - val_loss: 0.7808 - learning_rate: 1.0000e-05\n",
      "Epoch 50/100\n",
      "22/22 - 2s - 76ms/step - loss: 0.6262 - val_loss: 0.7766 - learning_rate: 1.0000e-05\n",
      "Epoch 51/100\n",
      "22/22 - 2s - 75ms/step - loss: 0.6252 - val_loss: 0.7686 - learning_rate: 1.0000e-05\n",
      "Epoch 52/100\n",
      "22/22 - 2s - 75ms/step - loss: 0.6216 - val_loss: 0.7802 - learning_rate: 1.0000e-05\n",
      "Epoch 53/100\n",
      "22/22 - 2s - 75ms/step - loss: 0.6226 - val_loss: 0.7858 - learning_rate: 1.0000e-05\n",
      "Epoch 54/100\n",
      "22/22 - 2s - 75ms/step - loss: 0.6237 - val_loss: 0.7892 - learning_rate: 1.0000e-05\n",
      "Epoch 55/100\n",
      "22/22 - 2s - 75ms/step - loss: 0.6266 - val_loss: 0.7853 - learning_rate: 1.0000e-05\n",
      "Epoch 56/100\n",
      "22/22 - 2s - 76ms/step - loss: 0.6269 - val_loss: 0.7844 - learning_rate: 1.0000e-05\n",
      "Epoch 57/100\n",
      "22/22 - 2s - 75ms/step - loss: 0.6275 - val_loss: 0.7816 - learning_rate: 1.0000e-05\n",
      "Epoch 58/100\n",
      "22/22 - 2s - 75ms/step - loss: 0.6236 - val_loss: 0.7713 - learning_rate: 1.0000e-05\n",
      "Epoch 59/100\n",
      "22/22 - 2s - 76ms/step - loss: 0.6256 - val_loss: 0.7789 - learning_rate: 1.0000e-05\n",
      "Epoch 60/100\n",
      "22/22 - 2s - 75ms/step - loss: 0.6244 - val_loss: 0.7862 - learning_rate: 1.0000e-05\n",
      "Epoch 61/100\n",
      "22/22 - 2s - 76ms/step - loss: 0.6252 - val_loss: 0.7883 - learning_rate: 1.0000e-05\n",
      "Epoch 62/100\n",
      "22/22 - 2s - 75ms/step - loss: 0.6256 - val_loss: 0.7874 - learning_rate: 1.0000e-05\n",
      "Epoch 63/100\n",
      "22/22 - 2s - 76ms/step - loss: 0.6247 - val_loss: 0.7951 - learning_rate: 1.0000e-05\n",
      "Epoch 64/100\n",
      "22/22 - 2s - 75ms/step - loss: 0.6252 - val_loss: 0.7922 - learning_rate: 1.0000e-05\n",
      "Epoch 65/100\n",
      "22/22 - 2s - 76ms/step - loss: 0.6243 - val_loss: 0.7903 - learning_rate: 1.0000e-05\n",
      "Epoch 66/100\n",
      "22/22 - 2s - 75ms/step - loss: 0.6249 - val_loss: 0.7811 - learning_rate: 1.0000e-05\n",
      "Epoch 67/100\n",
      "22/22 - 2s - 76ms/step - loss: 0.6258 - val_loss: 0.7962 - learning_rate: 1.0000e-05\n",
      "Epoch 68/100\n",
      "22/22 - 2s - 75ms/step - loss: 0.6234 - val_loss: 0.7824 - learning_rate: 1.0000e-05\n",
      "Epoch 69/100\n",
      "22/22 - 2s - 76ms/step - loss: 0.6228 - val_loss: 0.7796 - learning_rate: 1.0000e-05\n",
      "Epoch 70/100\n",
      "22/22 - 2s - 75ms/step - loss: 0.6232 - val_loss: 0.7839 - learning_rate: 1.0000e-05\n",
      "Epoch 71/100\n",
      "22/22 - 2s - 76ms/step - loss: 0.6213 - val_loss: 0.7843 - learning_rate: 1.0000e-05\n",
      "Epoch 72/100\n",
      "22/22 - 2s - 75ms/step - loss: 0.6246 - val_loss: 0.7793 - learning_rate: 1.0000e-05\n",
      "Epoch 73/100\n",
      "22/22 - 2s - 75ms/step - loss: 0.6254 - val_loss: 0.7754 - learning_rate: 1.0000e-05\n",
      "Epoch 74/100\n",
      "22/22 - 2s - 75ms/step - loss: 0.6257 - val_loss: 0.7688 - learning_rate: 1.0000e-05\n",
      "Epoch 75/100\n",
      "22/22 - 2s - 75ms/step - loss: 0.6257 - val_loss: 0.7759 - learning_rate: 1.0000e-05\n",
      "Epoch 76/100\n",
      "22/22 - 2s - 75ms/step - loss: 0.6244 - val_loss: 0.7880 - learning_rate: 1.0000e-05\n",
      "Epoch 77/100\n",
      "22/22 - 2s - 77ms/step - loss: 0.6226 - val_loss: 0.7810 - learning_rate: 1.0000e-05\n",
      "Epoch 78/100\n",
      "22/22 - 2s - 76ms/step - loss: 0.6237 - val_loss: 0.7829 - learning_rate: 1.0000e-05\n",
      "Epoch 79/100\n",
      "22/22 - 2s - 78ms/step - loss: 0.6249 - val_loss: 0.7903 - learning_rate: 1.0000e-05\n",
      "Epoch 80/100\n",
      "22/22 - 2s - 80ms/step - loss: 0.6239 - val_loss: 0.7823 - learning_rate: 1.0000e-05\n",
      "Epoch 81/100\n",
      "22/22 - 2s - 75ms/step - loss: 0.6202 - val_loss: 0.7899 - learning_rate: 1.0000e-05\n",
      "Epoch 82/100\n",
      "22/22 - 2s - 78ms/step - loss: 0.6241 - val_loss: 0.7880 - learning_rate: 1.0000e-05\n",
      "Epoch 83/100\n",
      "22/22 - 2s - 75ms/step - loss: 0.6243 - val_loss: 0.7772 - learning_rate: 1.0000e-05\n",
      "Epoch 84/100\n",
      "22/22 - 2s - 75ms/step - loss: 0.6248 - val_loss: 0.7827 - learning_rate: 1.0000e-05\n",
      "Epoch 85/100\n",
      "22/22 - 2s - 75ms/step - loss: 0.6241 - val_loss: 0.7909 - learning_rate: 1.0000e-05\n",
      "Epoch 86/100\n",
      "22/22 - 2s - 76ms/step - loss: 0.6254 - val_loss: 0.7885 - learning_rate: 1.0000e-05\n",
      "Epoch 87/100\n",
      "22/22 - 2s - 76ms/step - loss: 0.6265 - val_loss: 0.7893 - learning_rate: 1.0000e-05\n",
      "Epoch 88/100\n",
      "22/22 - 2s - 76ms/step - loss: 0.6285 - val_loss: 0.7810 - learning_rate: 1.0000e-05\n",
      "Epoch 89/100\n",
      "22/22 - 2s - 75ms/step - loss: 0.6228 - val_loss: 0.7751 - learning_rate: 1.0000e-05\n",
      "Epoch 90/100\n",
      "22/22 - 2s - 76ms/step - loss: 0.6221 - val_loss: 0.7822 - learning_rate: 1.0000e-05\n",
      "Epoch 91/100\n",
      "22/22 - 2s - 75ms/step - loss: 0.6276 - val_loss: 0.7729 - learning_rate: 1.0000e-05\n",
      "Epoch 92/100\n",
      "22/22 - 2s - 76ms/step - loss: 0.6261 - val_loss: 0.7790 - learning_rate: 1.0000e-05\n",
      "Epoch 93/100\n",
      "22/22 - 2s - 75ms/step - loss: 0.6262 - val_loss: 0.7821 - learning_rate: 1.0000e-05\n",
      "Epoch 94/100\n",
      "22/22 - 2s - 75ms/step - loss: 0.6242 - val_loss: 0.7805 - learning_rate: 1.0000e-05\n",
      "Epoch 95/100\n",
      "22/22 - 2s - 75ms/step - loss: 0.6259 - val_loss: 0.7849 - learning_rate: 1.0000e-05\n",
      "Epoch 96/100\n",
      "22/22 - 2s - 75ms/step - loss: 0.6235 - val_loss: 0.7809 - learning_rate: 1.0000e-05\n",
      "Epoch 97/100\n",
      "22/22 - 2s - 76ms/step - loss: 0.6272 - val_loss: 0.7738 - learning_rate: 1.0000e-05\n",
      "Epoch 98/100\n",
      "22/22 - 2s - 75ms/step - loss: 0.6268 - val_loss: 0.7888 - learning_rate: 1.0000e-05\n",
      "Epoch 99/100\n",
      "22/22 - 2s - 75ms/step - loss: 0.6256 - val_loss: 0.7853 - learning_rate: 1.0000e-05\n",
      "Epoch 100/100\n",
      "22/22 - 2s - 76ms/step - loss: 0.6244 - val_loss: 0.7770 - learning_rate: 1.0000e-05\n",
      "Entrenando cluster numero: 2\n",
      "Epoch 1/100\n",
      "19/19 - 8s - 445ms/step - loss: 0.8668 - val_loss: 0.9004 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "19/19 - 1s - 77ms/step - loss: 0.5688 - val_loss: 0.7368 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "19/19 - 2s - 80ms/step - loss: 0.5679 - val_loss: 0.5798 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "19/19 - 2s - 82ms/step - loss: 0.5606 - val_loss: 0.6459 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "19/19 - 1s - 77ms/step - loss: 0.5510 - val_loss: 0.5252 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "19/19 - 1s - 79ms/step - loss: 0.5537 - val_loss: 0.4827 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "19/19 - 1s - 77ms/step - loss: 0.5536 - val_loss: 0.6824 - learning_rate: 0.0010\n",
      "Epoch 8/100\n",
      "19/19 - 1s - 78ms/step - loss: 0.5528 - val_loss: 0.6825 - learning_rate: 0.0010\n",
      "Epoch 9/100\n",
      "19/19 - 1s - 78ms/step - loss: 0.5468 - val_loss: 0.7221 - learning_rate: 0.0010\n",
      "Epoch 10/100\n",
      "19/19 - 1s - 76ms/step - loss: 0.5470 - val_loss: 0.6627 - learning_rate: 0.0010\n",
      "Epoch 11/100\n",
      "19/19 - 1s - 78ms/step - loss: 0.5534 - val_loss: 0.8635 - learning_rate: 0.0010\n",
      "Epoch 12/100\n",
      "19/19 - 2s - 79ms/step - loss: 0.5571 - val_loss: 0.6789 - learning_rate: 0.0010\n",
      "Epoch 13/100\n",
      "19/19 - 1s - 77ms/step - loss: 0.5552 - val_loss: 0.5228 - learning_rate: 0.0010\n",
      "Epoch 14/100\n",
      "19/19 - 1s - 76ms/step - loss: 0.5458 - val_loss: 0.6721 - learning_rate: 0.0010\n",
      "Epoch 15/100\n",
      "19/19 - 1s - 78ms/step - loss: 0.5518 - val_loss: 0.6857 - learning_rate: 0.0010\n",
      "Epoch 16/100\n",
      "\n",
      "Epoch 16: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "19/19 - 1s - 77ms/step - loss: 0.5487 - val_loss: 0.6048 - learning_rate: 0.0010\n",
      "Epoch 17/100\n",
      "19/19 - 1s - 77ms/step - loss: 0.5487 - val_loss: 0.6624 - learning_rate: 2.0000e-04\n",
      "Epoch 18/100\n",
      "19/19 - 2s - 80ms/step - loss: 0.5444 - val_loss: 0.7093 - learning_rate: 2.0000e-04\n",
      "Epoch 19/100\n",
      "19/19 - 2s - 82ms/step - loss: 0.5472 - val_loss: 0.6541 - learning_rate: 2.0000e-04\n",
      "Epoch 20/100\n",
      "19/19 - 1s - 78ms/step - loss: 0.5463 - val_loss: 0.6479 - learning_rate: 2.0000e-04\n",
      "Epoch 21/100\n",
      "19/19 - 1s - 76ms/step - loss: 0.5450 - val_loss: 0.6644 - learning_rate: 2.0000e-04\n",
      "Epoch 22/100\n",
      "19/19 - 1s - 77ms/step - loss: 0.5417 - val_loss: 0.6233 - learning_rate: 2.0000e-04\n",
      "Epoch 23/100\n",
      "19/19 - 1s - 76ms/step - loss: 0.5452 - val_loss: 0.7100 - learning_rate: 2.0000e-04\n",
      "Epoch 24/100\n",
      "19/19 - 1s - 75ms/step - loss: 0.5483 - val_loss: 0.6992 - learning_rate: 2.0000e-04\n",
      "Epoch 25/100\n",
      "19/19 - 1s - 76ms/step - loss: 0.5431 - val_loss: 0.6278 - learning_rate: 2.0000e-04\n",
      "Epoch 26/100\n",
      "\n",
      "Epoch 26: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "19/19 - 1s - 76ms/step - loss: 0.5467 - val_loss: 0.6879 - learning_rate: 2.0000e-04\n",
      "Epoch 27/100\n",
      "19/19 - 1s - 77ms/step - loss: 0.5473 - val_loss: 0.6625 - learning_rate: 4.0000e-05\n",
      "Epoch 28/100\n",
      "19/19 - 1s - 79ms/step - loss: 0.5401 - val_loss: 0.6423 - learning_rate: 4.0000e-05\n",
      "Epoch 29/100\n",
      "19/19 - 1s - 77ms/step - loss: 0.5429 - val_loss: 0.6571 - learning_rate: 4.0000e-05\n",
      "Epoch 30/100\n",
      "19/19 - 1s - 76ms/step - loss: 0.5444 - val_loss: 0.6517 - learning_rate: 4.0000e-05\n",
      "Epoch 31/100\n",
      "19/19 - 1s - 77ms/step - loss: 0.5414 - val_loss: 0.6646 - learning_rate: 4.0000e-05\n",
      "Epoch 32/100\n",
      "19/19 - 1s - 76ms/step - loss: 0.5431 - val_loss: 0.6460 - learning_rate: 4.0000e-05\n",
      "Epoch 33/100\n",
      "19/19 - 1s - 76ms/step - loss: 0.5446 - val_loss: 0.6560 - learning_rate: 4.0000e-05\n",
      "Epoch 34/100\n",
      "19/19 - 1s - 77ms/step - loss: 0.5417 - val_loss: 0.6558 - learning_rate: 4.0000e-05\n",
      "Epoch 35/100\n",
      "19/19 - 1s - 77ms/step - loss: 0.5429 - val_loss: 0.6568 - learning_rate: 4.0000e-05\n",
      "Epoch 36/100\n",
      "\n",
      "Epoch 36: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "19/19 - 1s - 76ms/step - loss: 0.5438 - val_loss: 0.6649 - learning_rate: 4.0000e-05\n",
      "Epoch 37/100\n",
      "19/19 - 1s - 76ms/step - loss: 0.5458 - val_loss: 0.6595 - learning_rate: 1.0000e-05\n",
      "Epoch 38/100\n",
      "19/19 - 1s - 76ms/step - loss: 0.5434 - val_loss: 0.6622 - learning_rate: 1.0000e-05\n",
      "Epoch 39/100\n",
      "19/19 - 1s - 76ms/step - loss: 0.5423 - val_loss: 0.6629 - learning_rate: 1.0000e-05\n",
      "Epoch 40/100\n",
      "19/19 - 1s - 77ms/step - loss: 0.5434 - val_loss: 0.6594 - learning_rate: 1.0000e-05\n",
      "Epoch 41/100\n",
      "19/19 - 1s - 76ms/step - loss: 0.5432 - val_loss: 0.6606 - learning_rate: 1.0000e-05\n",
      "Epoch 42/100\n",
      "19/19 - 1s - 76ms/step - loss: 0.5442 - val_loss: 0.6568 - learning_rate: 1.0000e-05\n",
      "Epoch 43/100\n",
      "19/19 - 1s - 76ms/step - loss: 0.5439 - val_loss: 0.6581 - learning_rate: 1.0000e-05\n",
      "Epoch 44/100\n",
      "19/19 - 1s - 76ms/step - loss: 0.5462 - val_loss: 0.6575 - learning_rate: 1.0000e-05\n",
      "Epoch 45/100\n",
      "19/19 - 1s - 77ms/step - loss: 0.5418 - val_loss: 0.6560 - learning_rate: 1.0000e-05\n",
      "Epoch 46/100\n",
      "19/19 - 1s - 76ms/step - loss: 0.5438 - val_loss: 0.6552 - learning_rate: 1.0000e-05\n",
      "Epoch 47/100\n",
      "19/19 - 1s - 77ms/step - loss: 0.5412 - val_loss: 0.6597 - learning_rate: 1.0000e-05\n",
      "Epoch 48/100\n",
      "19/19 - 1s - 76ms/step - loss: 0.5423 - val_loss: 0.6481 - learning_rate: 1.0000e-05\n",
      "Epoch 49/100\n",
      "19/19 - 1s - 77ms/step - loss: 0.5441 - val_loss: 0.6517 - learning_rate: 1.0000e-05\n",
      "Epoch 50/100\n",
      "19/19 - 1s - 77ms/step - loss: 0.5450 - val_loss: 0.6557 - learning_rate: 1.0000e-05\n",
      "Epoch 51/100\n",
      "19/19 - 1s - 77ms/step - loss: 0.5445 - val_loss: 0.6629 - learning_rate: 1.0000e-05\n",
      "Epoch 52/100\n",
      "19/19 - 1s - 77ms/step - loss: 0.5409 - val_loss: 0.6590 - learning_rate: 1.0000e-05\n",
      "Epoch 53/100\n",
      "19/19 - 1s - 76ms/step - loss: 0.5435 - val_loss: 0.6576 - learning_rate: 1.0000e-05\n",
      "Epoch 54/100\n",
      "19/19 - 1s - 76ms/step - loss: 0.5454 - val_loss: 0.6483 - learning_rate: 1.0000e-05\n",
      "Epoch 55/100\n",
      "19/19 - 1s - 77ms/step - loss: 0.5413 - val_loss: 0.6517 - learning_rate: 1.0000e-05\n",
      "Epoch 56/100\n",
      "19/19 - 1s - 77ms/step - loss: 0.5455 - val_loss: 0.6576 - learning_rate: 1.0000e-05\n",
      "Epoch 57/100\n",
      "19/19 - 1s - 77ms/step - loss: 0.5418 - val_loss: 0.6627 - learning_rate: 1.0000e-05\n",
      "Epoch 58/100\n",
      "19/19 - 1s - 77ms/step - loss: 0.5443 - val_loss: 0.6593 - learning_rate: 1.0000e-05\n",
      "Epoch 59/100\n",
      "19/19 - 2s - 80ms/step - loss: 0.5442 - val_loss: 0.6572 - learning_rate: 1.0000e-05\n",
      "Epoch 60/100\n",
      "19/19 - 2s - 82ms/step - loss: 0.5431 - val_loss: 0.6589 - learning_rate: 1.0000e-05\n",
      "Epoch 61/100\n",
      "19/19 - 1s - 76ms/step - loss: 0.5426 - val_loss: 0.6618 - learning_rate: 1.0000e-05\n",
      "Epoch 62/100\n",
      "19/19 - 1s - 77ms/step - loss: 0.5458 - val_loss: 0.6585 - learning_rate: 1.0000e-05\n",
      "Epoch 63/100\n",
      "19/19 - 1s - 77ms/step - loss: 0.5435 - val_loss: 0.6595 - learning_rate: 1.0000e-05\n",
      "Epoch 64/100\n",
      "19/19 - 1s - 77ms/step - loss: 0.5460 - val_loss: 0.6630 - learning_rate: 1.0000e-05\n",
      "Epoch 65/100\n",
      "19/19 - 1s - 78ms/step - loss: 0.5469 - val_loss: 0.6575 - learning_rate: 1.0000e-05\n",
      "Epoch 66/100\n",
      "19/19 - 1s - 78ms/step - loss: 0.5415 - val_loss: 0.6643 - learning_rate: 1.0000e-05\n",
      "Epoch 67/100\n",
      "19/19 - 1s - 77ms/step - loss: 0.5440 - val_loss: 0.6572 - learning_rate: 1.0000e-05\n",
      "Epoch 68/100\n",
      "19/19 - 1s - 76ms/step - loss: 0.5450 - val_loss: 0.6590 - learning_rate: 1.0000e-05\n",
      "Epoch 69/100\n",
      "19/19 - 1s - 78ms/step - loss: 0.5421 - val_loss: 0.6548 - learning_rate: 1.0000e-05\n",
      "Epoch 70/100\n",
      "19/19 - 1s - 77ms/step - loss: 0.5453 - val_loss: 0.6568 - learning_rate: 1.0000e-05\n",
      "Epoch 71/100\n",
      "19/19 - 1s - 76ms/step - loss: 0.5401 - val_loss: 0.6600 - learning_rate: 1.0000e-05\n",
      "Epoch 72/100\n",
      "19/19 - 1s - 77ms/step - loss: 0.5422 - val_loss: 0.6594 - learning_rate: 1.0000e-05\n",
      "Epoch 73/100\n",
      "19/19 - 1s - 77ms/step - loss: 0.5412 - val_loss: 0.6570 - learning_rate: 1.0000e-05\n",
      "Epoch 74/100\n",
      "19/19 - 1s - 77ms/step - loss: 0.5417 - val_loss: 0.6666 - learning_rate: 1.0000e-05\n",
      "Epoch 75/100\n",
      "19/19 - 1s - 76ms/step - loss: 0.5425 - val_loss: 0.6569 - learning_rate: 1.0000e-05\n",
      "Epoch 76/100\n",
      "19/19 - 1s - 77ms/step - loss: 0.5419 - val_loss: 0.6562 - learning_rate: 1.0000e-05\n",
      "Epoch 77/100\n",
      "19/19 - 1s - 76ms/step - loss: 0.5449 - val_loss: 0.6525 - learning_rate: 1.0000e-05\n",
      "Epoch 78/100\n",
      "19/19 - 1s - 78ms/step - loss: 0.5458 - val_loss: 0.6564 - learning_rate: 1.0000e-05\n",
      "Epoch 79/100\n",
      "19/19 - 1s - 76ms/step - loss: 0.5416 - val_loss: 0.6644 - learning_rate: 1.0000e-05\n",
      "Epoch 80/100\n",
      "19/19 - 1s - 76ms/step - loss: 0.5395 - val_loss: 0.6584 - learning_rate: 1.0000e-05\n",
      "Epoch 81/100\n",
      "19/19 - 1s - 76ms/step - loss: 0.5430 - val_loss: 0.6604 - learning_rate: 1.0000e-05\n",
      "Epoch 82/100\n",
      "19/19 - 1s - 76ms/step - loss: 0.5433 - val_loss: 0.6606 - learning_rate: 1.0000e-05\n",
      "Epoch 83/100\n",
      "19/19 - 1s - 76ms/step - loss: 0.5455 - val_loss: 0.6642 - learning_rate: 1.0000e-05\n",
      "Epoch 84/100\n",
      "19/19 - 1s - 77ms/step - loss: 0.5433 - val_loss: 0.6522 - learning_rate: 1.0000e-05\n",
      "Epoch 85/100\n",
      "19/19 - 1s - 76ms/step - loss: 0.5428 - val_loss: 0.6534 - learning_rate: 1.0000e-05\n",
      "Epoch 86/100\n",
      "19/19 - 1s - 76ms/step - loss: 0.5452 - val_loss: 0.6524 - learning_rate: 1.0000e-05\n",
      "Epoch 87/100\n",
      "19/19 - 1s - 77ms/step - loss: 0.5450 - val_loss: 0.6589 - learning_rate: 1.0000e-05\n",
      "Epoch 88/100\n",
      "19/19 - 1s - 78ms/step - loss: 0.5438 - val_loss: 0.6587 - learning_rate: 1.0000e-05\n",
      "Epoch 89/100\n",
      "19/19 - 1s - 75ms/step - loss: 0.5432 - val_loss: 0.6542 - learning_rate: 1.0000e-05\n",
      "Epoch 90/100\n",
      "19/19 - 1s - 76ms/step - loss: 0.5447 - val_loss: 0.6559 - learning_rate: 1.0000e-05\n",
      "Epoch 91/100\n",
      "19/19 - 1s - 76ms/step - loss: 0.5443 - val_loss: 0.6532 - learning_rate: 1.0000e-05\n",
      "Epoch 92/100\n",
      "19/19 - 1s - 76ms/step - loss: 0.5449 - val_loss: 0.6528 - learning_rate: 1.0000e-05\n",
      "Epoch 93/100\n",
      "19/19 - 1s - 76ms/step - loss: 0.5436 - val_loss: 0.6534 - learning_rate: 1.0000e-05\n",
      "Epoch 94/100\n",
      "19/19 - 2s - 80ms/step - loss: 0.5465 - val_loss: 0.6519 - learning_rate: 1.0000e-05\n",
      "Epoch 95/100\n",
      "19/19 - 2s - 80ms/step - loss: 0.5424 - val_loss: 0.6631 - learning_rate: 1.0000e-05\n",
      "Epoch 96/100\n",
      "19/19 - 1s - 79ms/step - loss: 0.5428 - val_loss: 0.6602 - learning_rate: 1.0000e-05\n",
      "Epoch 97/100\n",
      "19/19 - 1s - 77ms/step - loss: 0.5429 - val_loss: 0.6609 - learning_rate: 1.0000e-05\n",
      "Epoch 98/100\n",
      "19/19 - 1s - 77ms/step - loss: 0.5433 - val_loss: 0.6564 - learning_rate: 1.0000e-05\n",
      "Epoch 99/100\n",
      "19/19 - 1s - 76ms/step - loss: 0.5422 - val_loss: 0.6578 - learning_rate: 1.0000e-05\n",
      "Epoch 100/100\n",
      "19/19 - 1s - 76ms/step - loss: 0.5423 - val_loss: 0.6583 - learning_rate: 1.0000e-05\n",
      "Entrenando cluster numero: 3\n",
      "Epoch 1/100\n",
      "19/19 - 9s - 473ms/step - loss: 1.0956 - val_loss: 1.5117 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "19/19 - 2s - 90ms/step - loss: 0.6234 - val_loss: 1.1670 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "19/19 - 2s - 94ms/step - loss: 0.6101 - val_loss: 0.8156 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "19/19 - 2s - 87ms/step - loss: 0.6155 - val_loss: 1.0392 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "19/19 - 2s - 90ms/step - loss: 0.6084 - val_loss: 1.2218 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "19/19 - 2s - 92ms/step - loss: 0.5982 - val_loss: 0.8898 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "19/19 - 2s - 86ms/step - loss: 0.5959 - val_loss: 0.7980 - learning_rate: 0.0010\n",
      "Epoch 8/100\n",
      "19/19 - 2s - 88ms/step - loss: 0.5916 - val_loss: 1.2781 - learning_rate: 0.0010\n",
      "Epoch 9/100\n",
      "19/19 - 2s - 87ms/step - loss: 0.5984 - val_loss: 0.8325 - learning_rate: 0.0010\n",
      "Epoch 10/100\n",
      "19/19 - 2s - 90ms/step - loss: 0.5976 - val_loss: 0.8687 - learning_rate: 0.0010\n",
      "Epoch 11/100\n",
      "19/19 - 2s - 86ms/step - loss: 0.5942 - val_loss: 1.1534 - learning_rate: 0.0010\n",
      "Epoch 12/100\n",
      "19/19 - 2s - 88ms/step - loss: 0.5890 - val_loss: 1.2708 - learning_rate: 0.0010\n",
      "Epoch 13/100\n",
      "19/19 - 2s - 87ms/step - loss: 0.5857 - val_loss: 1.1280 - learning_rate: 0.0010\n",
      "Epoch 14/100\n",
      "19/19 - 2s - 86ms/step - loss: 0.5881 - val_loss: 1.1333 - learning_rate: 0.0010\n",
      "Epoch 15/100\n",
      "19/19 - 2s - 87ms/step - loss: 0.5917 - val_loss: 1.1209 - learning_rate: 0.0010\n",
      "Epoch 16/100\n",
      "19/19 - 2s - 87ms/step - loss: 0.5897 - val_loss: 1.1761 - learning_rate: 0.0010\n",
      "Epoch 17/100\n",
      "\n",
      "Epoch 17: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "19/19 - 2s - 86ms/step - loss: 0.5924 - val_loss: 1.0002 - learning_rate: 0.0010\n",
      "Epoch 18/100\n",
      "19/19 - 2s - 86ms/step - loss: 0.5840 - val_loss: 1.1330 - learning_rate: 2.0000e-04\n",
      "Epoch 19/100\n",
      "19/19 - 2s - 87ms/step - loss: 0.5862 - val_loss: 1.0930 - learning_rate: 2.0000e-04\n",
      "Epoch 20/100\n",
      "19/19 - 2s - 89ms/step - loss: 0.5879 - val_loss: 1.0709 - learning_rate: 2.0000e-04\n",
      "Epoch 21/100\n",
      "19/19 - 2s - 87ms/step - loss: 0.5832 - val_loss: 1.0988 - learning_rate: 2.0000e-04\n",
      "Epoch 22/100\n",
      "19/19 - 2s - 86ms/step - loss: 0.5841 - val_loss: 1.0653 - learning_rate: 2.0000e-04\n",
      "Epoch 23/100\n",
      "19/19 - 2s - 87ms/step - loss: 0.5838 - val_loss: 1.0204 - learning_rate: 2.0000e-04\n",
      "Epoch 24/100\n",
      "19/19 - 2s - 90ms/step - loss: 0.5860 - val_loss: 1.0997 - learning_rate: 2.0000e-04\n",
      "Epoch 25/100\n",
      "19/19 - 2s - 86ms/step - loss: 0.5870 - val_loss: 1.0287 - learning_rate: 2.0000e-04\n",
      "Epoch 26/100\n",
      "19/19 - 2s - 86ms/step - loss: 0.5841 - val_loss: 1.1255 - learning_rate: 2.0000e-04\n",
      "Epoch 27/100\n",
      "\n",
      "Epoch 27: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "19/19 - 2s - 91ms/step - loss: 0.5862 - val_loss: 1.0747 - learning_rate: 2.0000e-04\n",
      "Epoch 28/100\n",
      "19/19 - 2s - 92ms/step - loss: 0.5849 - val_loss: 1.1096 - learning_rate: 4.0000e-05\n",
      "Epoch 29/100\n",
      "19/19 - 2s - 87ms/step - loss: 0.5874 - val_loss: 1.0690 - learning_rate: 4.0000e-05\n",
      "Epoch 30/100\n",
      "19/19 - 2s - 87ms/step - loss: 0.5809 - val_loss: 1.0971 - learning_rate: 4.0000e-05\n",
      "Epoch 31/100\n",
      "19/19 - 2s - 90ms/step - loss: 0.5812 - val_loss: 1.1051 - learning_rate: 4.0000e-05\n",
      "Epoch 32/100\n",
      "19/19 - 2s - 86ms/step - loss: 0.5822 - val_loss: 1.1027 - learning_rate: 4.0000e-05\n",
      "Epoch 33/100\n",
      "19/19 - 2s - 91ms/step - loss: 0.5827 - val_loss: 1.0774 - learning_rate: 4.0000e-05\n",
      "Epoch 34/100\n",
      "19/19 - 2s - 87ms/step - loss: 0.5835 - val_loss: 1.0895 - learning_rate: 4.0000e-05\n",
      "Epoch 35/100\n",
      "19/19 - 2s - 86ms/step - loss: 0.5838 - val_loss: 1.1109 - learning_rate: 4.0000e-05\n",
      "Epoch 36/100\n",
      "19/19 - 2s - 86ms/step - loss: 0.5848 - val_loss: 1.0970 - learning_rate: 4.0000e-05\n",
      "Epoch 37/100\n",
      "\n",
      "Epoch 37: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "19/19 - 2s - 87ms/step - loss: 0.5855 - val_loss: 1.1102 - learning_rate: 4.0000e-05\n",
      "Epoch 38/100\n",
      "19/19 - 2s - 88ms/step - loss: 0.5834 - val_loss: 1.0981 - learning_rate: 1.0000e-05\n",
      "Epoch 39/100\n",
      "19/19 - 2s - 87ms/step - loss: 0.5848 - val_loss: 1.0926 - learning_rate: 1.0000e-05\n",
      "Epoch 40/100\n",
      "19/19 - 2s - 87ms/step - loss: 0.5855 - val_loss: 1.0903 - learning_rate: 1.0000e-05\n",
      "Epoch 41/100\n",
      "19/19 - 2s - 87ms/step - loss: 0.5816 - val_loss: 1.0909 - learning_rate: 1.0000e-05\n",
      "Epoch 42/100\n",
      "19/19 - 2s - 88ms/step - loss: 0.5845 - val_loss: 1.0918 - learning_rate: 1.0000e-05\n",
      "Epoch 43/100\n",
      "19/19 - 2s - 88ms/step - loss: 0.5835 - val_loss: 1.0895 - learning_rate: 1.0000e-05\n",
      "Epoch 44/100\n",
      "19/19 - 2s - 87ms/step - loss: 0.5895 - val_loss: 1.0957 - learning_rate: 1.0000e-05\n",
      "Epoch 45/100\n",
      "19/19 - 2s - 87ms/step - loss: 0.5816 - val_loss: 1.0946 - learning_rate: 1.0000e-05\n",
      "Epoch 46/100\n",
      "19/19 - 2s - 87ms/step - loss: 0.5845 - val_loss: 1.0892 - learning_rate: 1.0000e-05\n",
      "Epoch 47/100\n",
      "19/19 - 2s - 87ms/step - loss: 0.5829 - val_loss: 1.0854 - learning_rate: 1.0000e-05\n",
      "Epoch 48/100\n",
      "19/19 - 2s - 87ms/step - loss: 0.5839 - val_loss: 1.0970 - learning_rate: 1.0000e-05\n",
      "Epoch 49/100\n",
      "19/19 - 2s - 88ms/step - loss: 0.5886 - val_loss: 1.0903 - learning_rate: 1.0000e-05\n",
      "Epoch 50/100\n",
      "19/19 - 2s - 87ms/step - loss: 0.5888 - val_loss: 1.0939 - learning_rate: 1.0000e-05\n",
      "Epoch 51/100\n",
      "19/19 - 2s - 87ms/step - loss: 0.5820 - val_loss: 1.0958 - learning_rate: 1.0000e-05\n",
      "Epoch 52/100\n",
      "19/19 - 2s - 95ms/step - loss: 0.5861 - val_loss: 1.0946 - learning_rate: 1.0000e-05\n",
      "Epoch 53/100\n",
      "19/19 - 2s - 94ms/step - loss: 0.5838 - val_loss: 1.0944 - learning_rate: 1.0000e-05\n",
      "Epoch 54/100\n",
      "19/19 - 2s - 92ms/step - loss: 0.5832 - val_loss: 1.0880 - learning_rate: 1.0000e-05\n",
      "Epoch 55/100\n",
      "19/19 - 2s - 106ms/step - loss: 0.5817 - val_loss: 1.0897 - learning_rate: 1.0000e-05\n",
      "Epoch 56/100\n",
      "19/19 - 2s - 91ms/step - loss: 0.5840 - val_loss: 1.0965 - learning_rate: 1.0000e-05\n",
      "Epoch 57/100\n",
      "19/19 - 2s - 91ms/step - loss: 0.5852 - val_loss: 1.0874 - learning_rate: 1.0000e-05\n",
      "Epoch 58/100\n",
      "19/19 - 2s - 91ms/step - loss: 0.5850 - val_loss: 1.0949 - learning_rate: 1.0000e-05\n",
      "Epoch 59/100\n",
      "19/19 - 2s - 88ms/step - loss: 0.5810 - val_loss: 1.0902 - learning_rate: 1.0000e-05\n",
      "Epoch 60/100\n",
      "19/19 - 2s - 89ms/step - loss: 0.5846 - val_loss: 1.0903 - learning_rate: 1.0000e-05\n",
      "Epoch 61/100\n",
      "19/19 - 2s - 93ms/step - loss: 0.5847 - val_loss: 1.0917 - learning_rate: 1.0000e-05\n",
      "Epoch 62/100\n",
      "19/19 - 2s - 95ms/step - loss: 0.5838 - val_loss: 1.0842 - learning_rate: 1.0000e-05\n",
      "Epoch 63/100\n",
      "19/19 - 2s - 91ms/step - loss: 0.5846 - val_loss: 1.0993 - learning_rate: 1.0000e-05\n",
      "Epoch 64/100\n",
      "19/19 - 2s - 131ms/step - loss: 0.5827 - val_loss: 1.0953 - learning_rate: 1.0000e-05\n",
      "Epoch 65/100\n",
      "19/19 - 2s - 91ms/step - loss: 0.5826 - val_loss: 1.0917 - learning_rate: 1.0000e-05\n",
      "Epoch 66/100\n",
      "19/19 - 2s - 86ms/step - loss: 0.5858 - val_loss: 1.0924 - learning_rate: 1.0000e-05\n",
      "Epoch 67/100\n",
      "19/19 - 2s - 87ms/step - loss: 0.5831 - val_loss: 1.0852 - learning_rate: 1.0000e-05\n",
      "Epoch 68/100\n",
      "19/19 - 2s - 86ms/step - loss: 0.5864 - val_loss: 1.0955 - learning_rate: 1.0000e-05\n",
      "Epoch 69/100\n",
      "19/19 - 2s - 87ms/step - loss: 0.5849 - val_loss: 1.0979 - learning_rate: 1.0000e-05\n",
      "Epoch 70/100\n",
      "19/19 - 2s - 86ms/step - loss: 0.5855 - val_loss: 1.0921 - learning_rate: 1.0000e-05\n",
      "Epoch 71/100\n",
      "19/19 - 2s - 86ms/step - loss: 0.5852 - val_loss: 1.0874 - learning_rate: 1.0000e-05\n",
      "Epoch 72/100\n",
      "19/19 - 2s - 86ms/step - loss: 0.5832 - val_loss: 1.0895 - learning_rate: 1.0000e-05\n",
      "Epoch 73/100\n",
      "19/19 - 2s - 86ms/step - loss: 0.5868 - val_loss: 1.0910 - learning_rate: 1.0000e-05\n",
      "Epoch 74/100\n",
      "19/19 - 2s - 87ms/step - loss: 0.5857 - val_loss: 1.1004 - learning_rate: 1.0000e-05\n",
      "Epoch 75/100\n",
      "19/19 - 2s - 87ms/step - loss: 0.5870 - val_loss: 1.0961 - learning_rate: 1.0000e-05\n",
      "Epoch 76/100\n",
      "19/19 - 2s - 86ms/step - loss: 0.5839 - val_loss: 1.0830 - learning_rate: 1.0000e-05\n",
      "Epoch 77/100\n",
      "19/19 - 2s - 86ms/step - loss: 0.5836 - val_loss: 1.0931 - learning_rate: 1.0000e-05\n",
      "Epoch 78/100\n",
      "19/19 - 2s - 87ms/step - loss: 0.5805 - val_loss: 1.0855 - learning_rate: 1.0000e-05\n",
      "Epoch 79/100\n",
      "19/19 - 2s - 87ms/step - loss: 0.5837 - val_loss: 1.0931 - learning_rate: 1.0000e-05\n",
      "Epoch 80/100\n",
      "19/19 - 2s - 86ms/step - loss: 0.5844 - val_loss: 1.1047 - learning_rate: 1.0000e-05\n",
      "Epoch 81/100\n",
      "19/19 - 2s - 87ms/step - loss: 0.5838 - val_loss: 1.0977 - learning_rate: 1.0000e-05\n",
      "Epoch 82/100\n",
      "19/19 - 2s - 86ms/step - loss: 0.5797 - val_loss: 1.0993 - learning_rate: 1.0000e-05\n",
      "Epoch 83/100\n",
      "19/19 - 2s - 87ms/step - loss: 0.5834 - val_loss: 1.0883 - learning_rate: 1.0000e-05\n",
      "Epoch 84/100\n",
      "19/19 - 2s - 86ms/step - loss: 0.5828 - val_loss: 1.0975 - learning_rate: 1.0000e-05\n",
      "Epoch 85/100\n",
      "19/19 - 2s - 86ms/step - loss: 0.5835 - val_loss: 1.0888 - learning_rate: 1.0000e-05\n",
      "Epoch 86/100\n",
      "19/19 - 2s - 86ms/step - loss: 0.5840 - val_loss: 1.0922 - learning_rate: 1.0000e-05\n",
      "Epoch 87/100\n",
      "19/19 - 2s - 86ms/step - loss: 0.5852 - val_loss: 1.1023 - learning_rate: 1.0000e-05\n",
      "Epoch 88/100\n",
      "19/19 - 2s - 87ms/step - loss: 0.5855 - val_loss: 1.0872 - learning_rate: 1.0000e-05\n",
      "Epoch 89/100\n",
      "19/19 - 2s - 86ms/step - loss: 0.5832 - val_loss: 1.0950 - learning_rate: 1.0000e-05\n",
      "Epoch 90/100\n",
      "19/19 - 2s - 86ms/step - loss: 0.5832 - val_loss: 1.0918 - learning_rate: 1.0000e-05\n",
      "Epoch 91/100\n",
      "19/19 - 2s - 86ms/step - loss: 0.5853 - val_loss: 1.0897 - learning_rate: 1.0000e-05\n",
      "Epoch 92/100\n",
      "19/19 - 2s - 86ms/step - loss: 0.5823 - val_loss: 1.0931 - learning_rate: 1.0000e-05\n",
      "Epoch 93/100\n",
      "19/19 - 2s - 88ms/step - loss: 0.5837 - val_loss: 1.0931 - learning_rate: 1.0000e-05\n",
      "Epoch 94/100\n",
      "19/19 - 2s - 86ms/step - loss: 0.5848 - val_loss: 1.0980 - learning_rate: 1.0000e-05\n",
      "Epoch 95/100\n",
      "19/19 - 2s - 88ms/step - loss: 0.5832 - val_loss: 1.0983 - learning_rate: 1.0000e-05\n",
      "Epoch 96/100\n",
      "19/19 - 2s - 86ms/step - loss: 0.5817 - val_loss: 1.1007 - learning_rate: 1.0000e-05\n",
      "Epoch 97/100\n",
      "19/19 - 2s - 86ms/step - loss: 0.5799 - val_loss: 1.0895 - learning_rate: 1.0000e-05\n",
      "Epoch 98/100\n",
      "19/19 - 2s - 88ms/step - loss: 0.5829 - val_loss: 1.0930 - learning_rate: 1.0000e-05\n",
      "Epoch 99/100\n",
      "19/19 - 2s - 93ms/step - loss: 0.5829 - val_loss: 1.0943 - learning_rate: 1.0000e-05\n",
      "Epoch 100/100\n",
      "19/19 - 2s - 87ms/step - loss: 0.5863 - val_loss: 1.0967 - learning_rate: 1.0000e-05\n",
      "Entrenando cluster numero: 4\n",
      "Epoch 1/100\n",
      "11/11 - 8s - 768ms/step - loss: 1.1258 - val_loss: 0.1876 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "11/11 - 1s - 115ms/step - loss: 0.7142 - val_loss: 0.5802 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "11/11 - 1s - 120ms/step - loss: 0.6515 - val_loss: 0.7355 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "11/11 - 1s - 100ms/step - loss: 0.6438 - val_loss: 0.5679 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "11/11 - 1s - 92ms/step - loss: 0.6402 - val_loss: 0.6574 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "11/11 - 1s - 92ms/step - loss: 0.6426 - val_loss: 0.6255 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "11/11 - 1s - 101ms/step - loss: 0.6392 - val_loss: 0.6691 - learning_rate: 0.0010\n",
      "Epoch 8/100\n",
      "11/11 - 1s - 93ms/step - loss: 0.6449 - val_loss: 0.9997 - learning_rate: 0.0010\n",
      "Epoch 9/100\n",
      "11/11 - 1s - 87ms/step - loss: 0.6415 - val_loss: 0.8041 - learning_rate: 0.0010\n",
      "Epoch 10/100\n",
      "11/11 - 1s - 87ms/step - loss: 0.6560 - val_loss: 0.5673 - learning_rate: 0.0010\n",
      "Epoch 11/100\n",
      "\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "11/11 - 1s - 85ms/step - loss: 0.6411 - val_loss: 0.5694 - learning_rate: 0.0010\n",
      "Epoch 12/100\n",
      "11/11 - 1s - 97ms/step - loss: 0.6293 - val_loss: 0.7278 - learning_rate: 2.0000e-04\n",
      "Epoch 13/100\n",
      "11/11 - 1s - 92ms/step - loss: 0.6181 - val_loss: 0.6362 - learning_rate: 2.0000e-04\n",
      "Epoch 14/100\n",
      "11/11 - 1s - 83ms/step - loss: 0.6254 - val_loss: 0.7404 - learning_rate: 2.0000e-04\n",
      "Epoch 15/100\n",
      "11/11 - 1s - 83ms/step - loss: 0.6266 - val_loss: 0.6442 - learning_rate: 2.0000e-04\n",
      "Epoch 16/100\n",
      "11/11 - 1s - 86ms/step - loss: 0.6264 - val_loss: 0.7108 - learning_rate: 2.0000e-04\n",
      "Epoch 17/100\n",
      "11/11 - 1s - 82ms/step - loss: 0.6302 - val_loss: 0.6672 - learning_rate: 2.0000e-04\n",
      "Epoch 18/100\n",
      "11/11 - 1s - 82ms/step - loss: 0.6209 - val_loss: 0.6966 - learning_rate: 2.0000e-04\n",
      "Epoch 19/100\n",
      "11/11 - 1s - 82ms/step - loss: 0.6296 - val_loss: 0.6959 - learning_rate: 2.0000e-04\n",
      "Epoch 20/100\n",
      "11/11 - 1s - 83ms/step - loss: 0.6297 - val_loss: 0.6809 - learning_rate: 2.0000e-04\n",
      "Epoch 21/100\n",
      "\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "11/11 - 1s - 84ms/step - loss: 0.6223 - val_loss: 0.6209 - learning_rate: 2.0000e-04\n",
      "Epoch 22/100\n",
      "11/11 - 1s - 81ms/step - loss: 0.6330 - val_loss: 0.6349 - learning_rate: 4.0000e-05\n",
      "Epoch 23/100\n",
      "11/11 - 1s - 82ms/step - loss: 0.6267 - val_loss: 0.6516 - learning_rate: 4.0000e-05\n",
      "Epoch 24/100\n",
      "11/11 - 1s - 82ms/step - loss: 0.6271 - val_loss: 0.6792 - learning_rate: 4.0000e-05\n",
      "Epoch 25/100\n",
      "11/11 - 1s - 86ms/step - loss: 0.6238 - val_loss: 0.6576 - learning_rate: 4.0000e-05\n",
      "Epoch 26/100\n",
      "11/11 - 1s - 81ms/step - loss: 0.6228 - val_loss: 0.6204 - learning_rate: 4.0000e-05\n",
      "Epoch 27/100\n",
      "11/11 - 1s - 82ms/step - loss: 0.6195 - val_loss: 0.6269 - learning_rate: 4.0000e-05\n",
      "Epoch 28/100\n",
      "11/11 - 1s - 82ms/step - loss: 0.6233 - val_loss: 0.6287 - learning_rate: 4.0000e-05\n",
      "Epoch 29/100\n",
      "11/11 - 1s - 84ms/step - loss: 0.6218 - val_loss: 0.6453 - learning_rate: 4.0000e-05\n",
      "Epoch 30/100\n",
      "11/11 - 1s - 82ms/step - loss: 0.6263 - val_loss: 0.6667 - learning_rate: 4.0000e-05\n",
      "Epoch 31/100\n",
      "\n",
      "Epoch 31: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "11/11 - 1s - 83ms/step - loss: 0.6240 - val_loss: 0.6656 - learning_rate: 4.0000e-05\n",
      "Epoch 32/100\n",
      "11/11 - 1s - 81ms/step - loss: 0.6230 - val_loss: 0.6609 - learning_rate: 1.0000e-05\n",
      "Epoch 33/100\n",
      "11/11 - 1s - 85ms/step - loss: 0.6211 - val_loss: 0.6587 - learning_rate: 1.0000e-05\n",
      "Epoch 34/100\n",
      "11/11 - 1s - 82ms/step - loss: 0.6267 - val_loss: 0.6560 - learning_rate: 1.0000e-05\n",
      "Epoch 35/100\n",
      "11/11 - 1s - 82ms/step - loss: 0.6271 - val_loss: 0.6520 - learning_rate: 1.0000e-05\n",
      "Epoch 36/100\n",
      "11/11 - 1s - 82ms/step - loss: 0.6217 - val_loss: 0.6494 - learning_rate: 1.0000e-05\n",
      "Epoch 37/100\n",
      "11/11 - 1s - 83ms/step - loss: 0.6290 - val_loss: 0.6547 - learning_rate: 1.0000e-05\n",
      "Epoch 38/100\n",
      "11/11 - 1s - 83ms/step - loss: 0.6228 - val_loss: 0.6542 - learning_rate: 1.0000e-05\n",
      "Epoch 39/100\n",
      "11/11 - 1s - 89ms/step - loss: 0.6246 - val_loss: 0.6574 - learning_rate: 1.0000e-05\n",
      "Epoch 40/100\n",
      "11/11 - 1s - 82ms/step - loss: 0.6159 - val_loss: 0.6654 - learning_rate: 1.0000e-05\n",
      "Epoch 41/100\n",
      "11/11 - 1s - 83ms/step - loss: 0.6276 - val_loss: 0.6640 - learning_rate: 1.0000e-05\n",
      "Epoch 42/100\n",
      "11/11 - 1s - 82ms/step - loss: 0.6250 - val_loss: 0.6598 - learning_rate: 1.0000e-05\n",
      "Epoch 43/100\n",
      "11/11 - 1s - 82ms/step - loss: 0.6193 - val_loss: 0.6602 - learning_rate: 1.0000e-05\n",
      "Epoch 44/100\n",
      "11/11 - 1s - 82ms/step - loss: 0.6305 - val_loss: 0.6682 - learning_rate: 1.0000e-05\n",
      "Epoch 45/100\n",
      "11/11 - 1s - 82ms/step - loss: 0.6244 - val_loss: 0.6762 - learning_rate: 1.0000e-05\n",
      "Epoch 46/100\n",
      "11/11 - 1s - 84ms/step - loss: 0.6251 - val_loss: 0.6805 - learning_rate: 1.0000e-05\n",
      "Epoch 47/100\n",
      "11/11 - 1s - 82ms/step - loss: 0.6192 - val_loss: 0.6807 - learning_rate: 1.0000e-05\n",
      "Epoch 48/100\n",
      "11/11 - 1s - 85ms/step - loss: 0.6240 - val_loss: 0.6802 - learning_rate: 1.0000e-05\n",
      "Epoch 49/100\n",
      "11/11 - 1s - 82ms/step - loss: 0.6264 - val_loss: 0.6814 - learning_rate: 1.0000e-05\n",
      "Epoch 50/100\n",
      "11/11 - 1s - 84ms/step - loss: 0.6218 - val_loss: 0.6765 - learning_rate: 1.0000e-05\n",
      "Epoch 51/100\n",
      "11/11 - 1s - 90ms/step - loss: 0.6202 - val_loss: 0.6847 - learning_rate: 1.0000e-05\n",
      "Epoch 52/100\n",
      "11/11 - 1s - 82ms/step - loss: 0.6295 - val_loss: 0.6921 - learning_rate: 1.0000e-05\n",
      "Epoch 53/100\n",
      "11/11 - 1s - 83ms/step - loss: 0.6223 - val_loss: 0.6955 - learning_rate: 1.0000e-05\n",
      "Epoch 54/100\n",
      "11/11 - 1s - 84ms/step - loss: 0.6286 - val_loss: 0.6854 - learning_rate: 1.0000e-05\n",
      "Epoch 55/100\n",
      "11/11 - 1s - 82ms/step - loss: 0.6200 - val_loss: 0.6732 - learning_rate: 1.0000e-05\n",
      "Epoch 56/100\n",
      "11/11 - 1s - 83ms/step - loss: 0.6241 - val_loss: 0.6685 - learning_rate: 1.0000e-05\n",
      "Epoch 57/100\n",
      "11/11 - 1s - 82ms/step - loss: 0.6225 - val_loss: 0.6643 - learning_rate: 1.0000e-05\n",
      "Epoch 58/100\n",
      "11/11 - 1s - 84ms/step - loss: 0.6278 - val_loss: 0.6623 - learning_rate: 1.0000e-05\n",
      "Epoch 59/100\n",
      "11/11 - 1s - 82ms/step - loss: 0.6190 - val_loss: 0.6681 - learning_rate: 1.0000e-05\n",
      "Epoch 60/100\n",
      "11/11 - 1s - 82ms/step - loss: 0.6299 - val_loss: 0.6626 - learning_rate: 1.0000e-05\n",
      "Epoch 61/100\n",
      "11/11 - 1s - 82ms/step - loss: 0.6238 - val_loss: 0.6496 - learning_rate: 1.0000e-05\n",
      "Epoch 62/100\n",
      "11/11 - 1s - 84ms/step - loss: 0.6241 - val_loss: 0.6462 - learning_rate: 1.0000e-05\n",
      "Epoch 63/100\n",
      "11/11 - 1s - 82ms/step - loss: 0.6245 - val_loss: 0.6436 - learning_rate: 1.0000e-05\n",
      "Epoch 64/100\n",
      "11/11 - 1s - 84ms/step - loss: 0.6221 - val_loss: 0.6425 - learning_rate: 1.0000e-05\n",
      "Epoch 65/100\n",
      "11/11 - 1s - 85ms/step - loss: 0.6208 - val_loss: 0.6515 - learning_rate: 1.0000e-05\n",
      "Epoch 66/100\n",
      "11/11 - 1s - 82ms/step - loss: 0.6203 - val_loss: 0.6595 - learning_rate: 1.0000e-05\n",
      "Epoch 67/100\n",
      "11/11 - 1s - 83ms/step - loss: 0.6245 - val_loss: 0.6631 - learning_rate: 1.0000e-05\n",
      "Epoch 68/100\n",
      "11/11 - 1s - 84ms/step - loss: 0.6255 - val_loss: 0.6583 - learning_rate: 1.0000e-05\n",
      "Epoch 69/100\n",
      "11/11 - 1s - 81ms/step - loss: 0.6205 - val_loss: 0.6632 - learning_rate: 1.0000e-05\n",
      "Epoch 70/100\n",
      "11/11 - 1s - 85ms/step - loss: 0.6240 - val_loss: 0.6636 - learning_rate: 1.0000e-05\n",
      "Epoch 71/100\n",
      "11/11 - 1s - 82ms/step - loss: 0.6216 - val_loss: 0.6714 - learning_rate: 1.0000e-05\n",
      "Epoch 72/100\n",
      "11/11 - 1s - 83ms/step - loss: 0.6246 - val_loss: 0.6811 - learning_rate: 1.0000e-05\n",
      "Epoch 73/100\n",
      "11/11 - 1s - 85ms/step - loss: 0.6186 - val_loss: 0.6902 - learning_rate: 1.0000e-05\n",
      "Epoch 74/100\n",
      "11/11 - 1s - 83ms/step - loss: 0.6263 - val_loss: 0.6910 - learning_rate: 1.0000e-05\n",
      "Epoch 75/100\n",
      "11/11 - 1s - 83ms/step - loss: 0.6240 - val_loss: 0.6921 - learning_rate: 1.0000e-05\n",
      "Epoch 76/100\n",
      "11/11 - 1s - 81ms/step - loss: 0.6208 - val_loss: 0.6841 - learning_rate: 1.0000e-05\n",
      "Epoch 77/100\n",
      "11/11 - 1s - 82ms/step - loss: 0.6236 - val_loss: 0.6709 - learning_rate: 1.0000e-05\n",
      "Epoch 78/100\n",
      "11/11 - 1s - 84ms/step - loss: 0.6309 - val_loss: 0.6631 - learning_rate: 1.0000e-05\n",
      "Epoch 79/100\n",
      "11/11 - 1s - 82ms/step - loss: 0.6182 - val_loss: 0.6710 - learning_rate: 1.0000e-05\n",
      "Epoch 80/100\n",
      "11/11 - 1s - 84ms/step - loss: 0.6209 - val_loss: 0.6831 - learning_rate: 1.0000e-05\n",
      "Epoch 81/100\n",
      "11/11 - 1s - 85ms/step - loss: 0.6214 - val_loss: 0.6853 - learning_rate: 1.0000e-05\n",
      "Epoch 82/100\n",
      "11/11 - 1s - 83ms/step - loss: 0.6231 - val_loss: 0.6788 - learning_rate: 1.0000e-05\n",
      "Epoch 83/100\n",
      "11/11 - 1s - 82ms/step - loss: 0.6204 - val_loss: 0.6732 - learning_rate: 1.0000e-05\n",
      "Epoch 84/100\n",
      "11/11 - 1s - 84ms/step - loss: 0.6255 - val_loss: 0.6635 - learning_rate: 1.0000e-05\n",
      "Epoch 85/100\n",
      "11/11 - 1s - 82ms/step - loss: 0.6199 - val_loss: 0.6561 - learning_rate: 1.0000e-05\n",
      "Epoch 86/100\n",
      "11/11 - 1s - 84ms/step - loss: 0.6226 - val_loss: 0.6497 - learning_rate: 1.0000e-05\n",
      "Epoch 87/100\n",
      "11/11 - 1s - 84ms/step - loss: 0.6202 - val_loss: 0.6497 - learning_rate: 1.0000e-05\n",
      "Epoch 88/100\n",
      "11/11 - 1s - 84ms/step - loss: 0.6239 - val_loss: 0.6549 - learning_rate: 1.0000e-05\n",
      "Epoch 89/100\n",
      "11/11 - 1s - 85ms/step - loss: 0.6221 - val_loss: 0.6631 - learning_rate: 1.0000e-05\n",
      "Epoch 90/100\n",
      "11/11 - 1s - 83ms/step - loss: 0.6216 - val_loss: 0.6654 - learning_rate: 1.0000e-05\n",
      "Epoch 91/100\n",
      "11/11 - 1s - 84ms/step - loss: 0.6270 - val_loss: 0.6769 - learning_rate: 1.0000e-05\n",
      "Epoch 92/100\n",
      "11/11 - 1s - 82ms/step - loss: 0.6246 - val_loss: 0.6800 - learning_rate: 1.0000e-05\n",
      "Epoch 93/100\n",
      "11/11 - 1s - 83ms/step - loss: 0.6282 - val_loss: 0.6806 - learning_rate: 1.0000e-05\n",
      "Epoch 94/100\n",
      "11/11 - 1s - 83ms/step - loss: 0.6227 - val_loss: 0.6884 - learning_rate: 1.0000e-05\n",
      "Epoch 95/100\n",
      "11/11 - 1s - 84ms/step - loss: 0.6224 - val_loss: 0.6904 - learning_rate: 1.0000e-05\n",
      "Epoch 96/100\n",
      "11/11 - 1s - 82ms/step - loss: 0.6289 - val_loss: 0.6879 - learning_rate: 1.0000e-05\n",
      "Epoch 97/100\n",
      "11/11 - 1s - 82ms/step - loss: 0.6254 - val_loss: 0.6810 - learning_rate: 1.0000e-05\n",
      "Epoch 98/100\n",
      "11/11 - 1s - 84ms/step - loss: 0.6233 - val_loss: 0.6950 - learning_rate: 1.0000e-05\n",
      "Epoch 99/100\n",
      "11/11 - 1s - 82ms/step - loss: 0.6224 - val_loss: 0.6936 - learning_rate: 1.0000e-05\n",
      "Epoch 100/100\n",
      "11/11 - 1s - 83ms/step - loss: 0.6233 - val_loss: 0.6782 - learning_rate: 1.0000e-05\n",
      "Entrenando cluster numero: 5\n",
      "Epoch 1/100\n",
      "3/3 - 9s - 3s/step - loss: 1.4708 - val_loss: 0.2960 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "3/3 - 0s - 124ms/step - loss: 0.7763 - val_loss: 2.3490 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "3/3 - 1s - 179ms/step - loss: 0.9650 - val_loss: 0.7618 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "3/3 - 0s - 58ms/step - loss: 0.7613 - val_loss: 0.4094 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "3/3 - 0s - 80ms/step - loss: 0.8139 - val_loss: 0.9857 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "3/3 - 0s - 51ms/step - loss: 0.7182 - val_loss: 1.4399 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "3/3 - 0s - 126ms/step - loss: 0.7233 - val_loss: 1.0399 - learning_rate: 0.0010\n",
      "Epoch 8/100\n",
      "3/3 - 0s - 77ms/step - loss: 0.6892 - val_loss: 0.6327 - learning_rate: 0.0010\n",
      "Epoch 9/100\n",
      "3/3 - 0s - 66ms/step - loss: 0.7310 - val_loss: 0.6699 - learning_rate: 0.0010\n",
      "Epoch 10/100\n",
      "3/3 - 0s - 58ms/step - loss: 0.6847 - val_loss: 1.0269 - learning_rate: 0.0010\n",
      "Epoch 11/100\n",
      "\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "3/3 - 0s - 45ms/step - loss: 0.6825 - val_loss: 1.1712 - learning_rate: 0.0010\n",
      "Epoch 12/100\n",
      "3/3 - 0s - 46ms/step - loss: 0.6882 - val_loss: 1.1254 - learning_rate: 2.0000e-04\n",
      "Epoch 13/100\n",
      "3/3 - 0s - 57ms/step - loss: 0.6710 - val_loss: 1.0487 - learning_rate: 2.0000e-04\n",
      "Epoch 14/100\n",
      "3/3 - 0s - 49ms/step - loss: 0.6686 - val_loss: 0.9507 - learning_rate: 2.0000e-04\n",
      "Epoch 15/100\n",
      "3/3 - 0s - 61ms/step - loss: 0.6577 - val_loss: 0.8675 - learning_rate: 2.0000e-04\n",
      "Epoch 16/100\n",
      "3/3 - 0s - 81ms/step - loss: 0.6589 - val_loss: 0.8303 - learning_rate: 2.0000e-04\n",
      "Epoch 17/100\n",
      "3/3 - 0s - 43ms/step - loss: 0.6681 - val_loss: 0.8357 - learning_rate: 2.0000e-04\n",
      "Epoch 18/100\n",
      "3/3 - 0s - 43ms/step - loss: 0.6817 - val_loss: 0.8662 - learning_rate: 2.0000e-04\n",
      "Epoch 19/100\n",
      "3/3 - 0s - 61ms/step - loss: 0.6739 - val_loss: 0.9186 - learning_rate: 2.0000e-04\n",
      "Epoch 20/100\n",
      "3/3 - 0s - 57ms/step - loss: 0.6542 - val_loss: 0.9641 - learning_rate: 2.0000e-04\n",
      "Epoch 21/100\n",
      "\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "3/3 - 0s - 55ms/step - loss: 0.6827 - val_loss: 0.9944 - learning_rate: 2.0000e-04\n",
      "Epoch 22/100\n",
      "3/3 - 0s - 39ms/step - loss: 0.6539 - val_loss: 0.9913 - learning_rate: 4.0000e-05\n",
      "Epoch 23/100\n",
      "3/3 - 0s - 53ms/step - loss: 0.6620 - val_loss: 0.9852 - learning_rate: 4.0000e-05\n",
      "Epoch 24/100\n",
      "3/3 - 0s - 44ms/step - loss: 0.6763 - val_loss: 0.9812 - learning_rate: 4.0000e-05\n",
      "Epoch 25/100\n",
      "3/3 - 0s - 46ms/step - loss: 0.6508 - val_loss: 0.9743 - learning_rate: 4.0000e-05\n",
      "Epoch 26/100\n",
      "3/3 - 0s - 39ms/step - loss: 0.6725 - val_loss: 0.9656 - learning_rate: 4.0000e-05\n",
      "Epoch 27/100\n",
      "3/3 - 0s - 44ms/step - loss: 0.6807 - val_loss: 0.9562 - learning_rate: 4.0000e-05\n",
      "Epoch 28/100\n",
      "3/3 - 0s - 39ms/step - loss: 0.6772 - val_loss: 0.9487 - learning_rate: 4.0000e-05\n",
      "Epoch 29/100\n",
      "3/3 - 0s - 44ms/step - loss: 0.6642 - val_loss: 0.9434 - learning_rate: 4.0000e-05\n",
      "Epoch 30/100\n",
      "3/3 - 0s - 46ms/step - loss: 0.6611 - val_loss: 0.9437 - learning_rate: 4.0000e-05\n",
      "Epoch 31/100\n",
      "\n",
      "Epoch 31: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "3/3 - 0s - 39ms/step - loss: 0.6710 - val_loss: 0.9418 - learning_rate: 4.0000e-05\n",
      "Epoch 32/100\n",
      "3/3 - 0s - 40ms/step - loss: 0.6930 - val_loss: 0.9417 - learning_rate: 1.0000e-05\n",
      "Epoch 33/100\n",
      "3/3 - 0s - 39ms/step - loss: 0.6817 - val_loss: 0.9416 - learning_rate: 1.0000e-05\n",
      "Epoch 34/100\n",
      "3/3 - 0s - 52ms/step - loss: 0.6670 - val_loss: 0.9420 - learning_rate: 1.0000e-05\n",
      "Epoch 35/100\n",
      "3/3 - 0s - 39ms/step - loss: 0.6608 - val_loss: 0.9415 - learning_rate: 1.0000e-05\n",
      "Epoch 36/100\n",
      "3/3 - 0s - 43ms/step - loss: 0.6574 - val_loss: 0.9413 - learning_rate: 1.0000e-05\n",
      "Epoch 37/100\n",
      "3/3 - 0s - 53ms/step - loss: 0.6415 - val_loss: 0.9416 - learning_rate: 1.0000e-05\n",
      "Epoch 38/100\n",
      "3/3 - 0s - 39ms/step - loss: 0.6538 - val_loss: 0.9414 - learning_rate: 1.0000e-05\n",
      "Epoch 39/100\n",
      "3/3 - 0s - 43ms/step - loss: 0.6751 - val_loss: 0.9410 - learning_rate: 1.0000e-05\n",
      "Epoch 40/100\n",
      "3/3 - 0s - 44ms/step - loss: 0.6612 - val_loss: 0.9401 - learning_rate: 1.0000e-05\n",
      "Epoch 41/100\n",
      "3/3 - 0s - 39ms/step - loss: 0.6598 - val_loss: 0.9384 - learning_rate: 1.0000e-05\n",
      "Epoch 42/100\n",
      "3/3 - 0s - 40ms/step - loss: 0.6717 - val_loss: 0.9373 - learning_rate: 1.0000e-05\n",
      "Epoch 43/100\n",
      "3/3 - 0s - 39ms/step - loss: 0.6486 - val_loss: 0.9368 - learning_rate: 1.0000e-05\n",
      "Epoch 44/100\n",
      "3/3 - 0s - 39ms/step - loss: 0.6648 - val_loss: 0.9351 - learning_rate: 1.0000e-05\n",
      "Epoch 45/100\n",
      "3/3 - 0s - 44ms/step - loss: 0.6608 - val_loss: 0.9356 - learning_rate: 1.0000e-05\n",
      "Epoch 46/100\n",
      "3/3 - 0s - 43ms/step - loss: 0.6673 - val_loss: 0.9369 - learning_rate: 1.0000e-05\n",
      "Epoch 47/100\n",
      "3/3 - 0s - 41ms/step - loss: 0.6770 - val_loss: 0.9377 - learning_rate: 1.0000e-05\n",
      "Epoch 48/100\n",
      "3/3 - 0s - 40ms/step - loss: 0.6638 - val_loss: 0.9387 - learning_rate: 1.0000e-05\n",
      "Epoch 49/100\n",
      "3/3 - 0s - 40ms/step - loss: 0.6645 - val_loss: 0.9397 - learning_rate: 1.0000e-05\n",
      "Epoch 50/100\n",
      "3/3 - 0s - 40ms/step - loss: 0.6519 - val_loss: 0.9406 - learning_rate: 1.0000e-05\n",
      "Epoch 51/100\n",
      "3/3 - 0s - 40ms/step - loss: 0.6821 - val_loss: 0.9402 - learning_rate: 1.0000e-05\n",
      "Epoch 52/100\n",
      "3/3 - 0s - 47ms/step - loss: 0.6682 - val_loss: 0.9388 - learning_rate: 1.0000e-05\n",
      "Epoch 53/100\n",
      "3/3 - 0s - 39ms/step - loss: 0.6775 - val_loss: 0.9372 - learning_rate: 1.0000e-05\n",
      "Epoch 54/100\n",
      "3/3 - 0s - 48ms/step - loss: 0.6688 - val_loss: 0.9365 - learning_rate: 1.0000e-05\n",
      "Epoch 55/100\n",
      "3/3 - 0s - 43ms/step - loss: 0.6739 - val_loss: 0.9370 - learning_rate: 1.0000e-05\n",
      "Epoch 56/100\n",
      "3/3 - 0s - 39ms/step - loss: 0.6502 - val_loss: 0.9373 - learning_rate: 1.0000e-05\n",
      "Epoch 57/100\n",
      "3/3 - 0s - 39ms/step - loss: 0.6623 - val_loss: 0.9375 - learning_rate: 1.0000e-05\n",
      "Epoch 58/100\n",
      "3/3 - 0s - 40ms/step - loss: 0.6753 - val_loss: 0.9376 - learning_rate: 1.0000e-05\n",
      "Epoch 59/100\n",
      "3/3 - 0s - 46ms/step - loss: 0.6826 - val_loss: 0.9390 - learning_rate: 1.0000e-05\n",
      "Epoch 60/100\n",
      "3/3 - 0s - 39ms/step - loss: 0.6904 - val_loss: 0.9391 - learning_rate: 1.0000e-05\n",
      "Epoch 61/100\n",
      "3/3 - 0s - 41ms/step - loss: 0.6667 - val_loss: 0.9401 - learning_rate: 1.0000e-05\n",
      "Epoch 62/100\n",
      "3/3 - 0s - 51ms/step - loss: 0.6856 - val_loss: 0.9407 - learning_rate: 1.0000e-05\n",
      "Epoch 63/100\n",
      "3/3 - 0s - 52ms/step - loss: 0.6724 - val_loss: 0.9399 - learning_rate: 1.0000e-05\n",
      "Epoch 64/100\n",
      "3/3 - 0s - 39ms/step - loss: 0.6539 - val_loss: 0.9404 - learning_rate: 1.0000e-05\n",
      "Epoch 65/100\n",
      "3/3 - 0s - 39ms/step - loss: 0.6815 - val_loss: 0.9411 - learning_rate: 1.0000e-05\n",
      "Epoch 66/100\n",
      "3/3 - 0s - 45ms/step - loss: 0.6515 - val_loss: 0.9431 - learning_rate: 1.0000e-05\n",
      "Epoch 67/100\n",
      "3/3 - 0s - 39ms/step - loss: 0.6636 - val_loss: 0.9432 - learning_rate: 1.0000e-05\n",
      "Epoch 68/100\n",
      "3/3 - 0s - 51ms/step - loss: 0.6859 - val_loss: 0.9426 - learning_rate: 1.0000e-05\n",
      "Epoch 69/100\n",
      "3/3 - 0s - 46ms/step - loss: 0.6418 - val_loss: 0.9408 - learning_rate: 1.0000e-05\n",
      "Epoch 70/100\n",
      "3/3 - 0s - 39ms/step - loss: 0.6509 - val_loss: 0.9397 - learning_rate: 1.0000e-05\n",
      "Epoch 71/100\n",
      "3/3 - 0s - 39ms/step - loss: 0.6789 - val_loss: 0.9399 - learning_rate: 1.0000e-05\n",
      "Epoch 72/100\n",
      "3/3 - 0s - 47ms/step - loss: 0.6580 - val_loss: 0.9390 - learning_rate: 1.0000e-05\n",
      "Epoch 73/100\n",
      "3/3 - 0s - 44ms/step - loss: 0.6697 - val_loss: 0.9387 - learning_rate: 1.0000e-05\n",
      "Epoch 74/100\n",
      "3/3 - 0s - 46ms/step - loss: 0.6609 - val_loss: 0.9382 - learning_rate: 1.0000e-05\n",
      "Epoch 75/100\n",
      "3/3 - 0s - 41ms/step - loss: 0.6563 - val_loss: 0.9379 - learning_rate: 1.0000e-05\n",
      "Epoch 76/100\n",
      "3/3 - 0s - 39ms/step - loss: 0.6736 - val_loss: 0.9388 - learning_rate: 1.0000e-05\n",
      "Epoch 77/100\n",
      "3/3 - 0s - 39ms/step - loss: 0.6914 - val_loss: 0.9395 - learning_rate: 1.0000e-05\n",
      "Epoch 78/100\n",
      "3/3 - 0s - 45ms/step - loss: 0.6690 - val_loss: 0.9414 - learning_rate: 1.0000e-05\n",
      "Epoch 79/100\n",
      "3/3 - 0s - 49ms/step - loss: 0.6664 - val_loss: 0.9417 - learning_rate: 1.0000e-05\n",
      "Epoch 80/100\n",
      "3/3 - 0s - 45ms/step - loss: 0.6653 - val_loss: 0.9412 - learning_rate: 1.0000e-05\n",
      "Epoch 81/100\n",
      "3/3 - 0s - 47ms/step - loss: 0.6587 - val_loss: 0.9410 - learning_rate: 1.0000e-05\n",
      "Epoch 82/100\n",
      "3/3 - 0s - 41ms/step - loss: 0.6657 - val_loss: 0.9424 - learning_rate: 1.0000e-05\n",
      "Epoch 83/100\n",
      "3/3 - 0s - 39ms/step - loss: 0.6734 - val_loss: 0.9440 - learning_rate: 1.0000e-05\n",
      "Epoch 84/100\n",
      "3/3 - 0s - 39ms/step - loss: 0.6617 - val_loss: 0.9431 - learning_rate: 1.0000e-05\n",
      "Epoch 85/100\n",
      "3/3 - 0s - 46ms/step - loss: 0.6858 - val_loss: 0.9437 - learning_rate: 1.0000e-05\n",
      "Epoch 86/100\n",
      "3/3 - 0s - 39ms/step - loss: 0.6640 - val_loss: 0.9425 - learning_rate: 1.0000e-05\n",
      "Epoch 87/100\n",
      "3/3 - 0s - 43ms/step - loss: 0.6685 - val_loss: 0.9412 - learning_rate: 1.0000e-05\n",
      "Epoch 88/100\n",
      "3/3 - 0s - 44ms/step - loss: 0.6702 - val_loss: 0.9412 - learning_rate: 1.0000e-05\n",
      "Epoch 89/100\n",
      "3/3 - 0s - 46ms/step - loss: 0.6631 - val_loss: 0.9404 - learning_rate: 1.0000e-05\n",
      "Epoch 90/100\n",
      "3/3 - 0s - 39ms/step - loss: 0.6488 - val_loss: 0.9417 - learning_rate: 1.0000e-05\n",
      "Epoch 91/100\n",
      "3/3 - 0s - 43ms/step - loss: 0.6622 - val_loss: 0.9425 - learning_rate: 1.0000e-05\n",
      "Epoch 92/100\n",
      "3/3 - 0s - 47ms/step - loss: 0.6681 - val_loss: 0.9435 - learning_rate: 1.0000e-05\n",
      "Epoch 93/100\n",
      "3/3 - 0s - 40ms/step - loss: 0.6607 - val_loss: 0.9435 - learning_rate: 1.0000e-05\n",
      "Epoch 94/100\n",
      "3/3 - 0s - 44ms/step - loss: 0.6700 - val_loss: 0.9448 - learning_rate: 1.0000e-05\n",
      "Epoch 95/100\n",
      "3/3 - 0s - 39ms/step - loss: 0.6518 - val_loss: 0.9467 - learning_rate: 1.0000e-05\n",
      "Epoch 96/100\n",
      "3/3 - 0s - 40ms/step - loss: 0.6658 - val_loss: 0.9467 - learning_rate: 1.0000e-05\n",
      "Epoch 97/100\n",
      "3/3 - 0s - 43ms/step - loss: 0.6707 - val_loss: 0.9450 - learning_rate: 1.0000e-05\n",
      "Epoch 98/100\n",
      "3/3 - 0s - 39ms/step - loss: 0.6782 - val_loss: 0.9423 - learning_rate: 1.0000e-05\n",
      "Epoch 99/100\n",
      "3/3 - 0s - 39ms/step - loss: 0.6830 - val_loss: 0.9413 - learning_rate: 1.0000e-05\n",
      "Epoch 100/100\n",
      "3/3 - 0s - 52ms/step - loss: 0.6798 - val_loss: 0.9398 - learning_rate: 1.0000e-05\n",
      "Entrenando cluster numero: 6\n",
      "Epoch 1/100\n",
      "43/43 - 11s - 245ms/step - loss: 0.7337 - val_loss: 0.8350 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "43/43 - 3s - 78ms/step - loss: 0.6173 - val_loss: 1.0188 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "43/43 - 4s - 82ms/step - loss: 0.6143 - val_loss: 0.7988 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "43/43 - 4s - 82ms/step - loss: 0.6080 - val_loss: 1.0088 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "43/43 - 4s - 83ms/step - loss: 0.6116 - val_loss: 1.0318 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "43/43 - 3s - 79ms/step - loss: 0.6116 - val_loss: 1.0135 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "43/43 - 3s - 80ms/step - loss: 0.6083 - val_loss: 0.7549 - learning_rate: 0.0010\n",
      "Epoch 8/100\n",
      "43/43 - 3s - 81ms/step - loss: 0.6103 - val_loss: 0.6774 - learning_rate: 0.0010\n",
      "Epoch 9/100\n",
      "43/43 - 4s - 84ms/step - loss: 0.6090 - val_loss: 0.7709 - learning_rate: 0.0010\n",
      "Epoch 10/100\n",
      "43/43 - 3s - 79ms/step - loss: 0.6093 - val_loss: 0.9452 - learning_rate: 0.0010\n",
      "Epoch 11/100\n",
      "43/43 - 3s - 79ms/step - loss: 0.6053 - val_loss: 0.8784 - learning_rate: 0.0010\n",
      "Epoch 12/100\n",
      "43/43 - 3s - 79ms/step - loss: 0.6077 - val_loss: 0.5794 - learning_rate: 0.0010\n",
      "Epoch 13/100\n",
      "43/43 - 3s - 78ms/step - loss: 0.6207 - val_loss: 1.1124 - learning_rate: 0.0010\n",
      "Epoch 14/100\n",
      "43/43 - 3s - 79ms/step - loss: 0.6027 - val_loss: 0.8377 - learning_rate: 0.0010\n",
      "Epoch 15/100\n",
      "43/43 - 3s - 79ms/step - loss: 0.6048 - val_loss: 0.8306 - learning_rate: 0.0010\n",
      "Epoch 16/100\n",
      "43/43 - 3s - 79ms/step - loss: 0.6051 - val_loss: 1.1359 - learning_rate: 0.0010\n",
      "Epoch 17/100\n",
      "43/43 - 3s - 78ms/step - loss: 0.6088 - val_loss: 1.0022 - learning_rate: 0.0010\n",
      "Epoch 18/100\n",
      "43/43 - 3s - 78ms/step - loss: 0.6020 - val_loss: 0.7214 - learning_rate: 0.0010\n",
      "Epoch 19/100\n",
      "43/43 - 3s - 78ms/step - loss: 0.6054 - val_loss: 0.8522 - learning_rate: 0.0010\n",
      "Epoch 20/100\n",
      "43/43 - 3s - 78ms/step - loss: 0.6031 - val_loss: 0.8676 - learning_rate: 0.0010\n",
      "Epoch 21/100\n",
      "43/43 - 3s - 79ms/step - loss: 0.6017 - val_loss: 0.9347 - learning_rate: 0.0010\n",
      "Epoch 22/100\n",
      "\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "43/43 - 3s - 78ms/step - loss: 0.6044 - val_loss: 0.8672 - learning_rate: 0.0010\n",
      "Epoch 23/100\n",
      "43/43 - 3s - 79ms/step - loss: 0.6007 - val_loss: 0.9307 - learning_rate: 2.0000e-04\n",
      "Epoch 24/100\n",
      "43/43 - 3s - 79ms/step - loss: 0.6006 - val_loss: 0.8941 - learning_rate: 2.0000e-04\n",
      "Epoch 25/100\n",
      "43/43 - 3s - 78ms/step - loss: 0.5988 - val_loss: 0.9030 - learning_rate: 2.0000e-04\n",
      "Epoch 26/100\n",
      "43/43 - 3s - 78ms/step - loss: 0.6002 - val_loss: 0.9331 - learning_rate: 2.0000e-04\n",
      "Epoch 27/100\n",
      "43/43 - 3s - 78ms/step - loss: 0.6005 - val_loss: 0.8926 - learning_rate: 2.0000e-04\n",
      "Epoch 28/100\n",
      "43/43 - 3s - 79ms/step - loss: 0.5996 - val_loss: 0.9830 - learning_rate: 2.0000e-04\n",
      "Epoch 29/100\n",
      "43/43 - 3s - 78ms/step - loss: 0.6016 - val_loss: 0.9989 - learning_rate: 2.0000e-04\n",
      "Epoch 30/100\n",
      "43/43 - 3s - 79ms/step - loss: 0.5999 - val_loss: 0.8269 - learning_rate: 2.0000e-04\n",
      "Epoch 31/100\n",
      "43/43 - 3s - 78ms/step - loss: 0.6043 - val_loss: 0.9071 - learning_rate: 2.0000e-04\n",
      "Epoch 32/100\n",
      "\n",
      "Epoch 32: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "43/43 - 3s - 78ms/step - loss: 0.5991 - val_loss: 0.9347 - learning_rate: 2.0000e-04\n",
      "Epoch 33/100\n",
      "43/43 - 3s - 78ms/step - loss: 0.5989 - val_loss: 0.9193 - learning_rate: 4.0000e-05\n",
      "Epoch 34/100\n",
      "43/43 - 3s - 78ms/step - loss: 0.5993 - val_loss: 0.9210 - learning_rate: 4.0000e-05\n",
      "Epoch 35/100\n",
      "43/43 - 3s - 81ms/step - loss: 0.5988 - val_loss: 0.9244 - learning_rate: 4.0000e-05\n",
      "Epoch 36/100\n",
      "43/43 - 3s - 81ms/step - loss: 0.5985 - val_loss: 0.9194 - learning_rate: 4.0000e-05\n",
      "Epoch 37/100\n",
      "43/43 - 3s - 79ms/step - loss: 0.5989 - val_loss: 0.9228 - learning_rate: 4.0000e-05\n",
      "Epoch 38/100\n",
      "43/43 - 3s - 78ms/step - loss: 0.5991 - val_loss: 0.9138 - learning_rate: 4.0000e-05\n",
      "Epoch 39/100\n",
      "43/43 - 3s - 78ms/step - loss: 0.5985 - val_loss: 0.9110 - learning_rate: 4.0000e-05\n",
      "Epoch 40/100\n",
      "43/43 - 3s - 78ms/step - loss: 0.5994 - val_loss: 0.9215 - learning_rate: 4.0000e-05\n",
      "Epoch 41/100\n",
      "43/43 - 3s - 79ms/step - loss: 0.5985 - val_loss: 0.9320 - learning_rate: 4.0000e-05\n",
      "Epoch 42/100\n",
      "\n",
      "Epoch 42: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "43/43 - 3s - 78ms/step - loss: 0.5983 - val_loss: 0.9041 - learning_rate: 4.0000e-05\n",
      "Epoch 43/100\n",
      "43/43 - 3s - 79ms/step - loss: 0.5984 - val_loss: 0.9100 - learning_rate: 1.0000e-05\n",
      "Epoch 44/100\n",
      "43/43 - 3s - 78ms/step - loss: 0.5980 - val_loss: 0.9146 - learning_rate: 1.0000e-05\n",
      "Epoch 45/100\n",
      "43/43 - 3s - 79ms/step - loss: 0.6005 - val_loss: 0.9233 - learning_rate: 1.0000e-05\n",
      "Epoch 46/100\n",
      "43/43 - 3s - 79ms/step - loss: 0.5983 - val_loss: 0.9236 - learning_rate: 1.0000e-05\n",
      "Epoch 47/100\n",
      "43/43 - 3s - 78ms/step - loss: 0.5991 - val_loss: 0.9283 - learning_rate: 1.0000e-05\n",
      "Epoch 48/100\n",
      "43/43 - 3s - 79ms/step - loss: 0.5983 - val_loss: 0.9326 - learning_rate: 1.0000e-05\n",
      "Epoch 49/100\n",
      "43/43 - 3s - 81ms/step - loss: 0.5987 - val_loss: 0.9184 - learning_rate: 1.0000e-05\n",
      "Epoch 50/100\n",
      "43/43 - 3s - 80ms/step - loss: 0.5984 - val_loss: 0.9149 - learning_rate: 1.0000e-05\n",
      "Epoch 51/100\n",
      "43/43 - 3s - 79ms/step - loss: 0.5980 - val_loss: 0.9227 - learning_rate: 1.0000e-05\n",
      "Epoch 52/100\n",
      "43/43 - 3s - 79ms/step - loss: 0.5993 - val_loss: 0.9301 - learning_rate: 1.0000e-05\n",
      "Epoch 53/100\n",
      "43/43 - 3s - 78ms/step - loss: 0.5975 - val_loss: 0.9238 - learning_rate: 1.0000e-05\n",
      "Epoch 54/100\n",
      "43/43 - 3s - 79ms/step - loss: 0.5985 - val_loss: 0.9257 - learning_rate: 1.0000e-05\n",
      "Epoch 55/100\n",
      "43/43 - 3s - 78ms/step - loss: 0.5994 - val_loss: 0.9342 - learning_rate: 1.0000e-05\n",
      "Epoch 56/100\n",
      "43/43 - 3s - 79ms/step - loss: 0.5989 - val_loss: 0.9318 - learning_rate: 1.0000e-05\n",
      "Epoch 57/100\n",
      "43/43 - 3s - 78ms/step - loss: 0.5988 - val_loss: 0.9299 - learning_rate: 1.0000e-05\n",
      "Epoch 58/100\n",
      "43/43 - 4s - 82ms/step - loss: 0.5980 - val_loss: 0.9267 - learning_rate: 1.0000e-05\n",
      "Epoch 59/100\n",
      "43/43 - 3s - 78ms/step - loss: 0.5987 - val_loss: 0.9305 - learning_rate: 1.0000e-05\n",
      "Epoch 60/100\n",
      "43/43 - 3s - 79ms/step - loss: 0.5998 - val_loss: 0.9201 - learning_rate: 1.0000e-05\n",
      "Epoch 61/100\n",
      "43/43 - 3s - 78ms/step - loss: 0.5985 - val_loss: 0.9361 - learning_rate: 1.0000e-05\n",
      "Epoch 62/100\n",
      "43/43 - 3s - 78ms/step - loss: 0.5989 - val_loss: 0.9305 - learning_rate: 1.0000e-05\n",
      "Epoch 63/100\n",
      "43/43 - 3s - 78ms/step - loss: 0.5989 - val_loss: 0.9337 - learning_rate: 1.0000e-05\n",
      "Epoch 64/100\n",
      "43/43 - 3s - 79ms/step - loss: 0.5976 - val_loss: 0.9419 - learning_rate: 1.0000e-05\n",
      "Epoch 65/100\n",
      "43/43 - 3s - 78ms/step - loss: 0.5974 - val_loss: 0.9352 - learning_rate: 1.0000e-05\n",
      "Epoch 66/100\n",
      "43/43 - 3s - 78ms/step - loss: 0.5991 - val_loss: 0.9341 - learning_rate: 1.0000e-05\n",
      "Epoch 67/100\n",
      "43/43 - 3s - 79ms/step - loss: 0.5986 - val_loss: 0.9336 - learning_rate: 1.0000e-05\n",
      "Epoch 68/100\n",
      "43/43 - 3s - 78ms/step - loss: 0.5983 - val_loss: 0.9289 - learning_rate: 1.0000e-05\n",
      "Epoch 69/100\n",
      "43/43 - 3s - 79ms/step - loss: 0.5977 - val_loss: 0.9240 - learning_rate: 1.0000e-05\n",
      "Epoch 70/100\n",
      "43/43 - 3s - 78ms/step - loss: 0.5982 - val_loss: 0.9192 - learning_rate: 1.0000e-05\n",
      "Epoch 71/100\n",
      "43/43 - 3s - 80ms/step - loss: 0.5982 - val_loss: 0.9340 - learning_rate: 1.0000e-05\n",
      "Epoch 72/100\n",
      "43/43 - 3s - 78ms/step - loss: 0.5994 - val_loss: 0.9314 - learning_rate: 1.0000e-05\n",
      "Epoch 73/100\n",
      "43/43 - 3s - 78ms/step - loss: 0.5984 - val_loss: 0.9372 - learning_rate: 1.0000e-05\n",
      "Epoch 74/100\n",
      "43/43 - 3s - 79ms/step - loss: 0.5989 - val_loss: 0.9237 - learning_rate: 1.0000e-05\n",
      "Epoch 75/100\n",
      "43/43 - 3s - 78ms/step - loss: 0.5972 - val_loss: 0.9343 - learning_rate: 1.0000e-05\n",
      "Epoch 76/100\n",
      "43/43 - 3s - 78ms/step - loss: 0.5985 - val_loss: 0.9277 - learning_rate: 1.0000e-05\n",
      "Epoch 77/100\n",
      "43/43 - 3s - 78ms/step - loss: 0.5983 - val_loss: 0.9211 - learning_rate: 1.0000e-05\n",
      "Epoch 78/100\n",
      "43/43 - 3s - 79ms/step - loss: 0.5979 - val_loss: 0.9214 - learning_rate: 1.0000e-05\n",
      "Epoch 79/100\n",
      "43/43 - 3s - 78ms/step - loss: 0.5991 - val_loss: 0.9135 - learning_rate: 1.0000e-05\n",
      "Epoch 80/100\n",
      "43/43 - 3s - 80ms/step - loss: 0.5975 - val_loss: 0.9219 - learning_rate: 1.0000e-05\n",
      "Epoch 81/100\n",
      "43/43 - 3s - 81ms/step - loss: 0.5981 - val_loss: 0.9225 - learning_rate: 1.0000e-05\n",
      "Epoch 82/100\n",
      "43/43 - 3s - 78ms/step - loss: 0.5994 - val_loss: 0.9343 - learning_rate: 1.0000e-05\n",
      "Epoch 83/100\n",
      "43/43 - 3s - 78ms/step - loss: 0.5995 - val_loss: 0.9291 - learning_rate: 1.0000e-05\n",
      "Epoch 84/100\n",
      "43/43 - 3s - 78ms/step - loss: 0.5980 - val_loss: 0.9178 - learning_rate: 1.0000e-05\n",
      "Epoch 85/100\n",
      "43/43 - 3s - 78ms/step - loss: 0.5990 - val_loss: 0.9256 - learning_rate: 1.0000e-05\n",
      "Epoch 86/100\n",
      "43/43 - 3s - 79ms/step - loss: 0.5979 - val_loss: 0.9282 - learning_rate: 1.0000e-05\n",
      "Epoch 87/100\n",
      "43/43 - 3s - 79ms/step - loss: 0.5991 - val_loss: 0.9279 - learning_rate: 1.0000e-05\n",
      "Epoch 88/100\n",
      "43/43 - 3s - 79ms/step - loss: 0.5982 - val_loss: 0.9283 - learning_rate: 1.0000e-05\n",
      "Epoch 89/100\n",
      "43/43 - 3s - 78ms/step - loss: 0.5988 - val_loss: 0.9302 - learning_rate: 1.0000e-05\n",
      "Epoch 90/100\n",
      "43/43 - 3s - 79ms/step - loss: 0.5999 - val_loss: 0.9289 - learning_rate: 1.0000e-05\n",
      "Epoch 91/100\n",
      "43/43 - 3s - 78ms/step - loss: 0.5983 - val_loss: 0.9323 - learning_rate: 1.0000e-05\n",
      "Epoch 92/100\n",
      "43/43 - 3s - 79ms/step - loss: 0.5983 - val_loss: 0.9275 - learning_rate: 1.0000e-05\n",
      "Epoch 93/100\n",
      "43/43 - 3s - 78ms/step - loss: 0.5982 - val_loss: 0.9072 - learning_rate: 1.0000e-05\n",
      "Epoch 94/100\n",
      "43/43 - 3s - 78ms/step - loss: 0.5984 - val_loss: 0.9281 - learning_rate: 1.0000e-05\n",
      "Epoch 95/100\n",
      "43/43 - 3s - 78ms/step - loss: 0.5989 - val_loss: 0.9286 - learning_rate: 1.0000e-05\n",
      "Epoch 96/100\n",
      "43/43 - 3s - 78ms/step - loss: 0.5987 - val_loss: 0.9234 - learning_rate: 1.0000e-05\n",
      "Epoch 97/100\n",
      "43/43 - 3s - 78ms/step - loss: 0.5989 - val_loss: 0.9168 - learning_rate: 1.0000e-05\n",
      "Epoch 98/100\n",
      "43/43 - 3s - 79ms/step - loss: 0.5982 - val_loss: 0.9272 - learning_rate: 1.0000e-05\n",
      "Epoch 99/100\n",
      "43/43 - 3s - 78ms/step - loss: 0.5982 - val_loss: 0.9238 - learning_rate: 1.0000e-05\n",
      "Epoch 100/100\n",
      "43/43 - 4s - 82ms/step - loss: 0.5979 - val_loss: 0.9223 - learning_rate: 1.0000e-05\n",
      "Entrenando cluster numero: 7\n",
      "Epoch 1/100\n",
      "18/18 - 8s - 423ms/step - loss: 0.9736 - val_loss: 0.9986 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "18/18 - 1s - 82ms/step - loss: 0.6610 - val_loss: 0.9075 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "18/18 - 1s - 81ms/step - loss: 0.6353 - val_loss: 0.7409 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "18/18 - 1s - 80ms/step - loss: 0.6289 - val_loss: 0.6873 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "18/18 - 1s - 80ms/step - loss: 0.6144 - val_loss: 0.8775 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "18/18 - 2s - 84ms/step - loss: 0.6159 - val_loss: 0.6245 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "18/18 - 1s - 80ms/step - loss: 0.6156 - val_loss: 0.8333 - learning_rate: 0.0010\n",
      "Epoch 8/100\n",
      "18/18 - 1s - 81ms/step - loss: 0.6209 - val_loss: 0.7813 - learning_rate: 0.0010\n",
      "Epoch 9/100\n",
      "18/18 - 1s - 82ms/step - loss: 0.6116 - val_loss: 0.7504 - learning_rate: 0.0010\n",
      "Epoch 10/100\n",
      "18/18 - 1s - 80ms/step - loss: 0.6190 - val_loss: 0.8628 - learning_rate: 0.0010\n",
      "Epoch 11/100\n",
      "18/18 - 1s - 81ms/step - loss: 0.6141 - val_loss: 0.7445 - learning_rate: 0.0010\n",
      "Epoch 12/100\n",
      "18/18 - 1s - 80ms/step - loss: 0.6166 - val_loss: 1.0902 - learning_rate: 0.0010\n",
      "Epoch 13/100\n",
      "18/18 - 2s - 85ms/step - loss: 0.6164 - val_loss: 0.6230 - learning_rate: 0.0010\n",
      "Epoch 14/100\n",
      "18/18 - 1s - 82ms/step - loss: 0.6176 - val_loss: 1.1220 - learning_rate: 0.0010\n",
      "Epoch 15/100\n",
      "18/18 - 1s - 80ms/step - loss: 0.6106 - val_loss: 0.7898 - learning_rate: 0.0010\n",
      "Epoch 16/100\n",
      "18/18 - 1s - 80ms/step - loss: 0.6136 - val_loss: 0.8038 - learning_rate: 0.0010\n",
      "Epoch 17/100\n",
      "18/18 - 1s - 80ms/step - loss: 0.6098 - val_loss: 0.7701 - learning_rate: 0.0010\n",
      "Epoch 18/100\n",
      "18/18 - 2s - 84ms/step - loss: 0.6207 - val_loss: 0.6688 - learning_rate: 0.0010\n",
      "Epoch 19/100\n",
      "18/18 - 1s - 80ms/step - loss: 0.6117 - val_loss: 0.7406 - learning_rate: 0.0010\n",
      "Epoch 20/100\n",
      "18/18 - 2s - 85ms/step - loss: 0.6193 - val_loss: 0.7812 - learning_rate: 0.0010\n",
      "Epoch 21/100\n",
      "18/18 - 2s - 85ms/step - loss: 0.6091 - val_loss: 0.7346 - learning_rate: 0.0010\n",
      "Epoch 22/100\n",
      "18/18 - 1s - 81ms/step - loss: 0.6117 - val_loss: 0.7448 - learning_rate: 0.0010\n",
      "Epoch 23/100\n",
      "\n",
      "Epoch 23: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "18/18 - 1s - 80ms/step - loss: 0.6059 - val_loss: 0.7097 - learning_rate: 0.0010\n",
      "Epoch 24/100\n",
      "18/18 - 1s - 80ms/step - loss: 0.6055 - val_loss: 0.8372 - learning_rate: 2.0000e-04\n",
      "Epoch 25/100\n",
      "18/18 - 1s - 80ms/step - loss: 0.6027 - val_loss: 0.7726 - learning_rate: 2.0000e-04\n",
      "Epoch 26/100\n",
      "18/18 - 1s - 79ms/step - loss: 0.6062 - val_loss: 0.8444 - learning_rate: 2.0000e-04\n",
      "Epoch 27/100\n",
      "18/18 - 1s - 81ms/step - loss: 0.6044 - val_loss: 0.7460 - learning_rate: 2.0000e-04\n",
      "Epoch 28/100\n",
      "18/18 - 1s - 80ms/step - loss: 0.6060 - val_loss: 0.8001 - learning_rate: 2.0000e-04\n",
      "Epoch 29/100\n",
      "18/18 - 1s - 82ms/step - loss: 0.6072 - val_loss: 0.7804 - learning_rate: 2.0000e-04\n",
      "Epoch 30/100\n",
      "18/18 - 2s - 92ms/step - loss: 0.6061 - val_loss: 0.7946 - learning_rate: 2.0000e-04\n",
      "Epoch 31/100\n",
      "18/18 - 1s - 82ms/step - loss: 0.6078 - val_loss: 0.7779 - learning_rate: 2.0000e-04\n",
      "Epoch 32/100\n",
      "18/18 - 1s - 83ms/step - loss: 0.6046 - val_loss: 0.7911 - learning_rate: 2.0000e-04\n",
      "Epoch 33/100\n",
      "\n",
      "Epoch 33: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "18/18 - 1s - 80ms/step - loss: 0.6050 - val_loss: 0.8588 - learning_rate: 2.0000e-04\n",
      "Epoch 34/100\n",
      "18/18 - 1s - 82ms/step - loss: 0.6038 - val_loss: 0.8158 - learning_rate: 4.0000e-05\n",
      "Epoch 35/100\n",
      "18/18 - 1s - 81ms/step - loss: 0.6027 - val_loss: 0.7915 - learning_rate: 4.0000e-05\n",
      "Epoch 36/100\n",
      "18/18 - 1s - 81ms/step - loss: 0.6041 - val_loss: 0.7928 - learning_rate: 4.0000e-05\n",
      "Epoch 37/100\n",
      "18/18 - 1s - 81ms/step - loss: 0.6049 - val_loss: 0.8054 - learning_rate: 4.0000e-05\n",
      "Epoch 38/100\n",
      "18/18 - 1s - 81ms/step - loss: 0.6046 - val_loss: 0.7983 - learning_rate: 4.0000e-05\n",
      "Epoch 39/100\n",
      "18/18 - 1s - 82ms/step - loss: 0.6042 - val_loss: 0.8028 - learning_rate: 4.0000e-05\n",
      "Epoch 40/100\n",
      "18/18 - 1s - 81ms/step - loss: 0.6046 - val_loss: 0.7994 - learning_rate: 4.0000e-05\n",
      "Epoch 41/100\n",
      "18/18 - 1s - 81ms/step - loss: 0.6080 - val_loss: 0.7938 - learning_rate: 4.0000e-05\n",
      "Epoch 42/100\n",
      "18/18 - 1s - 81ms/step - loss: 0.6046 - val_loss: 0.7962 - learning_rate: 4.0000e-05\n",
      "Epoch 43/100\n",
      "\n",
      "Epoch 43: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "18/18 - 2s - 87ms/step - loss: 0.6038 - val_loss: 0.8074 - learning_rate: 4.0000e-05\n",
      "Epoch 44/100\n",
      "18/18 - 2s - 84ms/step - loss: 0.6063 - val_loss: 0.7959 - learning_rate: 1.0000e-05\n",
      "Epoch 45/100\n",
      "18/18 - 1s - 80ms/step - loss: 0.6036 - val_loss: 0.8002 - learning_rate: 1.0000e-05\n",
      "Epoch 46/100\n",
      "18/18 - 1s - 81ms/step - loss: 0.6050 - val_loss: 0.7970 - learning_rate: 1.0000e-05\n",
      "Epoch 47/100\n",
      "18/18 - 1s - 80ms/step - loss: 0.6023 - val_loss: 0.7974 - learning_rate: 1.0000e-05\n",
      "Epoch 48/100\n",
      "18/18 - 1s - 80ms/step - loss: 0.6044 - val_loss: 0.8014 - learning_rate: 1.0000e-05\n",
      "Epoch 49/100\n",
      "18/18 - 1s - 81ms/step - loss: 0.6031 - val_loss: 0.8007 - learning_rate: 1.0000e-05\n",
      "Epoch 50/100\n",
      "18/18 - 1s - 82ms/step - loss: 0.6056 - val_loss: 0.8022 - learning_rate: 1.0000e-05\n",
      "Epoch 51/100\n",
      "18/18 - 2s - 85ms/step - loss: 0.6010 - val_loss: 0.8009 - learning_rate: 1.0000e-05\n",
      "Epoch 52/100\n",
      "18/18 - 2s - 84ms/step - loss: 0.6042 - val_loss: 0.8025 - learning_rate: 1.0000e-05\n",
      "Epoch 53/100\n",
      "18/18 - 1s - 83ms/step - loss: 0.6027 - val_loss: 0.8008 - learning_rate: 1.0000e-05\n",
      "Epoch 54/100\n",
      "18/18 - 1s - 82ms/step - loss: 0.6062 - val_loss: 0.7966 - learning_rate: 1.0000e-05\n",
      "Epoch 55/100\n",
      "18/18 - 2s - 83ms/step - loss: 0.6068 - val_loss: 0.7980 - learning_rate: 1.0000e-05\n",
      "Epoch 56/100\n",
      "18/18 - 1s - 83ms/step - loss: 0.6022 - val_loss: 0.7947 - learning_rate: 1.0000e-05\n",
      "Epoch 57/100\n",
      "18/18 - 1s - 82ms/step - loss: 0.6035 - val_loss: 0.7988 - learning_rate: 1.0000e-05\n",
      "Epoch 58/100\n",
      "18/18 - 1s - 82ms/step - loss: 0.6072 - val_loss: 0.8023 - learning_rate: 1.0000e-05\n",
      "Epoch 59/100\n",
      "18/18 - 1s - 81ms/step - loss: 0.6029 - val_loss: 0.7957 - learning_rate: 1.0000e-05\n",
      "Epoch 60/100\n",
      "18/18 - 1s - 82ms/step - loss: 0.6043 - val_loss: 0.7977 - learning_rate: 1.0000e-05\n",
      "Epoch 61/100\n",
      "18/18 - 2s - 84ms/step - loss: 0.6053 - val_loss: 0.7996 - learning_rate: 1.0000e-05\n",
      "Epoch 62/100\n",
      "18/18 - 2s - 84ms/step - loss: 0.6036 - val_loss: 0.7988 - learning_rate: 1.0000e-05\n",
      "Epoch 63/100\n",
      "18/18 - 1s - 82ms/step - loss: 0.6044 - val_loss: 0.7998 - learning_rate: 1.0000e-05\n",
      "Epoch 64/100\n",
      "18/18 - 1s - 82ms/step - loss: 0.6049 - val_loss: 0.7998 - learning_rate: 1.0000e-05\n",
      "Epoch 65/100\n",
      "18/18 - 1s - 81ms/step - loss: 0.6031 - val_loss: 0.7947 - learning_rate: 1.0000e-05\n",
      "Epoch 66/100\n",
      "18/18 - 1s - 82ms/step - loss: 0.6080 - val_loss: 0.7983 - learning_rate: 1.0000e-05\n",
      "Epoch 67/100\n",
      "18/18 - 1s - 81ms/step - loss: 0.6040 - val_loss: 0.8015 - learning_rate: 1.0000e-05\n",
      "Epoch 68/100\n",
      "18/18 - 1s - 82ms/step - loss: 0.6041 - val_loss: 0.8033 - learning_rate: 1.0000e-05\n",
      "Epoch 69/100\n",
      "18/18 - 1s - 81ms/step - loss: 0.6030 - val_loss: 0.7992 - learning_rate: 1.0000e-05\n",
      "Epoch 70/100\n",
      "18/18 - 1s - 82ms/step - loss: 0.6050 - val_loss: 0.7978 - learning_rate: 1.0000e-05\n",
      "Epoch 71/100\n",
      "18/18 - 1s - 81ms/step - loss: 0.6037 - val_loss: 0.8020 - learning_rate: 1.0000e-05\n",
      "Epoch 72/100\n",
      "18/18 - 1s - 82ms/step - loss: 0.6032 - val_loss: 0.8029 - learning_rate: 1.0000e-05\n",
      "Epoch 73/100\n",
      "18/18 - 1s - 82ms/step - loss: 0.6061 - val_loss: 0.7946 - learning_rate: 1.0000e-05\n",
      "Epoch 74/100\n",
      "18/18 - 1s - 82ms/step - loss: 0.6027 - val_loss: 0.8017 - learning_rate: 1.0000e-05\n",
      "Epoch 75/100\n",
      "18/18 - 1s - 81ms/step - loss: 0.6032 - val_loss: 0.8032 - learning_rate: 1.0000e-05\n",
      "Epoch 76/100\n",
      "18/18 - 1s - 82ms/step - loss: 0.6041 - val_loss: 0.8000 - learning_rate: 1.0000e-05\n",
      "Epoch 77/100\n",
      "18/18 - 1s - 81ms/step - loss: 0.6039 - val_loss: 0.8005 - learning_rate: 1.0000e-05\n",
      "Epoch 78/100\n",
      "18/18 - 1s - 80ms/step - loss: 0.6017 - val_loss: 0.7994 - learning_rate: 1.0000e-05\n",
      "Epoch 79/100\n",
      "18/18 - 1s - 82ms/step - loss: 0.6024 - val_loss: 0.8036 - learning_rate: 1.0000e-05\n",
      "Epoch 80/100\n",
      "18/18 - 1s - 81ms/step - loss: 0.6063 - val_loss: 0.7994 - learning_rate: 1.0000e-05\n",
      "Epoch 81/100\n",
      "18/18 - 1s - 81ms/step - loss: 0.6041 - val_loss: 0.8011 - learning_rate: 1.0000e-05\n",
      "Epoch 82/100\n",
      "18/18 - 1s - 81ms/step - loss: 0.6050 - val_loss: 0.7954 - learning_rate: 1.0000e-05\n",
      "Epoch 83/100\n",
      "18/18 - 1s - 83ms/step - loss: 0.6015 - val_loss: 0.8033 - learning_rate: 1.0000e-05\n",
      "Epoch 84/100\n",
      "18/18 - 2s - 85ms/step - loss: 0.6046 - val_loss: 0.7991 - learning_rate: 1.0000e-05\n",
      "Epoch 85/100\n",
      "18/18 - 1s - 83ms/step - loss: 0.6043 - val_loss: 0.8043 - learning_rate: 1.0000e-05\n",
      "Epoch 86/100\n",
      "18/18 - 1s - 82ms/step - loss: 0.6023 - val_loss: 0.8033 - learning_rate: 1.0000e-05\n",
      "Epoch 87/100\n",
      "18/18 - 1s - 81ms/step - loss: 0.6049 - val_loss: 0.7946 - learning_rate: 1.0000e-05\n",
      "Epoch 88/100\n",
      "18/18 - 1s - 81ms/step - loss: 0.6046 - val_loss: 0.7995 - learning_rate: 1.0000e-05\n",
      "Epoch 89/100\n",
      "18/18 - 1s - 81ms/step - loss: 0.6028 - val_loss: 0.8002 - learning_rate: 1.0000e-05\n",
      "Epoch 90/100\n",
      "18/18 - 1s - 81ms/step - loss: 0.6023 - val_loss: 0.7970 - learning_rate: 1.0000e-05\n",
      "Epoch 91/100\n",
      "18/18 - 1s - 81ms/step - loss: 0.6037 - val_loss: 0.8027 - learning_rate: 1.0000e-05\n",
      "Epoch 92/100\n",
      "18/18 - 1s - 81ms/step - loss: 0.6023 - val_loss: 0.8001 - learning_rate: 1.0000e-05\n",
      "Epoch 93/100\n",
      "18/18 - 1s - 81ms/step - loss: 0.6066 - val_loss: 0.7993 - learning_rate: 1.0000e-05\n",
      "Epoch 94/100\n",
      "18/18 - 1s - 81ms/step - loss: 0.6046 - val_loss: 0.8037 - learning_rate: 1.0000e-05\n",
      "Epoch 95/100\n",
      "18/18 - 1s - 83ms/step - loss: 0.6022 - val_loss: 0.8082 - learning_rate: 1.0000e-05\n",
      "Epoch 96/100\n",
      "18/18 - 2s - 84ms/step - loss: 0.6058 - val_loss: 0.7999 - learning_rate: 1.0000e-05\n",
      "Epoch 97/100\n",
      "18/18 - 1s - 81ms/step - loss: 0.6037 - val_loss: 0.7972 - learning_rate: 1.0000e-05\n",
      "Epoch 98/100\n",
      "18/18 - 1s - 81ms/step - loss: 0.6060 - val_loss: 0.7991 - learning_rate: 1.0000e-05\n",
      "Epoch 99/100\n",
      "18/18 - 1s - 81ms/step - loss: 0.6051 - val_loss: 0.7984 - learning_rate: 1.0000e-05\n",
      "Epoch 100/100\n",
      "18/18 - 1s - 83ms/step - loss: 0.6042 - val_loss: 0.7945 - learning_rate: 1.0000e-05\n",
      "Entrenando cluster numero: 8\n",
      "Epoch 1/100\n",
      "19/19 - 8s - 396ms/step - loss: 0.8726 - val_loss: 1.0642 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "19/19 - 2s - 85ms/step - loss: 0.6092 - val_loss: 0.6782 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "19/19 - 2s - 85ms/step - loss: 0.5981 - val_loss: 0.5323 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "19/19 - 2s - 82ms/step - loss: 0.5906 - val_loss: 0.6676 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "19/19 - 2s - 87ms/step - loss: 0.5919 - val_loss: 0.9748 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "19/19 - 2s - 86ms/step - loss: 0.6034 - val_loss: 0.4670 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "19/19 - 2s - 82ms/step - loss: 0.5946 - val_loss: 0.6949 - learning_rate: 0.0010\n",
      "Epoch 8/100\n",
      "19/19 - 2s - 81ms/step - loss: 0.5862 - val_loss: 0.5929 - learning_rate: 0.0010\n",
      "Epoch 9/100\n",
      "19/19 - 2s - 81ms/step - loss: 0.5868 - val_loss: 0.8324 - learning_rate: 0.0010\n",
      "Epoch 10/100\n",
      "19/19 - 2s - 82ms/step - loss: 0.5918 - val_loss: 0.5411 - learning_rate: 0.0010\n",
      "Epoch 11/100\n",
      "19/19 - 2s - 81ms/step - loss: 0.5893 - val_loss: 0.8922 - learning_rate: 0.0010\n",
      "Epoch 12/100\n",
      "19/19 - 2s - 82ms/step - loss: 0.5825 - val_loss: 0.8259 - learning_rate: 0.0010\n",
      "Epoch 13/100\n",
      "19/19 - 2s - 83ms/step - loss: 0.5837 - val_loss: 0.6852 - learning_rate: 0.0010\n",
      "Epoch 14/100\n",
      "19/19 - 2s - 87ms/step - loss: 0.5814 - val_loss: 0.7268 - learning_rate: 0.0010\n",
      "Epoch 15/100\n",
      "19/19 - 2s - 83ms/step - loss: 0.5863 - val_loss: 0.6647 - learning_rate: 0.0010\n",
      "Epoch 16/100\n",
      "\n",
      "Epoch 16: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "19/19 - 2s - 82ms/step - loss: 0.5873 - val_loss: 0.7189 - learning_rate: 0.0010\n",
      "Epoch 17/100\n",
      "19/19 - 2s - 82ms/step - loss: 0.5830 - val_loss: 0.7405 - learning_rate: 2.0000e-04\n",
      "Epoch 18/100\n",
      "19/19 - 2s - 81ms/step - loss: 0.5802 - val_loss: 0.6738 - learning_rate: 2.0000e-04\n",
      "Epoch 19/100\n",
      "19/19 - 2s - 80ms/step - loss: 0.5820 - val_loss: 0.7433 - learning_rate: 2.0000e-04\n",
      "Epoch 20/100\n",
      "19/19 - 2s - 82ms/step - loss: 0.5818 - val_loss: 0.7496 - learning_rate: 2.0000e-04\n",
      "Epoch 21/100\n",
      "19/19 - 2s - 81ms/step - loss: 0.5816 - val_loss: 0.6894 - learning_rate: 2.0000e-04\n",
      "Epoch 22/100\n",
      "19/19 - 2s - 81ms/step - loss: 0.5807 - val_loss: 0.6720 - learning_rate: 2.0000e-04\n",
      "Epoch 23/100\n",
      "19/19 - 2s - 82ms/step - loss: 0.5812 - val_loss: 0.7268 - learning_rate: 2.0000e-04\n",
      "Epoch 24/100\n",
      "19/19 - 2s - 82ms/step - loss: 0.5815 - val_loss: 0.7987 - learning_rate: 2.0000e-04\n",
      "Epoch 25/100\n",
      "19/19 - 2s - 82ms/step - loss: 0.5834 - val_loss: 0.7393 - learning_rate: 2.0000e-04\n",
      "Epoch 26/100\n",
      "\n",
      "Epoch 26: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "19/19 - 2s - 82ms/step - loss: 0.5802 - val_loss: 0.7254 - learning_rate: 2.0000e-04\n",
      "Epoch 27/100\n",
      "19/19 - 2s - 82ms/step - loss: 0.5787 - val_loss: 0.7047 - learning_rate: 4.0000e-05\n",
      "Epoch 28/100\n",
      "19/19 - 2s - 88ms/step - loss: 0.5769 - val_loss: 0.7245 - learning_rate: 4.0000e-05\n",
      "Epoch 29/100\n",
      "19/19 - 2s - 90ms/step - loss: 0.5774 - val_loss: 0.7268 - learning_rate: 4.0000e-05\n",
      "Epoch 30/100\n",
      "19/19 - 2s - 86ms/step - loss: 0.5793 - val_loss: 0.7224 - learning_rate: 4.0000e-05\n",
      "Epoch 31/100\n",
      "19/19 - 2s - 85ms/step - loss: 0.5756 - val_loss: 0.7160 - learning_rate: 4.0000e-05\n",
      "Epoch 32/100\n",
      "19/19 - 2s - 81ms/step - loss: 0.5793 - val_loss: 0.7022 - learning_rate: 4.0000e-05\n",
      "Epoch 33/100\n",
      "19/19 - 2s - 81ms/step - loss: 0.5804 - val_loss: 0.7365 - learning_rate: 4.0000e-05\n",
      "Epoch 34/100\n",
      "19/19 - 2s - 82ms/step - loss: 0.5807 - val_loss: 0.7103 - learning_rate: 4.0000e-05\n",
      "Epoch 35/100\n",
      "19/19 - 2s - 81ms/step - loss: 0.5801 - val_loss: 0.7342 - learning_rate: 4.0000e-05\n",
      "Epoch 36/100\n",
      "\n",
      "Epoch 36: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "19/19 - 2s - 81ms/step - loss: 0.5789 - val_loss: 0.7307 - learning_rate: 4.0000e-05\n",
      "Epoch 37/100\n",
      "19/19 - 2s - 82ms/step - loss: 0.5791 - val_loss: 0.7228 - learning_rate: 1.0000e-05\n",
      "Epoch 38/100\n",
      "19/19 - 2s - 81ms/step - loss: 0.5782 - val_loss: 0.7201 - learning_rate: 1.0000e-05\n",
      "Epoch 39/100\n",
      "19/19 - 2s - 83ms/step - loss: 0.5808 - val_loss: 0.7232 - learning_rate: 1.0000e-05\n",
      "Epoch 40/100\n",
      "19/19 - 2s - 81ms/step - loss: 0.5806 - val_loss: 0.7185 - learning_rate: 1.0000e-05\n",
      "Epoch 41/100\n",
      "19/19 - 2s - 82ms/step - loss: 0.5778 - val_loss: 0.7178 - learning_rate: 1.0000e-05\n",
      "Epoch 42/100\n",
      "19/19 - 2s - 81ms/step - loss: 0.5807 - val_loss: 0.7258 - learning_rate: 1.0000e-05\n",
      "Epoch 43/100\n",
      "19/19 - 2s - 81ms/step - loss: 0.5792 - val_loss: 0.7262 - learning_rate: 1.0000e-05\n",
      "Epoch 44/100\n",
      "19/19 - 2s - 82ms/step - loss: 0.5817 - val_loss: 0.7218 - learning_rate: 1.0000e-05\n",
      "Epoch 45/100\n",
      "19/19 - 2s - 81ms/step - loss: 0.5773 - val_loss: 0.7244 - learning_rate: 1.0000e-05\n",
      "Epoch 46/100\n",
      "19/19 - 2s - 82ms/step - loss: 0.5790 - val_loss: 0.7224 - learning_rate: 1.0000e-05\n",
      "Epoch 47/100\n",
      "19/19 - 2s - 81ms/step - loss: 0.5783 - val_loss: 0.7185 - learning_rate: 1.0000e-05\n",
      "Epoch 48/100\n",
      "19/19 - 2s - 81ms/step - loss: 0.5807 - val_loss: 0.7227 - learning_rate: 1.0000e-05\n",
      "Epoch 49/100\n",
      "19/19 - 2s - 81ms/step - loss: 0.5801 - val_loss: 0.7216 - learning_rate: 1.0000e-05\n",
      "Epoch 50/100\n",
      "19/19 - 2s - 82ms/step - loss: 0.5761 - val_loss: 0.7193 - learning_rate: 1.0000e-05\n",
      "Epoch 51/100\n",
      "19/19 - 2s - 86ms/step - loss: 0.5798 - val_loss: 0.7211 - learning_rate: 1.0000e-05\n",
      "Epoch 52/100\n",
      "19/19 - 2s - 89ms/step - loss: 0.5811 - val_loss: 0.7228 - learning_rate: 1.0000e-05\n",
      "Epoch 53/100\n",
      "19/19 - 2s - 82ms/step - loss: 0.5787 - val_loss: 0.7206 - learning_rate: 1.0000e-05\n",
      "Epoch 54/100\n",
      "19/19 - 2s - 81ms/step - loss: 0.5773 - val_loss: 0.7231 - learning_rate: 1.0000e-05\n",
      "Epoch 55/100\n",
      "19/19 - 2s - 82ms/step - loss: 0.5813 - val_loss: 0.7251 - learning_rate: 1.0000e-05\n",
      "Epoch 56/100\n",
      "19/19 - 2s - 84ms/step - loss: 0.5792 - val_loss: 0.7224 - learning_rate: 1.0000e-05\n",
      "Epoch 57/100\n",
      "19/19 - 2s - 81ms/step - loss: 0.5790 - val_loss: 0.7261 - learning_rate: 1.0000e-05\n",
      "Epoch 58/100\n",
      "19/19 - 2s - 82ms/step - loss: 0.5790 - val_loss: 0.7169 - learning_rate: 1.0000e-05\n",
      "Epoch 59/100\n",
      "19/19 - 2s - 81ms/step - loss: 0.5792 - val_loss: 0.7217 - learning_rate: 1.0000e-05\n",
      "Epoch 60/100\n",
      "19/19 - 2s - 81ms/step - loss: 0.5777 - val_loss: 0.7199 - learning_rate: 1.0000e-05\n",
      "Epoch 61/100\n",
      "19/19 - 2s - 81ms/step - loss: 0.5774 - val_loss: 0.7205 - learning_rate: 1.0000e-05\n",
      "Epoch 62/100\n",
      "19/19 - 2s - 81ms/step - loss: 0.5823 - val_loss: 0.7266 - learning_rate: 1.0000e-05\n",
      "Epoch 63/100\n",
      "19/19 - 2s - 81ms/step - loss: 0.5806 - val_loss: 0.7227 - learning_rate: 1.0000e-05\n",
      "Epoch 64/100\n",
      "19/19 - 2s - 81ms/step - loss: 0.5794 - val_loss: 0.7244 - learning_rate: 1.0000e-05\n",
      "Epoch 65/100\n",
      "19/19 - 2s - 80ms/step - loss: 0.5802 - val_loss: 0.7165 - learning_rate: 1.0000e-05\n",
      "Epoch 66/100\n",
      "19/19 - 2s - 82ms/step - loss: 0.5790 - val_loss: 0.7233 - learning_rate: 1.0000e-05\n",
      "Epoch 67/100\n",
      "19/19 - 2s - 81ms/step - loss: 0.5777 - val_loss: 0.7161 - learning_rate: 1.0000e-05\n",
      "Epoch 68/100\n",
      "19/19 - 2s - 83ms/step - loss: 0.5770 - val_loss: 0.7241 - learning_rate: 1.0000e-05\n",
      "Epoch 69/100\n",
      "19/19 - 2s - 81ms/step - loss: 0.5800 - val_loss: 0.7176 - learning_rate: 1.0000e-05\n",
      "Epoch 70/100\n",
      "19/19 - 2s - 81ms/step - loss: 0.5785 - val_loss: 0.7263 - learning_rate: 1.0000e-05\n",
      "Epoch 71/100\n",
      "19/19 - 2s - 81ms/step - loss: 0.5818 - val_loss: 0.7273 - learning_rate: 1.0000e-05\n",
      "Epoch 72/100\n",
      "19/19 - 2s - 82ms/step - loss: 0.5779 - val_loss: 0.7215 - learning_rate: 1.0000e-05\n",
      "Epoch 73/100\n",
      "19/19 - 2s - 89ms/step - loss: 0.5805 - val_loss: 0.7217 - learning_rate: 1.0000e-05\n",
      "Epoch 74/100\n",
      "19/19 - 2s - 88ms/step - loss: 0.5803 - val_loss: 0.7242 - learning_rate: 1.0000e-05\n",
      "Epoch 75/100\n",
      "19/19 - 2s - 85ms/step - loss: 0.5818 - val_loss: 0.7250 - learning_rate: 1.0000e-05\n",
      "Epoch 76/100\n",
      "19/19 - 2s - 83ms/step - loss: 0.5821 - val_loss: 0.7271 - learning_rate: 1.0000e-05\n",
      "Epoch 77/100\n",
      "19/19 - 2s - 87ms/step - loss: 0.5787 - val_loss: 0.7184 - learning_rate: 1.0000e-05\n",
      "Epoch 78/100\n",
      "19/19 - 2s - 83ms/step - loss: 0.5813 - val_loss: 0.7240 - learning_rate: 1.0000e-05\n",
      "Epoch 79/100\n",
      "19/19 - 2s - 82ms/step - loss: 0.5793 - val_loss: 0.7238 - learning_rate: 1.0000e-05\n",
      "Epoch 80/100\n",
      "19/19 - 2s - 81ms/step - loss: 0.5818 - val_loss: 0.7245 - learning_rate: 1.0000e-05\n",
      "Epoch 81/100\n",
      "19/19 - 2s - 82ms/step - loss: 0.5808 - val_loss: 0.7208 - learning_rate: 1.0000e-05\n",
      "Epoch 82/100\n",
      "19/19 - 2s - 81ms/step - loss: 0.5786 - val_loss: 0.7205 - learning_rate: 1.0000e-05\n",
      "Epoch 83/100\n",
      "19/19 - 2s - 82ms/step - loss: 0.5797 - val_loss: 0.7264 - learning_rate: 1.0000e-05\n",
      "Epoch 84/100\n",
      "19/19 - 2s - 81ms/step - loss: 0.5785 - val_loss: 0.7208 - learning_rate: 1.0000e-05\n",
      "Epoch 85/100\n",
      "19/19 - 2s - 82ms/step - loss: 0.5776 - val_loss: 0.7232 - learning_rate: 1.0000e-05\n",
      "Epoch 86/100\n",
      "19/19 - 2s - 82ms/step - loss: 0.5781 - val_loss: 0.7216 - learning_rate: 1.0000e-05\n",
      "Epoch 87/100\n",
      "19/19 - 2s - 81ms/step - loss: 0.5765 - val_loss: 0.7132 - learning_rate: 1.0000e-05\n",
      "Epoch 88/100\n",
      "19/19 - 2s - 81ms/step - loss: 0.5828 - val_loss: 0.7235 - learning_rate: 1.0000e-05\n",
      "Epoch 89/100\n",
      "19/19 - 2s - 82ms/step - loss: 0.5784 - val_loss: 0.7181 - learning_rate: 1.0000e-05\n",
      "Epoch 90/100\n",
      "19/19 - 2s - 83ms/step - loss: 0.5819 - val_loss: 0.7223 - learning_rate: 1.0000e-05\n",
      "Epoch 91/100\n",
      "19/19 - 2s - 82ms/step - loss: 0.5793 - val_loss: 0.7323 - learning_rate: 1.0000e-05\n",
      "Epoch 92/100\n",
      "19/19 - 2s - 83ms/step - loss: 0.5816 - val_loss: 0.7147 - learning_rate: 1.0000e-05\n",
      "Epoch 93/100\n",
      "19/19 - 2s - 90ms/step - loss: 0.5780 - val_loss: 0.7246 - learning_rate: 1.0000e-05\n",
      "Epoch 94/100\n",
      "19/19 - 2s - 83ms/step - loss: 0.5785 - val_loss: 0.7202 - learning_rate: 1.0000e-05\n",
      "Epoch 95/100\n",
      "19/19 - 2s - 81ms/step - loss: 0.5811 - val_loss: 0.7271 - learning_rate: 1.0000e-05\n",
      "Epoch 96/100\n",
      "19/19 - 2s - 82ms/step - loss: 0.5798 - val_loss: 0.7229 - learning_rate: 1.0000e-05\n",
      "Epoch 97/100\n",
      "19/19 - 2s - 85ms/step - loss: 0.5767 - val_loss: 0.7131 - learning_rate: 1.0000e-05\n",
      "Epoch 98/100\n",
      "19/19 - 2s - 83ms/step - loss: 0.5788 - val_loss: 0.7193 - learning_rate: 1.0000e-05\n",
      "Epoch 99/100\n",
      "19/19 - 2s - 81ms/step - loss: 0.5825 - val_loss: 0.7192 - learning_rate: 1.0000e-05\n",
      "Epoch 100/100\n",
      "19/19 - 2s - 81ms/step - loss: 0.5773 - val_loss: 0.7240 - learning_rate: 1.0000e-05\n",
      "Entrenando cluster numero: 9\n",
      "Epoch 1/100\n",
      "15/15 - 6s - 424ms/step - loss: 1.2718 - val_loss: 0.7579 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "15/15 - 1s - 82ms/step - loss: 0.7118 - val_loss: 0.5829 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "15/15 - 1s - 80ms/step - loss: 0.6751 - val_loss: 0.8932 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "15/15 - 1s - 81ms/step - loss: 0.6699 - val_loss: 1.1191 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "15/15 - 1s - 82ms/step - loss: 0.6718 - val_loss: 1.0095 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "15/15 - 1s - 85ms/step - loss: 0.6569 - val_loss: 0.8763 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "15/15 - 1s - 81ms/step - loss: 0.6656 - val_loss: 1.0168 - learning_rate: 0.0010\n",
      "Epoch 8/100\n",
      "15/15 - 1s - 87ms/step - loss: 0.6516 - val_loss: 0.8703 - learning_rate: 0.0010\n",
      "Epoch 9/100\n",
      "15/15 - 1s - 91ms/step - loss: 0.6608 - val_loss: 0.7811 - learning_rate: 0.0010\n",
      "Epoch 10/100\n",
      "15/15 - 1s - 79ms/step - loss: 0.6603 - val_loss: 1.0457 - learning_rate: 0.0010\n",
      "Epoch 11/100\n",
      "15/15 - 1s - 81ms/step - loss: 0.6548 - val_loss: 1.0670 - learning_rate: 0.0010\n",
      "Epoch 12/100\n",
      "\n",
      "Epoch 12: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "15/15 - 1s - 81ms/step - loss: 0.6569 - val_loss: 0.9931 - learning_rate: 0.0010\n",
      "Epoch 13/100\n",
      "15/15 - 1s - 80ms/step - loss: 0.6518 - val_loss: 0.9787 - learning_rate: 2.0000e-04\n",
      "Epoch 14/100\n",
      "15/15 - 1s - 80ms/step - loss: 0.6492 - val_loss: 0.9692 - learning_rate: 2.0000e-04\n",
      "Epoch 15/100\n",
      "15/15 - 1s - 81ms/step - loss: 0.6534 - val_loss: 0.9884 - learning_rate: 2.0000e-04\n",
      "Epoch 16/100\n",
      "15/15 - 1s - 80ms/step - loss: 0.6558 - val_loss: 1.0090 - learning_rate: 2.0000e-04\n",
      "Epoch 17/100\n",
      "15/15 - 1s - 80ms/step - loss: 0.6480 - val_loss: 0.9660 - learning_rate: 2.0000e-04\n",
      "Epoch 18/100\n",
      "15/15 - 1s - 82ms/step - loss: 0.6475 - val_loss: 0.9579 - learning_rate: 2.0000e-04\n",
      "Epoch 19/100\n",
      "15/15 - 1s - 80ms/step - loss: 0.6520 - val_loss: 1.0041 - learning_rate: 2.0000e-04\n",
      "Epoch 20/100\n",
      "15/15 - 1s - 81ms/step - loss: 0.6522 - val_loss: 0.9550 - learning_rate: 2.0000e-04\n",
      "Epoch 21/100\n",
      "15/15 - 1s - 83ms/step - loss: 0.6520 - val_loss: 0.9711 - learning_rate: 2.0000e-04\n",
      "Epoch 22/100\n",
      "\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "15/15 - 1s - 80ms/step - loss: 0.6504 - val_loss: 0.9290 - learning_rate: 2.0000e-04\n",
      "Epoch 23/100\n",
      "15/15 - 1s - 80ms/step - loss: 0.6502 - val_loss: 0.9416 - learning_rate: 4.0000e-05\n",
      "Epoch 24/100\n",
      "15/15 - 1s - 80ms/step - loss: 0.6487 - val_loss: 0.9824 - learning_rate: 4.0000e-05\n",
      "Epoch 25/100\n",
      "15/15 - 1s - 82ms/step - loss: 0.6487 - val_loss: 0.9781 - learning_rate: 4.0000e-05\n",
      "Epoch 26/100\n",
      "15/15 - 1s - 86ms/step - loss: 0.6429 - val_loss: 0.9714 - learning_rate: 4.0000e-05\n",
      "Epoch 27/100\n",
      "15/15 - 1s - 87ms/step - loss: 0.6482 - val_loss: 0.9891 - learning_rate: 4.0000e-05\n",
      "Epoch 28/100\n",
      "15/15 - 1s - 84ms/step - loss: 0.6503 - val_loss: 0.9784 - learning_rate: 4.0000e-05\n",
      "Epoch 29/100\n",
      "15/15 - 1s - 83ms/step - loss: 0.6443 - val_loss: 0.9765 - learning_rate: 4.0000e-05\n",
      "Epoch 30/100\n",
      "15/15 - 1s - 80ms/step - loss: 0.6492 - val_loss: 0.9828 - learning_rate: 4.0000e-05\n",
      "Epoch 31/100\n",
      "15/15 - 1s - 81ms/step - loss: 0.6487 - val_loss: 0.9775 - learning_rate: 4.0000e-05\n",
      "Epoch 32/100\n",
      "\n",
      "Epoch 32: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "15/15 - 1s - 82ms/step - loss: 0.6481 - val_loss: 0.9644 - learning_rate: 4.0000e-05\n",
      "Epoch 33/100\n",
      "15/15 - 1s - 79ms/step - loss: 0.6489 - val_loss: 0.9667 - learning_rate: 1.0000e-05\n",
      "Epoch 34/100\n",
      "15/15 - 1s - 83ms/step - loss: 0.6512 - val_loss: 0.9713 - learning_rate: 1.0000e-05\n",
      "Epoch 35/100\n",
      "15/15 - 1s - 81ms/step - loss: 0.6490 - val_loss: 0.9734 - learning_rate: 1.0000e-05\n",
      "Epoch 36/100\n",
      "15/15 - 1s - 80ms/step - loss: 0.6508 - val_loss: 0.9783 - learning_rate: 1.0000e-05\n",
      "Epoch 37/100\n",
      "15/15 - 1s - 81ms/step - loss: 0.6482 - val_loss: 0.9768 - learning_rate: 1.0000e-05\n",
      "Epoch 38/100\n",
      "15/15 - 1s - 83ms/step - loss: 0.6476 - val_loss: 0.9769 - learning_rate: 1.0000e-05\n",
      "Epoch 39/100\n",
      "15/15 - 1s - 80ms/step - loss: 0.6490 - val_loss: 0.9779 - learning_rate: 1.0000e-05\n",
      "Epoch 40/100\n",
      "15/15 - 1s - 81ms/step - loss: 0.6466 - val_loss: 0.9711 - learning_rate: 1.0000e-05\n",
      "Epoch 41/100\n",
      "15/15 - 1s - 80ms/step - loss: 0.6489 - val_loss: 0.9758 - learning_rate: 1.0000e-05\n",
      "Epoch 42/100\n",
      "15/15 - 1s - 82ms/step - loss: 0.6521 - val_loss: 0.9737 - learning_rate: 1.0000e-05\n",
      "Epoch 43/100\n",
      "15/15 - 1s - 80ms/step - loss: 0.6489 - val_loss: 0.9760 - learning_rate: 1.0000e-05\n",
      "Epoch 44/100\n",
      "15/15 - 1s - 80ms/step - loss: 0.6494 - val_loss: 0.9800 - learning_rate: 1.0000e-05\n",
      "Epoch 45/100\n",
      "15/15 - 1s - 80ms/step - loss: 0.6469 - val_loss: 0.9792 - learning_rate: 1.0000e-05\n",
      "Epoch 46/100\n",
      "15/15 - 1s - 83ms/step - loss: 0.6479 - val_loss: 0.9764 - learning_rate: 1.0000e-05\n",
      "Epoch 47/100\n",
      "15/15 - 1s - 84ms/step - loss: 0.6463 - val_loss: 0.9776 - learning_rate: 1.0000e-05\n",
      "Epoch 48/100\n",
      "15/15 - 1s - 84ms/step - loss: 0.6503 - val_loss: 0.9740 - learning_rate: 1.0000e-05\n",
      "Epoch 49/100\n",
      "15/15 - 1s - 80ms/step - loss: 0.6495 - val_loss: 0.9771 - learning_rate: 1.0000e-05\n",
      "Epoch 50/100\n",
      "15/15 - 1s - 81ms/step - loss: 0.6516 - val_loss: 0.9749 - learning_rate: 1.0000e-05\n",
      "Epoch 51/100\n",
      "15/15 - 1s - 80ms/step - loss: 0.6494 - val_loss: 0.9699 - learning_rate: 1.0000e-05\n",
      "Epoch 52/100\n",
      "15/15 - 1s - 80ms/step - loss: 0.6488 - val_loss: 0.9760 - learning_rate: 1.0000e-05\n",
      "Epoch 53/100\n",
      "15/15 - 1s - 81ms/step - loss: 0.6461 - val_loss: 0.9840 - learning_rate: 1.0000e-05\n",
      "Epoch 54/100\n",
      "15/15 - 1s - 81ms/step - loss: 0.6476 - val_loss: 0.9857 - learning_rate: 1.0000e-05\n",
      "Epoch 55/100\n",
      "15/15 - 1s - 81ms/step - loss: 0.6462 - val_loss: 0.9858 - learning_rate: 1.0000e-05\n",
      "Epoch 56/100\n",
      "15/15 - 1s - 81ms/step - loss: 0.6524 - val_loss: 0.9807 - learning_rate: 1.0000e-05\n",
      "Epoch 57/100\n",
      "15/15 - 1s - 80ms/step - loss: 0.6500 - val_loss: 0.9786 - learning_rate: 1.0000e-05\n",
      "Epoch 58/100\n",
      "15/15 - 1s - 81ms/step - loss: 0.6445 - val_loss: 0.9754 - learning_rate: 1.0000e-05\n",
      "Epoch 59/100\n",
      "15/15 - 1s - 81ms/step - loss: 0.6493 - val_loss: 0.9815 - learning_rate: 1.0000e-05\n",
      "Epoch 60/100\n",
      "15/15 - 1s - 81ms/step - loss: 0.6508 - val_loss: 0.9743 - learning_rate: 1.0000e-05\n",
      "Epoch 61/100\n",
      "15/15 - 1s - 81ms/step - loss: 0.6468 - val_loss: 0.9751 - learning_rate: 1.0000e-05\n",
      "Epoch 62/100\n",
      "15/15 - 1s - 81ms/step - loss: 0.6494 - val_loss: 0.9764 - learning_rate: 1.0000e-05\n",
      "Epoch 63/100\n",
      "15/15 - 1s - 81ms/step - loss: 0.6485 - val_loss: 0.9842 - learning_rate: 1.0000e-05\n",
      "Epoch 64/100\n",
      "15/15 - 1s - 82ms/step - loss: 0.6457 - val_loss: 0.9704 - learning_rate: 1.0000e-05\n",
      "Epoch 65/100\n",
      "15/15 - 1s - 82ms/step - loss: 0.6471 - val_loss: 0.9805 - learning_rate: 1.0000e-05\n",
      "Epoch 66/100\n",
      "15/15 - 1s - 85ms/step - loss: 0.6450 - val_loss: 0.9815 - learning_rate: 1.0000e-05\n",
      "Epoch 67/100\n",
      "15/15 - 1s - 87ms/step - loss: 0.6485 - val_loss: 0.9815 - learning_rate: 1.0000e-05\n",
      "Epoch 68/100\n",
      "15/15 - 1s - 82ms/step - loss: 0.6510 - val_loss: 0.9827 - learning_rate: 1.0000e-05\n",
      "Epoch 69/100\n",
      "15/15 - 1s - 83ms/step - loss: 0.6458 - val_loss: 0.9798 - learning_rate: 1.0000e-05\n",
      "Epoch 70/100\n",
      "15/15 - 1s - 81ms/step - loss: 0.6456 - val_loss: 0.9764 - learning_rate: 1.0000e-05\n",
      "Epoch 71/100\n",
      "15/15 - 1s - 79ms/step - loss: 0.6452 - val_loss: 0.9779 - learning_rate: 1.0000e-05\n",
      "Epoch 72/100\n",
      "15/15 - 1s - 80ms/step - loss: 0.6464 - val_loss: 0.9758 - learning_rate: 1.0000e-05\n",
      "Epoch 73/100\n",
      "15/15 - 1s - 80ms/step - loss: 0.6482 - val_loss: 0.9690 - learning_rate: 1.0000e-05\n",
      "Epoch 74/100\n",
      "15/15 - 1s - 80ms/step - loss: 0.6439 - val_loss: 0.9701 - learning_rate: 1.0000e-05\n",
      "Epoch 75/100\n",
      "15/15 - 1s - 85ms/step - loss: 0.6473 - val_loss: 0.9815 - learning_rate: 1.0000e-05\n",
      "Epoch 76/100\n",
      "15/15 - 1s - 83ms/step - loss: 0.6454 - val_loss: 0.9852 - learning_rate: 1.0000e-05\n",
      "Epoch 77/100\n",
      "15/15 - 1s - 81ms/step - loss: 0.6475 - val_loss: 0.9832 - learning_rate: 1.0000e-05\n",
      "Epoch 78/100\n",
      "15/15 - 1s - 80ms/step - loss: 0.6486 - val_loss: 0.9738 - learning_rate: 1.0000e-05\n",
      "Epoch 79/100\n",
      "15/15 - 1s - 80ms/step - loss: 0.6498 - val_loss: 0.9761 - learning_rate: 1.0000e-05\n",
      "Epoch 80/100\n",
      "15/15 - 1s - 80ms/step - loss: 0.6473 - val_loss: 0.9740 - learning_rate: 1.0000e-05\n",
      "Epoch 81/100\n",
      "15/15 - 1s - 81ms/step - loss: 0.6506 - val_loss: 0.9693 - learning_rate: 1.0000e-05\n",
      "Epoch 82/100\n",
      "15/15 - 1s - 80ms/step - loss: 0.6472 - val_loss: 0.9778 - learning_rate: 1.0000e-05\n",
      "Epoch 83/100\n",
      "15/15 - 1s - 82ms/step - loss: 0.6460 - val_loss: 0.9803 - learning_rate: 1.0000e-05\n",
      "Epoch 84/100\n",
      "15/15 - 1s - 86ms/step - loss: 0.6455 - val_loss: 0.9880 - learning_rate: 1.0000e-05\n",
      "Epoch 85/100\n",
      "15/15 - 1s - 85ms/step - loss: 0.6463 - val_loss: 0.9738 - learning_rate: 1.0000e-05\n",
      "Epoch 86/100\n",
      "15/15 - 1s - 80ms/step - loss: 0.6494 - val_loss: 0.9793 - learning_rate: 1.0000e-05\n",
      "Epoch 87/100\n",
      "15/15 - 1s - 80ms/step - loss: 0.6475 - val_loss: 0.9871 - learning_rate: 1.0000e-05\n",
      "Epoch 88/100\n",
      "15/15 - 1s - 82ms/step - loss: 0.6450 - val_loss: 0.9900 - learning_rate: 1.0000e-05\n",
      "Epoch 89/100\n",
      "15/15 - 1s - 80ms/step - loss: 0.6473 - val_loss: 0.9745 - learning_rate: 1.0000e-05\n",
      "Epoch 90/100\n",
      "15/15 - 1s - 81ms/step - loss: 0.6455 - val_loss: 0.9789 - learning_rate: 1.0000e-05\n",
      "Epoch 91/100\n",
      "15/15 - 1s - 80ms/step - loss: 0.6474 - val_loss: 0.9843 - learning_rate: 1.0000e-05\n",
      "Epoch 92/100\n",
      "15/15 - 1s - 80ms/step - loss: 0.6457 - val_loss: 0.9832 - learning_rate: 1.0000e-05\n",
      "Epoch 93/100\n",
      "15/15 - 1s - 82ms/step - loss: 0.6479 - val_loss: 0.9841 - learning_rate: 1.0000e-05\n",
      "Epoch 94/100\n",
      "15/15 - 1s - 80ms/step - loss: 0.6491 - val_loss: 0.9822 - learning_rate: 1.0000e-05\n",
      "Epoch 95/100\n",
      "15/15 - 1s - 81ms/step - loss: 0.6494 - val_loss: 0.9860 - learning_rate: 1.0000e-05\n",
      "Epoch 96/100\n",
      "15/15 - 1s - 84ms/step - loss: 0.6455 - val_loss: 0.9787 - learning_rate: 1.0000e-05\n",
      "Epoch 97/100\n",
      "15/15 - 1s - 80ms/step - loss: 0.6479 - val_loss: 0.9742 - learning_rate: 1.0000e-05\n",
      "Epoch 98/100\n",
      "15/15 - 1s - 82ms/step - loss: 0.6471 - val_loss: 0.9826 - learning_rate: 1.0000e-05\n",
      "Epoch 99/100\n",
      "15/15 - 1s - 80ms/step - loss: 0.6491 - val_loss: 0.9862 - learning_rate: 1.0000e-05\n",
      "Epoch 100/100\n",
      "15/15 - 1s - 81ms/step - loss: 0.6490 - val_loss: 0.9819 - learning_rate: 1.0000e-05\n",
      "Entrenando cluster numero: 10\n",
      "Epoch 1/100\n",
      "14/14 - 9s - 655ms/step - loss: 1.4008 - val_loss: 0.6574 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "14/14 - 1s - 102ms/step - loss: 0.6743 - val_loss: 0.7545 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "14/14 - 1s - 78ms/step - loss: 0.6178 - val_loss: 1.0302 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "14/14 - 1s - 85ms/step - loss: 0.6119 - val_loss: 0.9433 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "14/14 - 1s - 101ms/step - loss: 0.6059 - val_loss: 0.8820 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "14/14 - 1s - 93ms/step - loss: 0.6216 - val_loss: 0.9829 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "14/14 - 1s - 89ms/step - loss: 0.6072 - val_loss: 1.0489 - learning_rate: 0.0010\n",
      "Epoch 8/100\n",
      "14/14 - 1s - 84ms/step - loss: 0.6069 - val_loss: 0.9374 - learning_rate: 0.0010\n",
      "Epoch 9/100\n",
      "14/14 - 1s - 81ms/step - loss: 0.6117 - val_loss: 0.9643 - learning_rate: 0.0010\n",
      "Epoch 10/100\n",
      "14/14 - 1s - 79ms/step - loss: 0.5963 - val_loss: 1.0557 - learning_rate: 0.0010\n",
      "Epoch 11/100\n",
      "\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "14/14 - 1s - 97ms/step - loss: 0.6063 - val_loss: 1.1609 - learning_rate: 0.0010\n",
      "Epoch 12/100\n",
      "14/14 - 1s - 78ms/step - loss: 0.5992 - val_loss: 0.9660 - learning_rate: 2.0000e-04\n",
      "Epoch 13/100\n",
      "14/14 - 1s - 79ms/step - loss: 0.6007 - val_loss: 1.0812 - learning_rate: 2.0000e-04\n",
      "Epoch 14/100\n",
      "14/14 - 1s - 78ms/step - loss: 0.6017 - val_loss: 1.0447 - learning_rate: 2.0000e-04\n",
      "Epoch 15/100\n",
      "14/14 - 1s - 81ms/step - loss: 0.5978 - val_loss: 1.0868 - learning_rate: 2.0000e-04\n",
      "Epoch 16/100\n",
      "14/14 - 1s - 92ms/step - loss: 0.5982 - val_loss: 0.9719 - learning_rate: 2.0000e-04\n",
      "Epoch 17/100\n",
      "14/14 - 1s - 78ms/step - loss: 0.5991 - val_loss: 1.1142 - learning_rate: 2.0000e-04\n",
      "Epoch 18/100\n",
      "14/14 - 1s - 82ms/step - loss: 0.5924 - val_loss: 1.0116 - learning_rate: 2.0000e-04\n",
      "Epoch 19/100\n",
      "14/14 - 1s - 77ms/step - loss: 0.5995 - val_loss: 1.1151 - learning_rate: 2.0000e-04\n",
      "Epoch 20/100\n",
      "14/14 - 1s - 81ms/step - loss: 0.5949 - val_loss: 1.0046 - learning_rate: 2.0000e-04\n",
      "Epoch 21/100\n",
      "\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "14/14 - 1s - 83ms/step - loss: 0.5948 - val_loss: 1.1180 - learning_rate: 2.0000e-04\n",
      "Epoch 22/100\n",
      "14/14 - 1s - 78ms/step - loss: 0.5914 - val_loss: 1.0976 - learning_rate: 4.0000e-05\n",
      "Epoch 23/100\n",
      "14/14 - 1s - 78ms/step - loss: 0.5943 - val_loss: 1.0597 - learning_rate: 4.0000e-05\n",
      "Epoch 24/100\n",
      "14/14 - 1s - 78ms/step - loss: 0.5940 - val_loss: 1.0448 - learning_rate: 4.0000e-05\n",
      "Epoch 25/100\n",
      "14/14 - 1s - 91ms/step - loss: 0.5955 - val_loss: 1.0773 - learning_rate: 4.0000e-05\n",
      "Epoch 26/100\n",
      "14/14 - 1s - 78ms/step - loss: 0.5989 - val_loss: 1.0870 - learning_rate: 4.0000e-05\n",
      "Epoch 27/100\n",
      "14/14 - 1s - 90ms/step - loss: 0.5930 - val_loss: 1.0729 - learning_rate: 4.0000e-05\n",
      "Epoch 28/100\n",
      "14/14 - 1s - 87ms/step - loss: 0.5921 - val_loss: 1.0734 - learning_rate: 4.0000e-05\n",
      "Epoch 29/100\n",
      "14/14 - 1s - 79ms/step - loss: 0.5936 - val_loss: 1.0874 - learning_rate: 4.0000e-05\n",
      "Epoch 30/100\n",
      "14/14 - 1s - 78ms/step - loss: 0.5970 - val_loss: 1.0325 - learning_rate: 4.0000e-05\n",
      "Epoch 31/100\n",
      "\n",
      "Epoch 31: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "14/14 - 1s - 78ms/step - loss: 0.5932 - val_loss: 1.0804 - learning_rate: 4.0000e-05\n",
      "Epoch 32/100\n",
      "14/14 - 1s - 81ms/step - loss: 0.5932 - val_loss: 1.0771 - learning_rate: 1.0000e-05\n",
      "Epoch 33/100\n",
      "14/14 - 1s - 78ms/step - loss: 0.5876 - val_loss: 1.0681 - learning_rate: 1.0000e-05\n",
      "Epoch 34/100\n",
      "14/14 - 1s - 79ms/step - loss: 0.5952 - val_loss: 1.0736 - learning_rate: 1.0000e-05\n",
      "Epoch 35/100\n",
      "14/14 - 1s - 78ms/step - loss: 0.5965 - val_loss: 1.0604 - learning_rate: 1.0000e-05\n",
      "Epoch 36/100\n",
      "14/14 - 1s - 89ms/step - loss: 0.5916 - val_loss: 1.0540 - learning_rate: 1.0000e-05\n",
      "Epoch 37/100\n",
      "14/14 - 1s - 79ms/step - loss: 0.5931 - val_loss: 1.0538 - learning_rate: 1.0000e-05\n",
      "Epoch 38/100\n",
      "14/14 - 1s - 77ms/step - loss: 0.5906 - val_loss: 1.0653 - learning_rate: 1.0000e-05\n",
      "Epoch 39/100\n",
      "14/14 - 1s - 78ms/step - loss: 0.5946 - val_loss: 1.0606 - learning_rate: 1.0000e-05\n",
      "Epoch 40/100\n",
      "14/14 - 1s - 79ms/step - loss: 0.5936 - val_loss: 1.0626 - learning_rate: 1.0000e-05\n",
      "Epoch 41/100\n",
      "14/14 - 1s - 90ms/step - loss: 0.5912 - val_loss: 1.0571 - learning_rate: 1.0000e-05\n",
      "Epoch 42/100\n",
      "14/14 - 1s - 83ms/step - loss: 0.5961 - val_loss: 1.0587 - learning_rate: 1.0000e-05\n",
      "Epoch 43/100\n",
      "14/14 - 1s - 78ms/step - loss: 0.5933 - val_loss: 1.0592 - learning_rate: 1.0000e-05\n",
      "Epoch 44/100\n",
      "14/14 - 1s - 78ms/step - loss: 0.5948 - val_loss: 1.0601 - learning_rate: 1.0000e-05\n",
      "Epoch 45/100\n",
      "14/14 - 1s - 78ms/step - loss: 0.5926 - val_loss: 1.0748 - learning_rate: 1.0000e-05\n",
      "Epoch 46/100\n",
      "14/14 - 1s - 78ms/step - loss: 0.5965 - val_loss: 1.0740 - learning_rate: 1.0000e-05\n",
      "Epoch 47/100\n",
      "14/14 - 1s - 77ms/step - loss: 0.5949 - val_loss: 1.0723 - learning_rate: 1.0000e-05\n",
      "Epoch 48/100\n",
      "14/14 - 1s - 78ms/step - loss: 0.5925 - val_loss: 1.0559 - learning_rate: 1.0000e-05\n",
      "Epoch 49/100\n",
      "14/14 - 1s - 78ms/step - loss: 0.5949 - val_loss: 1.0552 - learning_rate: 1.0000e-05\n",
      "Epoch 50/100\n",
      "14/14 - 1s - 78ms/step - loss: 0.5890 - val_loss: 1.0618 - learning_rate: 1.0000e-05\n",
      "Epoch 51/100\n",
      "14/14 - 1s - 79ms/step - loss: 0.5975 - val_loss: 1.0657 - learning_rate: 1.0000e-05\n",
      "Epoch 52/100\n",
      "14/14 - 1s - 78ms/step - loss: 0.5953 - val_loss: 1.0617 - learning_rate: 1.0000e-05\n",
      "Epoch 53/100\n",
      "14/14 - 1s - 79ms/step - loss: 0.5946 - val_loss: 1.0560 - learning_rate: 1.0000e-05\n",
      "Epoch 54/100\n",
      "14/14 - 1s - 79ms/step - loss: 0.5907 - val_loss: 1.0624 - learning_rate: 1.0000e-05\n",
      "Epoch 55/100\n",
      "14/14 - 1s - 89ms/step - loss: 0.5961 - val_loss: 1.0560 - learning_rate: 1.0000e-05\n",
      "Epoch 56/100\n",
      "14/14 - 1s - 81ms/step - loss: 0.5890 - val_loss: 1.0494 - learning_rate: 1.0000e-05\n",
      "Epoch 57/100\n",
      "14/14 - 1s - 78ms/step - loss: 0.5910 - val_loss: 1.0408 - learning_rate: 1.0000e-05\n",
      "Epoch 58/100\n",
      "14/14 - 1s - 78ms/step - loss: 0.5936 - val_loss: 1.0372 - learning_rate: 1.0000e-05\n",
      "Epoch 59/100\n",
      "14/14 - 1s - 78ms/step - loss: 0.5966 - val_loss: 1.0492 - learning_rate: 1.0000e-05\n",
      "Epoch 60/100\n",
      "14/14 - 1s - 77ms/step - loss: 0.5982 - val_loss: 1.0548 - learning_rate: 1.0000e-05\n",
      "Epoch 61/100\n",
      "14/14 - 1s - 78ms/step - loss: 0.5922 - val_loss: 1.0644 - learning_rate: 1.0000e-05\n",
      "Epoch 62/100\n",
      "14/14 - 1s - 78ms/step - loss: 0.5952 - val_loss: 1.0647 - learning_rate: 1.0000e-05\n",
      "Epoch 63/100\n",
      "14/14 - 1s - 78ms/step - loss: 0.5967 - val_loss: 1.0643 - learning_rate: 1.0000e-05\n",
      "Epoch 64/100\n",
      "14/14 - 1s - 80ms/step - loss: 0.5898 - val_loss: 1.0647 - learning_rate: 1.0000e-05\n",
      "Epoch 65/100\n",
      "14/14 - 1s - 77ms/step - loss: 0.5942 - val_loss: 1.0708 - learning_rate: 1.0000e-05\n",
      "Epoch 66/100\n",
      "14/14 - 1s - 80ms/step - loss: 0.5914 - val_loss: 1.0724 - learning_rate: 1.0000e-05\n",
      "Epoch 67/100\n",
      "14/14 - 1s - 77ms/step - loss: 0.5926 - val_loss: 1.0666 - learning_rate: 1.0000e-05\n",
      "Epoch 68/100\n",
      "14/14 - 1s - 78ms/step - loss: 0.5901 - val_loss: 1.0693 - learning_rate: 1.0000e-05\n",
      "Epoch 69/100\n",
      "14/14 - 1s - 85ms/step - loss: 0.5930 - val_loss: 1.0541 - learning_rate: 1.0000e-05\n",
      "Epoch 70/100\n",
      "14/14 - 1s - 83ms/step - loss: 0.5888 - val_loss: 1.0529 - learning_rate: 1.0000e-05\n",
      "Epoch 71/100\n",
      "14/14 - 1s - 77ms/step - loss: 0.5951 - val_loss: 1.0700 - learning_rate: 1.0000e-05\n",
      "Epoch 72/100\n",
      "14/14 - 1s - 79ms/step - loss: 0.5953 - val_loss: 1.0677 - learning_rate: 1.0000e-05\n",
      "Epoch 73/100\n",
      "14/14 - 1s - 78ms/step - loss: 0.5966 - val_loss: 1.0738 - learning_rate: 1.0000e-05\n",
      "Epoch 74/100\n",
      "14/14 - 1s - 78ms/step - loss: 0.5889 - val_loss: 1.0740 - learning_rate: 1.0000e-05\n",
      "Epoch 75/100\n",
      "14/14 - 1s - 77ms/step - loss: 0.5938 - val_loss: 1.0645 - learning_rate: 1.0000e-05\n",
      "Epoch 76/100\n",
      "14/14 - 1s - 77ms/step - loss: 0.5944 - val_loss: 1.0610 - learning_rate: 1.0000e-05\n",
      "Epoch 77/100\n",
      "14/14 - 1s - 78ms/step - loss: 0.5967 - val_loss: 1.0559 - learning_rate: 1.0000e-05\n",
      "Epoch 78/100\n",
      "14/14 - 1s - 78ms/step - loss: 0.5932 - val_loss: 1.0480 - learning_rate: 1.0000e-05\n",
      "Epoch 79/100\n",
      "14/14 - 1s - 79ms/step - loss: 0.5894 - val_loss: 1.0606 - learning_rate: 1.0000e-05\n",
      "Epoch 80/100\n",
      "14/14 - 1s - 78ms/step - loss: 0.5927 - val_loss: 1.0543 - learning_rate: 1.0000e-05\n",
      "Epoch 81/100\n",
      "14/14 - 1s - 78ms/step - loss: 0.5911 - val_loss: 1.0527 - learning_rate: 1.0000e-05\n",
      "Epoch 82/100\n",
      "14/14 - 1s - 86ms/step - loss: 0.5977 - val_loss: 1.0471 - learning_rate: 1.0000e-05\n",
      "Epoch 83/100\n",
      "14/14 - 1s - 85ms/step - loss: 0.5926 - val_loss: 1.0560 - learning_rate: 1.0000e-05\n",
      "Epoch 84/100\n",
      "14/14 - 1s - 79ms/step - loss: 0.5969 - val_loss: 1.0641 - learning_rate: 1.0000e-05\n",
      "Epoch 85/100\n",
      "14/14 - 1s - 79ms/step - loss: 0.5945 - val_loss: 1.0679 - learning_rate: 1.0000e-05\n",
      "Epoch 86/100\n",
      "14/14 - 1s - 78ms/step - loss: 0.5941 - val_loss: 1.0758 - learning_rate: 1.0000e-05\n",
      "Epoch 87/100\n",
      "14/14 - 1s - 79ms/step - loss: 0.5922 - val_loss: 1.0633 - learning_rate: 1.0000e-05\n",
      "Epoch 88/100\n",
      "14/14 - 1s - 78ms/step - loss: 0.5907 - val_loss: 1.0518 - learning_rate: 1.0000e-05\n",
      "Epoch 89/100\n",
      "14/14 - 1s - 78ms/step - loss: 0.5940 - val_loss: 1.0591 - learning_rate: 1.0000e-05\n",
      "Epoch 90/100\n",
      "14/14 - 1s - 78ms/step - loss: 0.5897 - val_loss: 1.0462 - learning_rate: 1.0000e-05\n",
      "Epoch 91/100\n",
      "14/14 - 1s - 79ms/step - loss: 0.5930 - val_loss: 1.0385 - learning_rate: 1.0000e-05\n",
      "Epoch 92/100\n",
      "14/14 - 1s - 78ms/step - loss: 0.5963 - val_loss: 1.0377 - learning_rate: 1.0000e-05\n",
      "Epoch 93/100\n",
      "14/14 - 1s - 79ms/step - loss: 0.5930 - val_loss: 1.0596 - learning_rate: 1.0000e-05\n",
      "Epoch 94/100\n",
      "14/14 - 1s - 78ms/step - loss: 0.5915 - val_loss: 1.0849 - learning_rate: 1.0000e-05\n",
      "Epoch 95/100\n",
      "14/14 - 1s - 78ms/step - loss: 0.5929 - val_loss: 1.0745 - learning_rate: 1.0000e-05\n",
      "Epoch 96/100\n",
      "14/14 - 1s - 87ms/step - loss: 0.5951 - val_loss: 1.0841 - learning_rate: 1.0000e-05\n",
      "Epoch 97/100\n",
      "14/14 - 1s - 80ms/step - loss: 0.5955 - val_loss: 1.0813 - learning_rate: 1.0000e-05\n",
      "Epoch 98/100\n",
      "14/14 - 1s - 77ms/step - loss: 0.5895 - val_loss: 1.0825 - learning_rate: 1.0000e-05\n",
      "Epoch 99/100\n",
      "14/14 - 1s - 77ms/step - loss: 0.5973 - val_loss: 1.0767 - learning_rate: 1.0000e-05\n",
      "Epoch 100/100\n",
      "14/14 - 1s - 78ms/step - loss: 0.5959 - val_loss: 1.0741 - learning_rate: 1.0000e-05\n",
      "Entrenando cluster numero: 11\n",
      "Epoch 1/100\n",
      "9/9 - 7s - 815ms/step - loss: 1.4195 - val_loss: 0.3227 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "9/9 - 1s - 83ms/step - loss: 0.7880 - val_loss: 1.4688 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "9/9 - 1s - 84ms/step - loss: 0.7225 - val_loss: 0.5324 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "9/9 - 1s - 80ms/step - loss: 0.7004 - val_loss: 1.0117 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "9/9 - 1s - 81ms/step - loss: 0.6813 - val_loss: 0.6861 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "9/9 - 1s - 84ms/step - loss: 0.6756 - val_loss: 0.9378 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "9/9 - 1s - 81ms/step - loss: 0.6660 - val_loss: 0.8255 - learning_rate: 0.0010\n",
      "Epoch 8/100\n",
      "9/9 - 1s - 80ms/step - loss: 0.6529 - val_loss: 0.8216 - learning_rate: 0.0010\n",
      "Epoch 9/100\n",
      "9/9 - 1s - 80ms/step - loss: 0.6643 - val_loss: 0.9510 - learning_rate: 0.0010\n",
      "Epoch 10/100\n",
      "9/9 - 1s - 81ms/step - loss: 0.6710 - val_loss: 0.8457 - learning_rate: 0.0010\n",
      "Epoch 11/100\n",
      "\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "9/9 - 1s - 81ms/step - loss: 0.6638 - val_loss: 0.9207 - learning_rate: 0.0010\n",
      "Epoch 12/100\n",
      "9/9 - 1s - 83ms/step - loss: 0.6663 - val_loss: 0.9082 - learning_rate: 2.0000e-04\n",
      "Epoch 13/100\n",
      "9/9 - 1s - 81ms/step - loss: 0.6730 - val_loss: 0.8725 - learning_rate: 2.0000e-04\n",
      "Epoch 14/100\n",
      "9/9 - 1s - 83ms/step - loss: 0.6542 - val_loss: 0.8142 - learning_rate: 2.0000e-04\n",
      "Epoch 15/100\n",
      "9/9 - 1s - 84ms/step - loss: 0.6561 - val_loss: 0.8686 - learning_rate: 2.0000e-04\n",
      "Epoch 16/100\n",
      "9/9 - 1s - 81ms/step - loss: 0.6588 - val_loss: 0.9076 - learning_rate: 2.0000e-04\n",
      "Epoch 17/100\n",
      "9/9 - 1s - 82ms/step - loss: 0.6640 - val_loss: 0.8777 - learning_rate: 2.0000e-04\n",
      "Epoch 18/100\n",
      "9/9 - 1s - 82ms/step - loss: 0.6555 - val_loss: 0.8520 - learning_rate: 2.0000e-04\n",
      "Epoch 19/100\n",
      "9/9 - 1s - 81ms/step - loss: 0.6638 - val_loss: 0.8674 - learning_rate: 2.0000e-04\n",
      "Epoch 20/100\n",
      "9/9 - 1s - 81ms/step - loss: 0.6681 - val_loss: 0.8455 - learning_rate: 2.0000e-04\n",
      "Epoch 21/100\n",
      "\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "9/9 - 1s - 83ms/step - loss: 0.6575 - val_loss: 0.8463 - learning_rate: 2.0000e-04\n",
      "Epoch 22/100\n",
      "9/9 - 1s - 82ms/step - loss: 0.6601 - val_loss: 0.8564 - learning_rate: 4.0000e-05\n",
      "Epoch 23/100\n",
      "9/9 - 1s - 84ms/step - loss: 0.6539 - val_loss: 0.8608 - learning_rate: 4.0000e-05\n",
      "Epoch 24/100\n",
      "9/9 - 1s - 80ms/step - loss: 0.6611 - val_loss: 0.8806 - learning_rate: 4.0000e-05\n",
      "Epoch 25/100\n",
      "9/9 - 1s - 81ms/step - loss: 0.6598 - val_loss: 0.8830 - learning_rate: 4.0000e-05\n",
      "Epoch 26/100\n",
      "9/9 - 1s - 83ms/step - loss: 0.6583 - val_loss: 0.8786 - learning_rate: 4.0000e-05\n",
      "Epoch 27/100\n",
      "9/9 - 1s - 83ms/step - loss: 0.6619 - val_loss: 0.8806 - learning_rate: 4.0000e-05\n",
      "Epoch 28/100\n",
      "9/9 - 1s - 81ms/step - loss: 0.6586 - val_loss: 0.8869 - learning_rate: 4.0000e-05\n",
      "Epoch 29/100\n",
      "9/9 - 1s - 82ms/step - loss: 0.6589 - val_loss: 0.8672 - learning_rate: 4.0000e-05\n",
      "Epoch 30/100\n",
      "9/9 - 1s - 81ms/step - loss: 0.6553 - val_loss: 0.8718 - learning_rate: 4.0000e-05\n",
      "Epoch 31/100\n",
      "\n",
      "Epoch 31: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "9/9 - 1s - 85ms/step - loss: 0.6602 - val_loss: 0.8797 - learning_rate: 4.0000e-05\n",
      "Epoch 32/100\n",
      "9/9 - 1s - 81ms/step - loss: 0.6615 - val_loss: 0.8797 - learning_rate: 1.0000e-05\n",
      "Epoch 33/100\n",
      "9/9 - 1s - 80ms/step - loss: 0.6620 - val_loss: 0.8781 - learning_rate: 1.0000e-05\n",
      "Epoch 34/100\n",
      "9/9 - 1s - 85ms/step - loss: 0.6600 - val_loss: 0.8760 - learning_rate: 1.0000e-05\n",
      "Epoch 35/100\n",
      "9/9 - 1s - 82ms/step - loss: 0.6567 - val_loss: 0.8780 - learning_rate: 1.0000e-05\n",
      "Epoch 36/100\n",
      "9/9 - 1s - 81ms/step - loss: 0.6562 - val_loss: 0.8727 - learning_rate: 1.0000e-05\n",
      "Epoch 37/100\n",
      "9/9 - 1s - 84ms/step - loss: 0.6642 - val_loss: 0.8718 - learning_rate: 1.0000e-05\n",
      "Epoch 38/100\n",
      "9/9 - 1s - 80ms/step - loss: 0.6581 - val_loss: 0.8704 - learning_rate: 1.0000e-05\n",
      "Epoch 39/100\n",
      "9/9 - 1s - 80ms/step - loss: 0.6631 - val_loss: 0.8719 - learning_rate: 1.0000e-05\n",
      "Epoch 40/100\n",
      "9/9 - 1s - 81ms/step - loss: 0.6574 - val_loss: 0.8742 - learning_rate: 1.0000e-05\n",
      "Epoch 41/100\n",
      "9/9 - 1s - 82ms/step - loss: 0.6644 - val_loss: 0.8739 - learning_rate: 1.0000e-05\n",
      "Epoch 42/100\n",
      "9/9 - 1s - 81ms/step - loss: 0.6647 - val_loss: 0.8715 - learning_rate: 1.0000e-05\n",
      "Epoch 43/100\n",
      "9/9 - 1s - 82ms/step - loss: 0.6554 - val_loss: 0.8694 - learning_rate: 1.0000e-05\n",
      "Epoch 44/100\n",
      "9/9 - 1s - 86ms/step - loss: 0.6553 - val_loss: 0.8735 - learning_rate: 1.0000e-05\n",
      "Epoch 45/100\n",
      "9/9 - 1s - 82ms/step - loss: 0.6539 - val_loss: 0.8705 - learning_rate: 1.0000e-05\n",
      "Epoch 46/100\n",
      "9/9 - 1s - 83ms/step - loss: 0.6533 - val_loss: 0.8730 - learning_rate: 1.0000e-05\n",
      "Epoch 47/100\n",
      "9/9 - 1s - 80ms/step - loss: 0.6653 - val_loss: 0.8723 - learning_rate: 1.0000e-05\n",
      "Epoch 48/100\n",
      "9/9 - 1s - 82ms/step - loss: 0.6578 - val_loss: 0.8773 - learning_rate: 1.0000e-05\n",
      "Epoch 49/100\n",
      "9/9 - 1s - 80ms/step - loss: 0.6585 - val_loss: 0.8729 - learning_rate: 1.0000e-05\n",
      "Epoch 50/100\n",
      "9/9 - 1s - 81ms/step - loss: 0.6599 - val_loss: 0.8748 - learning_rate: 1.0000e-05\n",
      "Epoch 51/100\n",
      "9/9 - 1s - 81ms/step - loss: 0.6508 - val_loss: 0.8720 - learning_rate: 1.0000e-05\n",
      "Epoch 52/100\n",
      "9/9 - 1s - 80ms/step - loss: 0.6558 - val_loss: 0.8744 - learning_rate: 1.0000e-05\n",
      "Epoch 53/100\n",
      "9/9 - 1s - 82ms/step - loss: 0.6593 - val_loss: 0.8726 - learning_rate: 1.0000e-05\n",
      "Epoch 54/100\n",
      "9/9 - 1s - 83ms/step - loss: 0.6587 - val_loss: 0.8730 - learning_rate: 1.0000e-05\n",
      "Epoch 55/100\n",
      "9/9 - 1s - 81ms/step - loss: 0.6500 - val_loss: 0.8756 - learning_rate: 1.0000e-05\n",
      "Epoch 56/100\n",
      "9/9 - 1s - 84ms/step - loss: 0.6590 - val_loss: 0.8714 - learning_rate: 1.0000e-05\n",
      "Epoch 57/100\n",
      "9/9 - 1s - 81ms/step - loss: 0.6562 - val_loss: 0.8744 - learning_rate: 1.0000e-05\n",
      "Epoch 58/100\n",
      "9/9 - 1s - 82ms/step - loss: 0.6548 - val_loss: 0.8732 - learning_rate: 1.0000e-05\n",
      "Epoch 59/100\n",
      "9/9 - 1s - 82ms/step - loss: 0.6637 - val_loss: 0.8757 - learning_rate: 1.0000e-05\n",
      "Epoch 60/100\n",
      "9/9 - 1s - 81ms/step - loss: 0.6571 - val_loss: 0.8786 - learning_rate: 1.0000e-05\n",
      "Epoch 61/100\n",
      "9/9 - 1s - 84ms/step - loss: 0.6607 - val_loss: 0.8799 - learning_rate: 1.0000e-05\n",
      "Epoch 62/100\n",
      "9/9 - 1s - 80ms/step - loss: 0.6584 - val_loss: 0.8805 - learning_rate: 1.0000e-05\n",
      "Epoch 63/100\n",
      "9/9 - 1s - 88ms/step - loss: 0.6541 - val_loss: 0.8774 - learning_rate: 1.0000e-05\n",
      "Epoch 64/100\n",
      "9/9 - 1s - 88ms/step - loss: 0.6608 - val_loss: 0.8781 - learning_rate: 1.0000e-05\n",
      "Epoch 65/100\n",
      "9/9 - 1s - 87ms/step - loss: 0.6643 - val_loss: 0.8743 - learning_rate: 1.0000e-05\n",
      "Epoch 66/100\n",
      "9/9 - 1s - 81ms/step - loss: 0.6570 - val_loss: 0.8771 - learning_rate: 1.0000e-05\n",
      "Epoch 67/100\n",
      "9/9 - 1s - 81ms/step - loss: 0.6544 - val_loss: 0.8747 - learning_rate: 1.0000e-05\n",
      "Epoch 68/100\n",
      "9/9 - 1s - 83ms/step - loss: 0.6621 - val_loss: 0.8746 - learning_rate: 1.0000e-05\n",
      "Epoch 69/100\n",
      "9/9 - 1s - 80ms/step - loss: 0.6571 - val_loss: 0.8736 - learning_rate: 1.0000e-05\n",
      "Epoch 70/100\n",
      "9/9 - 1s - 80ms/step - loss: 0.6608 - val_loss: 0.8735 - learning_rate: 1.0000e-05\n",
      "Epoch 71/100\n",
      "9/9 - 1s - 84ms/step - loss: 0.6579 - val_loss: 0.8733 - learning_rate: 1.0000e-05\n",
      "Epoch 72/100\n",
      "9/9 - 1s - 82ms/step - loss: 0.6613 - val_loss: 0.8783 - learning_rate: 1.0000e-05\n",
      "Epoch 73/100\n",
      "9/9 - 1s - 81ms/step - loss: 0.6575 - val_loss: 0.8809 - learning_rate: 1.0000e-05\n",
      "Epoch 74/100\n",
      "9/9 - 1s - 84ms/step - loss: 0.6612 - val_loss: 0.8760 - learning_rate: 1.0000e-05\n",
      "Epoch 75/100\n",
      "9/9 - 1s - 81ms/step - loss: 0.6630 - val_loss: 0.8724 - learning_rate: 1.0000e-05\n",
      "Epoch 76/100\n",
      "9/9 - 1s - 80ms/step - loss: 0.6567 - val_loss: 0.8722 - learning_rate: 1.0000e-05\n",
      "Epoch 77/100\n",
      "9/9 - 1s - 81ms/step - loss: 0.6531 - val_loss: 0.8766 - learning_rate: 1.0000e-05\n",
      "Epoch 78/100\n",
      "9/9 - 1s - 82ms/step - loss: 0.6561 - val_loss: 0.8737 - learning_rate: 1.0000e-05\n",
      "Epoch 79/100\n",
      "9/9 - 1s - 83ms/step - loss: 0.6546 - val_loss: 0.8753 - learning_rate: 1.0000e-05\n",
      "Epoch 80/100\n",
      "9/9 - 1s - 81ms/step - loss: 0.6532 - val_loss: 0.8734 - learning_rate: 1.0000e-05\n",
      "Epoch 81/100\n",
      "9/9 - 1s - 82ms/step - loss: 0.6580 - val_loss: 0.8728 - learning_rate: 1.0000e-05\n",
      "Epoch 82/100\n",
      "9/9 - 1s - 81ms/step - loss: 0.6536 - val_loss: 0.8789 - learning_rate: 1.0000e-05\n",
      "Epoch 83/100\n",
      "9/9 - 1s - 80ms/step - loss: 0.6567 - val_loss: 0.8788 - learning_rate: 1.0000e-05\n",
      "Epoch 84/100\n",
      "9/9 - 1s - 81ms/step - loss: 0.6598 - val_loss: 0.8770 - learning_rate: 1.0000e-05\n",
      "Epoch 85/100\n",
      "9/9 - 1s - 81ms/step - loss: 0.6573 - val_loss: 0.8717 - learning_rate: 1.0000e-05\n",
      "Epoch 86/100\n",
      "9/9 - 1s - 83ms/step - loss: 0.6551 - val_loss: 0.8792 - learning_rate: 1.0000e-05\n",
      "Epoch 87/100\n",
      "9/9 - 1s - 83ms/step - loss: 0.6588 - val_loss: 0.8776 - learning_rate: 1.0000e-05\n",
      "Epoch 88/100\n",
      "9/9 - 1s - 81ms/step - loss: 0.6539 - val_loss: 0.8804 - learning_rate: 1.0000e-05\n",
      "Epoch 89/100\n",
      "9/9 - 1s - 81ms/step - loss: 0.6565 - val_loss: 0.8764 - learning_rate: 1.0000e-05\n",
      "Epoch 90/100\n",
      "9/9 - 1s - 81ms/step - loss: 0.6554 - val_loss: 0.8774 - learning_rate: 1.0000e-05\n",
      "Epoch 91/100\n",
      "9/9 - 1s - 84ms/step - loss: 0.6611 - val_loss: 0.8729 - learning_rate: 1.0000e-05\n",
      "Epoch 92/100\n",
      "9/9 - 1s - 81ms/step - loss: 0.6651 - val_loss: 0.8741 - learning_rate: 1.0000e-05\n",
      "Epoch 93/100\n",
      "9/9 - 1s - 80ms/step - loss: 0.6615 - val_loss: 0.8796 - learning_rate: 1.0000e-05\n",
      "Epoch 94/100\n",
      "9/9 - 1s - 83ms/step - loss: 0.6611 - val_loss: 0.8765 - learning_rate: 1.0000e-05\n",
      "Epoch 95/100\n",
      "9/9 - 1s - 81ms/step - loss: 0.6544 - val_loss: 0.8784 - learning_rate: 1.0000e-05\n",
      "Epoch 96/100\n",
      "9/9 - 1s - 84ms/step - loss: 0.6513 - val_loss: 0.8816 - learning_rate: 1.0000e-05\n",
      "Epoch 97/100\n",
      "9/9 - 1s - 81ms/step - loss: 0.6596 - val_loss: 0.8769 - learning_rate: 1.0000e-05\n",
      "Epoch 98/100\n",
      "9/9 - 1s - 82ms/step - loss: 0.6549 - val_loss: 0.8805 - learning_rate: 1.0000e-05\n",
      "Epoch 99/100\n",
      "9/9 - 1s - 82ms/step - loss: 0.6571 - val_loss: 0.8800 - learning_rate: 1.0000e-05\n",
      "Epoch 100/100\n",
      "9/9 - 1s - 80ms/step - loss: 0.6581 - val_loss: 0.8825 - learning_rate: 1.0000e-05\n",
      "Entrenando cluster numero: 12\n",
      "Epoch 1/100\n",
      "30/30 - 9s - 313ms/step - loss: 0.9175 - val_loss: 0.8645 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "30/30 - 2s - 81ms/step - loss: 0.6429 - val_loss: 0.9137 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "30/30 - 2s - 81ms/step - loss: 0.6460 - val_loss: 1.1054 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "30/30 - 2s - 81ms/step - loss: 0.6305 - val_loss: 0.8160 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "30/30 - 3s - 86ms/step - loss: 0.6304 - val_loss: 0.9234 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "30/30 - 2s - 82ms/step - loss: 0.6238 - val_loss: 0.9179 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "30/30 - 3s - 87ms/step - loss: 0.6232 - val_loss: 0.7021 - learning_rate: 0.0010\n",
      "Epoch 8/100\n",
      "30/30 - 2s - 82ms/step - loss: 0.6261 - val_loss: 1.0080 - learning_rate: 0.0010\n",
      "Epoch 9/100\n",
      "30/30 - 2s - 80ms/step - loss: 0.6275 - val_loss: 0.9270 - learning_rate: 0.0010\n",
      "Epoch 10/100\n",
      "30/30 - 2s - 80ms/step - loss: 0.6265 - val_loss: 0.8747 - learning_rate: 0.0010\n",
      "Epoch 11/100\n",
      "30/30 - 2s - 80ms/step - loss: 0.6338 - val_loss: 0.7590 - learning_rate: 0.0010\n",
      "Epoch 12/100\n",
      "30/30 - 2s - 80ms/step - loss: 0.6246 - val_loss: 0.7197 - learning_rate: 0.0010\n",
      "Epoch 13/100\n",
      "30/30 - 2s - 80ms/step - loss: 0.6263 - val_loss: 0.8434 - learning_rate: 0.0010\n",
      "Epoch 14/100\n",
      "30/30 - 2s - 79ms/step - loss: 0.6221 - val_loss: 0.9521 - learning_rate: 0.0010\n",
      "Epoch 15/100\n",
      "30/30 - 2s - 80ms/step - loss: 0.6273 - val_loss: 1.0563 - learning_rate: 0.0010\n",
      "Epoch 16/100\n",
      "30/30 - 2s - 79ms/step - loss: 0.6266 - val_loss: 0.9097 - learning_rate: 0.0010\n",
      "Epoch 17/100\n",
      "\n",
      "Epoch 17: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "30/30 - 3s - 84ms/step - loss: 0.6240 - val_loss: 0.9822 - learning_rate: 0.0010\n",
      "Epoch 18/100\n",
      "30/30 - 2s - 82ms/step - loss: 0.6199 - val_loss: 0.9208 - learning_rate: 2.0000e-04\n",
      "Epoch 19/100\n",
      "30/30 - 2s - 80ms/step - loss: 0.6181 - val_loss: 0.9144 - learning_rate: 2.0000e-04\n",
      "Epoch 20/100\n",
      "30/30 - 2s - 80ms/step - loss: 0.6174 - val_loss: 0.8136 - learning_rate: 2.0000e-04\n",
      "Epoch 21/100\n",
      "30/30 - 2s - 80ms/step - loss: 0.6181 - val_loss: 0.9568 - learning_rate: 2.0000e-04\n",
      "Epoch 22/100\n",
      "30/30 - 2s - 80ms/step - loss: 0.6198 - val_loss: 0.8354 - learning_rate: 2.0000e-04\n",
      "Epoch 23/100\n",
      "30/30 - 2s - 80ms/step - loss: 0.6201 - val_loss: 0.9893 - learning_rate: 2.0000e-04\n",
      "Epoch 24/100\n",
      "30/30 - 2s - 80ms/step - loss: 0.6205 - val_loss: 0.8548 - learning_rate: 2.0000e-04\n",
      "Epoch 25/100\n",
      "30/30 - 2s - 80ms/step - loss: 0.6176 - val_loss: 0.9723 - learning_rate: 2.0000e-04\n",
      "Epoch 26/100\n",
      "30/30 - 2s - 81ms/step - loss: 0.6172 - val_loss: 0.9911 - learning_rate: 2.0000e-04\n",
      "Epoch 27/100\n",
      "\n",
      "Epoch 27: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "30/30 - 2s - 79ms/step - loss: 0.6186 - val_loss: 0.8801 - learning_rate: 2.0000e-04\n",
      "Epoch 28/100\n",
      "30/30 - 2s - 80ms/step - loss: 0.6177 - val_loss: 0.9214 - learning_rate: 4.0000e-05\n",
      "Epoch 29/100\n",
      "30/30 - 2s - 80ms/step - loss: 0.6175 - val_loss: 0.9212 - learning_rate: 4.0000e-05\n",
      "Epoch 30/100\n",
      "30/30 - 3s - 85ms/step - loss: 0.6149 - val_loss: 0.9302 - learning_rate: 4.0000e-05\n",
      "Epoch 31/100\n",
      "30/30 - 2s - 80ms/step - loss: 0.6180 - val_loss: 0.9255 - learning_rate: 4.0000e-05\n",
      "Epoch 32/100\n",
      "30/30 - 2s - 80ms/step - loss: 0.6188 - val_loss: 0.9354 - learning_rate: 4.0000e-05\n",
      "Epoch 33/100\n",
      "30/30 - 2s - 80ms/step - loss: 0.6181 - val_loss: 0.9123 - learning_rate: 4.0000e-05\n",
      "Epoch 34/100\n",
      "30/30 - 2s - 80ms/step - loss: 0.6152 - val_loss: 0.9270 - learning_rate: 4.0000e-05\n",
      "Epoch 35/100\n",
      "30/30 - 2s - 80ms/step - loss: 0.6179 - val_loss: 0.9207 - learning_rate: 4.0000e-05\n",
      "Epoch 36/100\n",
      "30/30 - 2s - 81ms/step - loss: 0.6164 - val_loss: 0.9379 - learning_rate: 4.0000e-05\n",
      "Epoch 37/100\n",
      "\n",
      "Epoch 37: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "30/30 - 2s - 81ms/step - loss: 0.6171 - val_loss: 0.9178 - learning_rate: 4.0000e-05\n",
      "Epoch 38/100\n",
      "30/30 - 2s - 80ms/step - loss: 0.6167 - val_loss: 0.9202 - learning_rate: 1.0000e-05\n",
      "Epoch 39/100\n",
      "30/30 - 2s - 83ms/step - loss: 0.6199 - val_loss: 0.9237 - learning_rate: 1.0000e-05\n",
      "Epoch 40/100\n",
      "30/30 - 2s - 82ms/step - loss: 0.6169 - val_loss: 0.9235 - learning_rate: 1.0000e-05\n",
      "Epoch 41/100\n",
      "30/30 - 3s - 86ms/step - loss: 0.6166 - val_loss: 0.9267 - learning_rate: 1.0000e-05\n",
      "Epoch 42/100\n",
      "30/30 - 2s - 82ms/step - loss: 0.6150 - val_loss: 0.9274 - learning_rate: 1.0000e-05\n",
      "Epoch 43/100\n",
      "30/30 - 2s - 80ms/step - loss: 0.6163 - val_loss: 0.9206 - learning_rate: 1.0000e-05\n",
      "Epoch 44/100\n",
      "30/30 - 2s - 81ms/step - loss: 0.6158 - val_loss: 0.9252 - learning_rate: 1.0000e-05\n",
      "Epoch 45/100\n",
      "30/30 - 2s - 80ms/step - loss: 0.6169 - val_loss: 0.9132 - learning_rate: 1.0000e-05\n",
      "Epoch 46/100\n",
      "30/30 - 2s - 80ms/step - loss: 0.6163 - val_loss: 0.9255 - learning_rate: 1.0000e-05\n",
      "Epoch 47/100\n",
      "30/30 - 2s - 80ms/step - loss: 0.6160 - val_loss: 0.9245 - learning_rate: 1.0000e-05\n",
      "Epoch 48/100\n",
      "30/30 - 2s - 80ms/step - loss: 0.6176 - val_loss: 0.9217 - learning_rate: 1.0000e-05\n",
      "Epoch 49/100\n",
      "30/30 - 2s - 80ms/step - loss: 0.6192 - val_loss: 0.9306 - learning_rate: 1.0000e-05\n",
      "Epoch 50/100\n",
      "30/30 - 2s - 80ms/step - loss: 0.6179 - val_loss: 0.9256 - learning_rate: 1.0000e-05\n",
      "Epoch 51/100\n",
      "30/30 - 2s - 81ms/step - loss: 0.6173 - val_loss: 0.9257 - learning_rate: 1.0000e-05\n",
      "Epoch 52/100\n",
      "30/30 - 2s - 80ms/step - loss: 0.6180 - val_loss: 0.9209 - learning_rate: 1.0000e-05\n",
      "Epoch 53/100\n",
      "30/30 - 3s - 84ms/step - loss: 0.6167 - val_loss: 0.9353 - learning_rate: 1.0000e-05\n",
      "Epoch 54/100\n",
      "30/30 - 2s - 82ms/step - loss: 0.6177 - val_loss: 0.9301 - learning_rate: 1.0000e-05\n",
      "Epoch 55/100\n",
      "30/30 - 2s - 79ms/step - loss: 0.6155 - val_loss: 0.9214 - learning_rate: 1.0000e-05\n",
      "Epoch 56/100\n",
      "30/30 - 2s - 80ms/step - loss: 0.6181 - val_loss: 0.9291 - learning_rate: 1.0000e-05\n",
      "Epoch 57/100\n",
      "30/30 - 2s - 79ms/step - loss: 0.6170 - val_loss: 0.9276 - learning_rate: 1.0000e-05\n",
      "Epoch 58/100\n",
      "30/30 - 2s - 80ms/step - loss: 0.6168 - val_loss: 0.9234 - learning_rate: 1.0000e-05\n",
      "Epoch 59/100\n",
      "30/30 - 2s - 79ms/step - loss: 0.6150 - val_loss: 0.9326 - learning_rate: 1.0000e-05\n",
      "Epoch 60/100\n",
      "30/30 - 2s - 79ms/step - loss: 0.6188 - val_loss: 0.9237 - learning_rate: 1.0000e-05\n",
      "Epoch 61/100\n",
      "30/30 - 2s - 80ms/step - loss: 0.6157 - val_loss: 0.9266 - learning_rate: 1.0000e-05\n",
      "Epoch 62/100\n",
      "30/30 - 2s - 79ms/step - loss: 0.6172 - val_loss: 0.9361 - learning_rate: 1.0000e-05\n",
      "Epoch 63/100\n",
      "30/30 - 2s - 79ms/step - loss: 0.6177 - val_loss: 0.9289 - learning_rate: 1.0000e-05\n",
      "Epoch 64/100\n",
      "30/30 - 2s - 82ms/step - loss: 0.6165 - val_loss: 0.9264 - learning_rate: 1.0000e-05\n",
      "Epoch 65/100\n",
      "30/30 - 3s - 84ms/step - loss: 0.6178 - val_loss: 0.9331 - learning_rate: 1.0000e-05\n",
      "Epoch 66/100\n",
      "30/30 - 2s - 79ms/step - loss: 0.6161 - val_loss: 0.9238 - learning_rate: 1.0000e-05\n",
      "Epoch 67/100\n",
      "30/30 - 2s - 81ms/step - loss: 0.6160 - val_loss: 0.9262 - learning_rate: 1.0000e-05\n",
      "Epoch 68/100\n",
      "30/30 - 2s - 80ms/step - loss: 0.6176 - val_loss: 0.9264 - learning_rate: 1.0000e-05\n",
      "Epoch 69/100\n",
      "30/30 - 2s - 80ms/step - loss: 0.6173 - val_loss: 0.9265 - learning_rate: 1.0000e-05\n",
      "Epoch 70/100\n",
      "30/30 - 2s - 80ms/step - loss: 0.6166 - val_loss: 0.9249 - learning_rate: 1.0000e-05\n",
      "Epoch 71/100\n",
      "30/30 - 2s - 80ms/step - loss: 0.6180 - val_loss: 0.9279 - learning_rate: 1.0000e-05\n",
      "Epoch 72/100\n",
      "30/30 - 2s - 80ms/step - loss: 0.6175 - val_loss: 0.9327 - learning_rate: 1.0000e-05\n",
      "Epoch 73/100\n",
      "30/30 - 2s - 80ms/step - loss: 0.6154 - val_loss: 0.9299 - learning_rate: 1.0000e-05\n",
      "Epoch 74/100\n",
      "30/30 - 2s - 80ms/step - loss: 0.6161 - val_loss: 0.9235 - learning_rate: 1.0000e-05\n",
      "Epoch 75/100\n",
      "30/30 - 2s - 80ms/step - loss: 0.6161 - val_loss: 0.9292 - learning_rate: 1.0000e-05\n",
      "Epoch 76/100\n",
      "30/30 - 2s - 80ms/step - loss: 0.6150 - val_loss: 0.9311 - learning_rate: 1.0000e-05\n",
      "Epoch 77/100\n",
      "30/30 - 3s - 85ms/step - loss: 0.6179 - val_loss: 0.9304 - learning_rate: 1.0000e-05\n",
      "Epoch 78/100\n",
      "30/30 - 2s - 80ms/step - loss: 0.6194 - val_loss: 0.9257 - learning_rate: 1.0000e-05\n",
      "Epoch 79/100\n",
      "30/30 - 2s - 80ms/step - loss: 0.6163 - val_loss: 0.9323 - learning_rate: 1.0000e-05\n",
      "Epoch 80/100\n",
      "30/30 - 2s - 79ms/step - loss: 0.6170 - val_loss: 0.9320 - learning_rate: 1.0000e-05\n",
      "Epoch 81/100\n",
      "30/30 - 2s - 79ms/step - loss: 0.6160 - val_loss: 0.9352 - learning_rate: 1.0000e-05\n",
      "Epoch 82/100\n",
      "30/30 - 2s - 80ms/step - loss: 0.6171 - val_loss: 0.9313 - learning_rate: 1.0000e-05\n",
      "Epoch 83/100\n",
      "30/30 - 2s - 79ms/step - loss: 0.6178 - val_loss: 0.9351 - learning_rate: 1.0000e-05\n",
      "Epoch 84/100\n",
      "30/30 - 2s - 80ms/step - loss: 0.6142 - val_loss: 0.9268 - learning_rate: 1.0000e-05\n",
      "Epoch 85/100\n",
      "30/30 - 2s - 79ms/step - loss: 0.6159 - val_loss: 0.9286 - learning_rate: 1.0000e-05\n",
      "Epoch 86/100\n",
      "30/30 - 2s - 80ms/step - loss: 0.6174 - val_loss: 0.9303 - learning_rate: 1.0000e-05\n",
      "Epoch 87/100\n",
      "30/30 - 2s - 80ms/step - loss: 0.6168 - val_loss: 0.9292 - learning_rate: 1.0000e-05\n",
      "Epoch 88/100\n",
      "30/30 - 2s - 79ms/step - loss: 0.6175 - val_loss: 0.9314 - learning_rate: 1.0000e-05\n",
      "Epoch 89/100\n",
      "30/30 - 2s - 83ms/step - loss: 0.6174 - val_loss: 0.9286 - learning_rate: 1.0000e-05\n",
      "Epoch 90/100\n",
      "30/30 - 2s - 82ms/step - loss: 0.6159 - val_loss: 0.9187 - learning_rate: 1.0000e-05\n",
      "Epoch 91/100\n",
      "30/30 - 2s - 79ms/step - loss: 0.6181 - val_loss: 0.9309 - learning_rate: 1.0000e-05\n",
      "Epoch 92/100\n",
      "30/30 - 2s - 80ms/step - loss: 0.6185 - val_loss: 0.9216 - learning_rate: 1.0000e-05\n",
      "Epoch 93/100\n",
      "30/30 - 2s - 81ms/step - loss: 0.6161 - val_loss: 0.9298 - learning_rate: 1.0000e-05\n",
      "Epoch 94/100\n",
      "30/30 - 2s - 81ms/step - loss: 0.6169 - val_loss: 0.9280 - learning_rate: 1.0000e-05\n",
      "Epoch 95/100\n",
      "30/30 - 2s - 79ms/step - loss: 0.6165 - val_loss: 0.9304 - learning_rate: 1.0000e-05\n",
      "Epoch 96/100\n",
      "30/30 - 2s - 80ms/step - loss: 0.6176 - val_loss: 0.9280 - learning_rate: 1.0000e-05\n",
      "Epoch 97/100\n",
      "30/30 - 2s - 80ms/step - loss: 0.6173 - val_loss: 0.9301 - learning_rate: 1.0000e-05\n",
      "Epoch 98/100\n",
      "30/30 - 2s - 83ms/step - loss: 0.6163 - val_loss: 0.9362 - learning_rate: 1.0000e-05\n",
      "Epoch 99/100\n",
      "30/30 - 2s - 82ms/step - loss: 0.6164 - val_loss: 0.9359 - learning_rate: 1.0000e-05\n",
      "Epoch 100/100\n",
      "30/30 - 2s - 80ms/step - loss: 0.6168 - val_loss: 0.9265 - learning_rate: 1.0000e-05\n",
      "Entrenando cluster numero: 13\n",
      "Epoch 1/100\n",
      "10/10 - 7s - 744ms/step - loss: 1.8333 - val_loss: 0.0946 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "10/10 - 1s - 87ms/step - loss: 0.9022 - val_loss: 1.4266 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "10/10 - 1s - 86ms/step - loss: 0.7524 - val_loss: 0.5521 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "10/10 - 1s - 84ms/step - loss: 0.7247 - val_loss: 1.1168 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "10/10 - 1s - 83ms/step - loss: 0.7165 - val_loss: 0.7090 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "10/10 - 1s - 83ms/step - loss: 0.7174 - val_loss: 0.8896 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "10/10 - 1s - 85ms/step - loss: 0.7273 - val_loss: 0.8493 - learning_rate: 0.0010\n",
      "Epoch 8/100\n",
      "10/10 - 1s - 84ms/step - loss: 0.7137 - val_loss: 0.9072 - learning_rate: 0.0010\n",
      "Epoch 9/100\n",
      "10/10 - 1s - 82ms/step - loss: 0.7053 - val_loss: 0.8689 - learning_rate: 0.0010\n",
      "Epoch 10/100\n",
      "10/10 - 1s - 83ms/step - loss: 0.7209 - val_loss: 0.8399 - learning_rate: 0.0010\n",
      "Epoch 11/100\n",
      "\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "10/10 - 1s - 85ms/step - loss: 0.7104 - val_loss: 0.8284 - learning_rate: 0.0010\n",
      "Epoch 12/100\n",
      "10/10 - 1s - 83ms/step - loss: 0.7068 - val_loss: 0.8499 - learning_rate: 2.0000e-04\n",
      "Epoch 13/100\n",
      "10/10 - 1s - 85ms/step - loss: 0.7119 - val_loss: 0.8867 - learning_rate: 2.0000e-04\n",
      "Epoch 14/100\n",
      "10/10 - 1s - 83ms/step - loss: 0.7098 - val_loss: 0.8883 - learning_rate: 2.0000e-04\n",
      "Epoch 15/100\n",
      "10/10 - 1s - 83ms/step - loss: 0.7068 - val_loss: 0.8675 - learning_rate: 2.0000e-04\n",
      "Epoch 16/100\n",
      "10/10 - 1s - 83ms/step - loss: 0.7112 - val_loss: 0.8476 - learning_rate: 2.0000e-04\n",
      "Epoch 17/100\n",
      "10/10 - 1s - 84ms/step - loss: 0.7135 - val_loss: 0.8703 - learning_rate: 2.0000e-04\n",
      "Epoch 18/100\n",
      "10/10 - 1s - 85ms/step - loss: 0.7085 - val_loss: 0.9067 - learning_rate: 2.0000e-04\n",
      "Epoch 19/100\n",
      "10/10 - 1s - 83ms/step - loss: 0.7105 - val_loss: 0.8671 - learning_rate: 2.0000e-04\n",
      "Epoch 20/100\n",
      "10/10 - 1s - 85ms/step - loss: 0.7036 - val_loss: 0.8774 - learning_rate: 2.0000e-04\n",
      "Epoch 21/100\n",
      "\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "10/10 - 1s - 83ms/step - loss: 0.7089 - val_loss: 0.8712 - learning_rate: 2.0000e-04\n",
      "Epoch 22/100\n",
      "10/10 - 1s - 86ms/step - loss: 0.7093 - val_loss: 0.8826 - learning_rate: 4.0000e-05\n",
      "Epoch 23/100\n",
      "10/10 - 1s - 83ms/step - loss: 0.6974 - val_loss: 0.8759 - learning_rate: 4.0000e-05\n",
      "Epoch 24/100\n",
      "10/10 - 1s - 83ms/step - loss: 0.7066 - val_loss: 0.8895 - learning_rate: 4.0000e-05\n",
      "Epoch 25/100\n",
      "10/10 - 1s - 83ms/step - loss: 0.7114 - val_loss: 0.8848 - learning_rate: 4.0000e-05\n",
      "Epoch 26/100\n",
      "10/10 - 1s - 87ms/step - loss: 0.7149 - val_loss: 0.8793 - learning_rate: 4.0000e-05\n",
      "Epoch 27/100\n",
      "10/10 - 1s - 87ms/step - loss: 0.7031 - val_loss: 0.8757 - learning_rate: 4.0000e-05\n",
      "Epoch 28/100\n",
      "10/10 - 1s - 86ms/step - loss: 0.7099 - val_loss: 0.8792 - learning_rate: 4.0000e-05\n",
      "Epoch 29/100\n",
      "10/10 - 1s - 86ms/step - loss: 0.7074 - val_loss: 0.8774 - learning_rate: 4.0000e-05\n",
      "Epoch 30/100\n",
      "10/10 - 1s - 85ms/step - loss: 0.7061 - val_loss: 0.8705 - learning_rate: 4.0000e-05\n",
      "Epoch 31/100\n",
      "\n",
      "Epoch 31: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "10/10 - 1s - 85ms/step - loss: 0.6949 - val_loss: 0.8889 - learning_rate: 4.0000e-05\n",
      "Epoch 32/100\n",
      "10/10 - 1s - 82ms/step - loss: 0.7052 - val_loss: 0.8865 - learning_rate: 1.0000e-05\n",
      "Epoch 33/100\n",
      "10/10 - 1s - 84ms/step - loss: 0.7098 - val_loss: 0.8854 - learning_rate: 1.0000e-05\n",
      "Epoch 34/100\n",
      "10/10 - 1s - 84ms/step - loss: 0.7067 - val_loss: 0.8855 - learning_rate: 1.0000e-05\n",
      "Epoch 35/100\n",
      "10/10 - 1s - 85ms/step - loss: 0.7015 - val_loss: 0.8873 - learning_rate: 1.0000e-05\n",
      "Epoch 36/100\n",
      "10/10 - 1s - 85ms/step - loss: 0.6984 - val_loss: 0.8853 - learning_rate: 1.0000e-05\n",
      "Epoch 37/100\n",
      "10/10 - 1s - 83ms/step - loss: 0.7059 - val_loss: 0.8815 - learning_rate: 1.0000e-05\n",
      "Epoch 38/100\n",
      "10/10 - 1s - 88ms/step - loss: 0.7109 - val_loss: 0.8812 - learning_rate: 1.0000e-05\n",
      "Epoch 39/100\n",
      "10/10 - 1s - 83ms/step - loss: 0.7084 - val_loss: 0.8832 - learning_rate: 1.0000e-05\n",
      "Epoch 40/100\n",
      "10/10 - 1s - 83ms/step - loss: 0.6954 - val_loss: 0.8850 - learning_rate: 1.0000e-05\n",
      "Epoch 41/100\n",
      "10/10 - 1s - 83ms/step - loss: 0.7099 - val_loss: 0.8811 - learning_rate: 1.0000e-05\n",
      "Epoch 42/100\n",
      "10/10 - 1s - 83ms/step - loss: 0.7102 - val_loss: 0.8853 - learning_rate: 1.0000e-05\n",
      "Epoch 43/100\n",
      "10/10 - 1s - 87ms/step - loss: 0.7068 - val_loss: 0.8843 - learning_rate: 1.0000e-05\n",
      "Epoch 44/100\n",
      "10/10 - 1s - 85ms/step - loss: 0.7037 - val_loss: 0.8855 - learning_rate: 1.0000e-05\n",
      "Epoch 45/100\n",
      "10/10 - 1s - 83ms/step - loss: 0.7025 - val_loss: 0.8844 - learning_rate: 1.0000e-05\n",
      "Epoch 46/100\n",
      "10/10 - 1s - 85ms/step - loss: 0.7055 - val_loss: 0.8833 - learning_rate: 1.0000e-05\n",
      "Epoch 47/100\n",
      "10/10 - 1s - 83ms/step - loss: 0.7004 - val_loss: 0.8792 - learning_rate: 1.0000e-05\n",
      "Epoch 48/100\n",
      "10/10 - 1s - 87ms/step - loss: 0.7136 - val_loss: 0.8824 - learning_rate: 1.0000e-05\n",
      "Epoch 49/100\n",
      "10/10 - 1s - 87ms/step - loss: 0.7058 - val_loss: 0.8812 - learning_rate: 1.0000e-05\n",
      "Epoch 50/100\n",
      "10/10 - 1s - 87ms/step - loss: 0.7024 - val_loss: 0.8813 - learning_rate: 1.0000e-05\n",
      "Epoch 51/100\n",
      "10/10 - 1s - 85ms/step - loss: 0.7088 - val_loss: 0.8826 - learning_rate: 1.0000e-05\n",
      "Epoch 52/100\n",
      "10/10 - 1s - 83ms/step - loss: 0.7111 - val_loss: 0.8821 - learning_rate: 1.0000e-05\n",
      "Epoch 53/100\n",
      "10/10 - 1s - 84ms/step - loss: 0.7030 - val_loss: 0.8861 - learning_rate: 1.0000e-05\n",
      "Epoch 54/100\n",
      "10/10 - 1s - 83ms/step - loss: 0.7064 - val_loss: 0.8889 - learning_rate: 1.0000e-05\n",
      "Epoch 55/100\n",
      "10/10 - 1s - 83ms/step - loss: 0.7075 - val_loss: 0.8847 - learning_rate: 1.0000e-05\n",
      "Epoch 56/100\n",
      "10/10 - 1s - 86ms/step - loss: 0.6992 - val_loss: 0.8812 - learning_rate: 1.0000e-05\n",
      "Epoch 57/100\n",
      "10/10 - 1s - 83ms/step - loss: 0.7041 - val_loss: 0.8775 - learning_rate: 1.0000e-05\n",
      "Epoch 58/100\n",
      "10/10 - 1s - 87ms/step - loss: 0.7103 - val_loss: 0.8882 - learning_rate: 1.0000e-05\n",
      "Epoch 59/100\n",
      "10/10 - 1s - 84ms/step - loss: 0.7045 - val_loss: 0.8844 - learning_rate: 1.0000e-05\n",
      "Epoch 60/100\n",
      "10/10 - 1s - 83ms/step - loss: 0.7066 - val_loss: 0.8850 - learning_rate: 1.0000e-05\n",
      "Epoch 61/100\n",
      "10/10 - 1s - 85ms/step - loss: 0.7044 - val_loss: 0.8850 - learning_rate: 1.0000e-05\n",
      "Epoch 62/100\n",
      "10/10 - 1s - 84ms/step - loss: 0.6984 - val_loss: 0.8816 - learning_rate: 1.0000e-05\n",
      "Epoch 63/100\n",
      "10/10 - 1s - 83ms/step - loss: 0.7003 - val_loss: 0.8798 - learning_rate: 1.0000e-05\n",
      "Epoch 64/100\n",
      "10/10 - 1s - 83ms/step - loss: 0.6993 - val_loss: 0.8758 - learning_rate: 1.0000e-05\n",
      "Epoch 65/100\n",
      "10/10 - 1s - 91ms/step - loss: 0.7017 - val_loss: 0.8807 - learning_rate: 1.0000e-05\n",
      "Epoch 66/100\n",
      "10/10 - 1s - 91ms/step - loss: 0.7012 - val_loss: 0.8843 - learning_rate: 1.0000e-05\n",
      "Epoch 67/100\n",
      "10/10 - 1s - 91ms/step - loss: 0.7166 - val_loss: 0.8823 - learning_rate: 1.0000e-05\n",
      "Epoch 68/100\n",
      "10/10 - 1s - 84ms/step - loss: 0.7071 - val_loss: 0.8872 - learning_rate: 1.0000e-05\n",
      "Epoch 69/100\n",
      "10/10 - 1s - 86ms/step - loss: 0.7062 - val_loss: 0.8896 - learning_rate: 1.0000e-05\n",
      "Epoch 70/100\n",
      "10/10 - 1s - 85ms/step - loss: 0.7047 - val_loss: 0.8912 - learning_rate: 1.0000e-05\n",
      "Epoch 71/100\n",
      "10/10 - 1s - 84ms/step - loss: 0.7111 - val_loss: 0.8853 - learning_rate: 1.0000e-05\n",
      "Epoch 72/100\n",
      "10/10 - 1s - 83ms/step - loss: 0.7061 - val_loss: 0.8811 - learning_rate: 1.0000e-05\n",
      "Epoch 73/100\n",
      "10/10 - 1s - 83ms/step - loss: 0.7023 - val_loss: 0.8832 - learning_rate: 1.0000e-05\n",
      "Epoch 74/100\n",
      "10/10 - 1s - 83ms/step - loss: 0.7069 - val_loss: 0.8789 - learning_rate: 1.0000e-05\n",
      "Epoch 75/100\n",
      "10/10 - 1s - 85ms/step - loss: 0.7015 - val_loss: 0.8817 - learning_rate: 1.0000e-05\n",
      "Epoch 76/100\n",
      "10/10 - 1s - 85ms/step - loss: 0.7072 - val_loss: 0.8821 - learning_rate: 1.0000e-05\n",
      "Epoch 77/100\n",
      "10/10 - 1s - 83ms/step - loss: 0.7102 - val_loss: 0.8833 - learning_rate: 1.0000e-05\n",
      "Epoch 78/100\n",
      "10/10 - 1s - 87ms/step - loss: 0.7069 - val_loss: 0.8824 - learning_rate: 1.0000e-05\n",
      "Epoch 79/100\n",
      "10/10 - 1s - 82ms/step - loss: 0.6983 - val_loss: 0.8797 - learning_rate: 1.0000e-05\n",
      "Epoch 80/100\n",
      "10/10 - 1s - 85ms/step - loss: 0.7028 - val_loss: 0.8841 - learning_rate: 1.0000e-05\n",
      "Epoch 81/100\n",
      "10/10 - 1s - 83ms/step - loss: 0.7005 - val_loss: 0.8809 - learning_rate: 1.0000e-05\n",
      "Epoch 82/100\n",
      "10/10 - 1s - 84ms/step - loss: 0.7029 - val_loss: 0.8793 - learning_rate: 1.0000e-05\n",
      "Epoch 83/100\n",
      "10/10 - 1s - 86ms/step - loss: 0.7022 - val_loss: 0.8820 - learning_rate: 1.0000e-05\n",
      "Epoch 84/100\n",
      "10/10 - 1s - 83ms/step - loss: 0.7078 - val_loss: 0.8811 - learning_rate: 1.0000e-05\n",
      "Epoch 85/100\n",
      "10/10 - 1s - 85ms/step - loss: 0.7011 - val_loss: 0.8798 - learning_rate: 1.0000e-05\n",
      "Epoch 86/100\n",
      "10/10 - 1s - 83ms/step - loss: 0.7093 - val_loss: 0.8784 - learning_rate: 1.0000e-05\n",
      "Epoch 87/100\n",
      "10/10 - 1s - 83ms/step - loss: 0.7030 - val_loss: 0.8821 - learning_rate: 1.0000e-05\n",
      "Epoch 88/100\n",
      "10/10 - 1s - 86ms/step - loss: 0.7002 - val_loss: 0.8799 - learning_rate: 1.0000e-05\n",
      "Epoch 89/100\n",
      "10/10 - 1s - 84ms/step - loss: 0.7067 - val_loss: 0.8896 - learning_rate: 1.0000e-05\n",
      "Epoch 90/100\n",
      "10/10 - 1s - 83ms/step - loss: 0.7036 - val_loss: 0.8870 - learning_rate: 1.0000e-05\n",
      "Epoch 91/100\n",
      "10/10 - 1s - 85ms/step - loss: 0.7025 - val_loss: 0.8843 - learning_rate: 1.0000e-05\n",
      "Epoch 92/100\n",
      "10/10 - 1s - 83ms/step - loss: 0.7063 - val_loss: 0.8822 - learning_rate: 1.0000e-05\n",
      "Epoch 93/100\n",
      "10/10 - 1s - 84ms/step - loss: 0.7093 - val_loss: 0.8771 - learning_rate: 1.0000e-05\n",
      "Epoch 94/100\n",
      "10/10 - 1s - 86ms/step - loss: 0.6978 - val_loss: 0.8892 - learning_rate: 1.0000e-05\n",
      "Epoch 95/100\n",
      "10/10 - 1s - 83ms/step - loss: 0.7058 - val_loss: 0.8908 - learning_rate: 1.0000e-05\n",
      "Epoch 96/100\n",
      "10/10 - 1s - 85ms/step - loss: 0.7076 - val_loss: 0.8855 - learning_rate: 1.0000e-05\n",
      "Epoch 97/100\n",
      "10/10 - 1s - 83ms/step - loss: 0.7040 - val_loss: 0.8839 - learning_rate: 1.0000e-05\n",
      "Epoch 98/100\n",
      "10/10 - 1s - 84ms/step - loss: 0.7005 - val_loss: 0.8863 - learning_rate: 1.0000e-05\n",
      "Epoch 99/100\n",
      "10/10 - 1s - 85ms/step - loss: 0.7005 - val_loss: 0.8805 - learning_rate: 1.0000e-05\n",
      "Epoch 100/100\n",
      "10/10 - 1s - 83ms/step - loss: 0.7006 - val_loss: 0.8876 - learning_rate: 1.0000e-05\n",
      "Entrenando cluster numero: 14\n",
      "Epoch 1/100\n",
      "14/14 - 7s - 524ms/step - loss: 1.1838 - val_loss: 0.2716 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "14/14 - 1s - 83ms/step - loss: 0.7257 - val_loss: 0.6219 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "14/14 - 1s - 85ms/step - loss: 0.6814 - val_loss: 0.9350 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "14/14 - 1s - 90ms/step - loss: 0.6779 - val_loss: 0.7948 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "14/14 - 1s - 84ms/step - loss: 0.6766 - val_loss: 0.7207 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "14/14 - 1s - 84ms/step - loss: 0.6778 - val_loss: 0.6570 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "14/14 - 1s - 83ms/step - loss: 0.6663 - val_loss: 0.8126 - learning_rate: 0.0010\n",
      "Epoch 8/100\n",
      "14/14 - 1s - 81ms/step - loss: 0.6747 - val_loss: 0.6758 - learning_rate: 0.0010\n",
      "Epoch 9/100\n",
      "14/14 - 1s - 82ms/step - loss: 0.6731 - val_loss: 0.6428 - learning_rate: 0.0010\n",
      "Epoch 10/100\n",
      "14/14 - 1s - 97ms/step - loss: 0.6683 - val_loss: 0.7547 - learning_rate: 0.0010\n",
      "Epoch 11/100\n",
      "\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "14/14 - 1s - 86ms/step - loss: 0.6651 - val_loss: 0.7650 - learning_rate: 0.0010\n",
      "Epoch 12/100\n",
      "14/14 - 1s - 82ms/step - loss: 0.6685 - val_loss: 0.8176 - learning_rate: 2.0000e-04\n",
      "Epoch 13/100\n",
      "14/14 - 1s - 82ms/step - loss: 0.6676 - val_loss: 0.7992 - learning_rate: 2.0000e-04\n",
      "Epoch 14/100\n",
      "14/14 - 1s - 88ms/step - loss: 0.6648 - val_loss: 0.7737 - learning_rate: 2.0000e-04\n",
      "Epoch 15/100\n",
      "14/14 - 1s - 81ms/step - loss: 0.6631 - val_loss: 0.8094 - learning_rate: 2.0000e-04\n",
      "Epoch 16/100\n",
      "14/14 - 1s - 81ms/step - loss: 0.6686 - val_loss: 0.7802 - learning_rate: 2.0000e-04\n",
      "Epoch 17/100\n",
      "14/14 - 1s - 85ms/step - loss: 0.6658 - val_loss: 0.7945 - learning_rate: 2.0000e-04\n",
      "Epoch 18/100\n",
      "14/14 - 1s - 88ms/step - loss: 0.6694 - val_loss: 0.7965 - learning_rate: 2.0000e-04\n",
      "Epoch 19/100\n",
      "14/14 - 1s - 85ms/step - loss: 0.6674 - val_loss: 0.7814 - learning_rate: 2.0000e-04\n",
      "Epoch 20/100\n",
      "14/14 - 1s - 81ms/step - loss: 0.6592 - val_loss: 0.8114 - learning_rate: 2.0000e-04\n",
      "Epoch 21/100\n",
      "\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "14/14 - 1s - 82ms/step - loss: 0.6676 - val_loss: 0.7978 - learning_rate: 2.0000e-04\n",
      "Epoch 22/100\n",
      "14/14 - 1s - 81ms/step - loss: 0.6670 - val_loss: 0.7823 - learning_rate: 4.0000e-05\n",
      "Epoch 23/100\n",
      "14/14 - 1s - 81ms/step - loss: 0.6624 - val_loss: 0.7851 - learning_rate: 4.0000e-05\n",
      "Epoch 24/100\n",
      "14/14 - 1s - 81ms/step - loss: 0.6642 - val_loss: 0.8107 - learning_rate: 4.0000e-05\n",
      "Epoch 25/100\n",
      "14/14 - 1s - 81ms/step - loss: 0.6656 - val_loss: 0.7886 - learning_rate: 4.0000e-05\n",
      "Epoch 26/100\n",
      "14/14 - 1s - 84ms/step - loss: 0.6594 - val_loss: 0.8035 - learning_rate: 4.0000e-05\n",
      "Epoch 27/100\n",
      "14/14 - 1s - 82ms/step - loss: 0.6651 - val_loss: 0.7958 - learning_rate: 4.0000e-05\n",
      "Epoch 28/100\n",
      "14/14 - 1s - 82ms/step - loss: 0.6620 - val_loss: 0.7939 - learning_rate: 4.0000e-05\n",
      "Epoch 29/100\n",
      "14/14 - 1s - 84ms/step - loss: 0.6687 - val_loss: 0.7888 - learning_rate: 4.0000e-05\n",
      "Epoch 30/100\n",
      "14/14 - 1s - 84ms/step - loss: 0.6607 - val_loss: 0.8036 - learning_rate: 4.0000e-05\n",
      "Epoch 31/100\n",
      "\n",
      "Epoch 31: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "14/14 - 1s - 87ms/step - loss: 0.6634 - val_loss: 0.7966 - learning_rate: 4.0000e-05\n",
      "Epoch 32/100\n",
      "14/14 - 1s - 87ms/step - loss: 0.6627 - val_loss: 0.7938 - learning_rate: 1.0000e-05\n",
      "Epoch 33/100\n",
      "14/14 - 1s - 82ms/step - loss: 0.6682 - val_loss: 0.7880 - learning_rate: 1.0000e-05\n",
      "Epoch 34/100\n",
      "14/14 - 1s - 81ms/step - loss: 0.6661 - val_loss: 0.7873 - learning_rate: 1.0000e-05\n",
      "Epoch 35/100\n",
      "14/14 - 1s - 81ms/step - loss: 0.6632 - val_loss: 0.7917 - learning_rate: 1.0000e-05\n",
      "Epoch 36/100\n",
      "14/14 - 1s - 82ms/step - loss: 0.6646 - val_loss: 0.7903 - learning_rate: 1.0000e-05\n",
      "Epoch 37/100\n",
      "14/14 - 1s - 81ms/step - loss: 0.6698 - val_loss: 0.8007 - learning_rate: 1.0000e-05\n",
      "Epoch 38/100\n",
      "14/14 - 1s - 81ms/step - loss: 0.6652 - val_loss: 0.8000 - learning_rate: 1.0000e-05\n",
      "Epoch 39/100\n",
      "14/14 - 1s - 87ms/step - loss: 0.6684 - val_loss: 0.7945 - learning_rate: 1.0000e-05\n",
      "Epoch 40/100\n",
      "14/14 - 1s - 86ms/step - loss: 0.6639 - val_loss: 0.8066 - learning_rate: 1.0000e-05\n",
      "Epoch 41/100\n",
      "14/14 - 1s - 81ms/step - loss: 0.6615 - val_loss: 0.8007 - learning_rate: 1.0000e-05\n",
      "Epoch 42/100\n",
      "14/14 - 1s - 81ms/step - loss: 0.6614 - val_loss: 0.8039 - learning_rate: 1.0000e-05\n",
      "Epoch 43/100\n",
      "14/14 - 1s - 81ms/step - loss: 0.6635 - val_loss: 0.8070 - learning_rate: 1.0000e-05\n",
      "Epoch 44/100\n",
      "14/14 - 1s - 83ms/step - loss: 0.6660 - val_loss: 0.8043 - learning_rate: 1.0000e-05\n",
      "Epoch 45/100\n",
      "14/14 - 1s - 82ms/step - loss: 0.6593 - val_loss: 0.8014 - learning_rate: 1.0000e-05\n",
      "Epoch 46/100\n",
      "14/14 - 1s - 82ms/step - loss: 0.6620 - val_loss: 0.8000 - learning_rate: 1.0000e-05\n",
      "Epoch 47/100\n",
      "14/14 - 1s - 86ms/step - loss: 0.6685 - val_loss: 0.7982 - learning_rate: 1.0000e-05\n",
      "Epoch 48/100\n",
      "14/14 - 1s - 88ms/step - loss: 0.6573 - val_loss: 0.7960 - learning_rate: 1.0000e-05\n",
      "Epoch 49/100\n",
      "14/14 - 1s - 80ms/step - loss: 0.6616 - val_loss: 0.8016 - learning_rate: 1.0000e-05\n",
      "Epoch 50/100\n",
      "14/14 - 1s - 82ms/step - loss: 0.6657 - val_loss: 0.8075 - learning_rate: 1.0000e-05\n",
      "Epoch 51/100\n",
      "14/14 - 1s - 80ms/step - loss: 0.6667 - val_loss: 0.8065 - learning_rate: 1.0000e-05\n",
      "Epoch 52/100\n",
      "14/14 - 1s - 82ms/step - loss: 0.6662 - val_loss: 0.7981 - learning_rate: 1.0000e-05\n",
      "Epoch 53/100\n",
      "14/14 - 1s - 83ms/step - loss: 0.6663 - val_loss: 0.8000 - learning_rate: 1.0000e-05\n",
      "Epoch 54/100\n",
      "14/14 - 1s - 83ms/step - loss: 0.6640 - val_loss: 0.8020 - learning_rate: 1.0000e-05\n",
      "Epoch 55/100\n",
      "14/14 - 1s - 90ms/step - loss: 0.6637 - val_loss: 0.8037 - learning_rate: 1.0000e-05\n",
      "Epoch 56/100\n",
      "14/14 - 1s - 83ms/step - loss: 0.6655 - val_loss: 0.8048 - learning_rate: 1.0000e-05\n",
      "Epoch 57/100\n",
      "14/14 - 1s - 81ms/step - loss: 0.6593 - val_loss: 0.8068 - learning_rate: 1.0000e-05\n",
      "Epoch 58/100\n",
      "14/14 - 1s - 81ms/step - loss: 0.6630 - val_loss: 0.7954 - learning_rate: 1.0000e-05\n",
      "Epoch 59/100\n",
      "14/14 - 1s - 83ms/step - loss: 0.6654 - val_loss: 0.7893 - learning_rate: 1.0000e-05\n",
      "Epoch 60/100\n",
      "14/14 - 1s - 81ms/step - loss: 0.6655 - val_loss: 0.7908 - learning_rate: 1.0000e-05\n",
      "Epoch 61/100\n",
      "14/14 - 1s - 81ms/step - loss: 0.6642 - val_loss: 0.7995 - learning_rate: 1.0000e-05\n",
      "Epoch 62/100\n",
      "14/14 - 1s - 83ms/step - loss: 0.6653 - val_loss: 0.8034 - learning_rate: 1.0000e-05\n",
      "Epoch 63/100\n",
      "14/14 - 1s - 88ms/step - loss: 0.6648 - val_loss: 0.8045 - learning_rate: 1.0000e-05\n",
      "Epoch 64/100\n",
      "14/14 - 1s - 85ms/step - loss: 0.6633 - val_loss: 0.8087 - learning_rate: 1.0000e-05\n",
      "Epoch 65/100\n",
      "14/14 - 1s - 82ms/step - loss: 0.6657 - val_loss: 0.8021 - learning_rate: 1.0000e-05\n",
      "Epoch 66/100\n",
      "14/14 - 1s - 82ms/step - loss: 0.6641 - val_loss: 0.8014 - learning_rate: 1.0000e-05\n",
      "Epoch 67/100\n",
      "14/14 - 1s - 81ms/step - loss: 0.6672 - val_loss: 0.8012 - learning_rate: 1.0000e-05\n",
      "Epoch 68/100\n",
      "14/14 - 1s - 83ms/step - loss: 0.6640 - val_loss: 0.7902 - learning_rate: 1.0000e-05\n",
      "Epoch 69/100\n",
      "14/14 - 1s - 81ms/step - loss: 0.6656 - val_loss: 0.8000 - learning_rate: 1.0000e-05\n",
      "Epoch 70/100\n",
      "14/14 - 1s - 82ms/step - loss: 0.6596 - val_loss: 0.7924 - learning_rate: 1.0000e-05\n",
      "Epoch 71/100\n",
      "14/14 - 1s - 90ms/step - loss: 0.6624 - val_loss: 0.7942 - learning_rate: 1.0000e-05\n",
      "Epoch 72/100\n",
      "14/14 - 1s - 86ms/step - loss: 0.6680 - val_loss: 0.7938 - learning_rate: 1.0000e-05\n",
      "Epoch 73/100\n",
      "14/14 - 1s - 84ms/step - loss: 0.6657 - val_loss: 0.8005 - learning_rate: 1.0000e-05\n",
      "Epoch 74/100\n",
      "14/14 - 1s - 81ms/step - loss: 0.6622 - val_loss: 0.8010 - learning_rate: 1.0000e-05\n",
      "Epoch 75/100\n",
      "14/14 - 1s - 82ms/step - loss: 0.6652 - val_loss: 0.7979 - learning_rate: 1.0000e-05\n",
      "Epoch 76/100\n",
      "14/14 - 1s - 81ms/step - loss: 0.6624 - val_loss: 0.7960 - learning_rate: 1.0000e-05\n",
      "Epoch 77/100\n",
      "14/14 - 1s - 82ms/step - loss: 0.6591 - val_loss: 0.8021 - learning_rate: 1.0000e-05\n",
      "Epoch 78/100\n",
      "14/14 - 1s - 82ms/step - loss: 0.6643 - val_loss: 0.8098 - learning_rate: 1.0000e-05\n",
      "Epoch 79/100\n",
      "14/14 - 1s - 81ms/step - loss: 0.6630 - val_loss: 0.8063 - learning_rate: 1.0000e-05\n",
      "Epoch 80/100\n",
      "14/14 - 1s - 83ms/step - loss: 0.6710 - val_loss: 0.7945 - learning_rate: 1.0000e-05\n",
      "Epoch 81/100\n",
      "14/14 - 1s - 81ms/step - loss: 0.6647 - val_loss: 0.7973 - learning_rate: 1.0000e-05\n",
      "Epoch 82/100\n",
      "14/14 - 1s - 81ms/step - loss: 0.6602 - val_loss: 0.8006 - learning_rate: 1.0000e-05\n",
      "Epoch 83/100\n",
      "14/14 - 1s - 81ms/step - loss: 0.6548 - val_loss: 0.8033 - learning_rate: 1.0000e-05\n",
      "Epoch 84/100\n",
      "14/14 - 1s - 87ms/step - loss: 0.6617 - val_loss: 0.8062 - learning_rate: 1.0000e-05\n",
      "Epoch 85/100\n",
      "14/14 - 1s - 86ms/step - loss: 0.6640 - val_loss: 0.8039 - learning_rate: 1.0000e-05\n",
      "Epoch 86/100\n",
      "14/14 - 1s - 81ms/step - loss: 0.6638 - val_loss: 0.8117 - learning_rate: 1.0000e-05\n",
      "Epoch 87/100\n",
      "14/14 - 1s - 81ms/step - loss: 0.6637 - val_loss: 0.8090 - learning_rate: 1.0000e-05\n",
      "Epoch 88/100\n",
      "14/14 - 1s - 82ms/step - loss: 0.6645 - val_loss: 0.8075 - learning_rate: 1.0000e-05\n",
      "Epoch 89/100\n",
      "14/14 - 1s - 80ms/step - loss: 0.6621 - val_loss: 0.8040 - learning_rate: 1.0000e-05\n",
      "Epoch 90/100\n",
      "14/14 - 1s - 81ms/step - loss: 0.6642 - val_loss: 0.7955 - learning_rate: 1.0000e-05\n",
      "Epoch 91/100\n",
      "14/14 - 1s - 81ms/step - loss: 0.6653 - val_loss: 0.7897 - learning_rate: 1.0000e-05\n",
      "Epoch 92/100\n",
      "14/14 - 1s - 87ms/step - loss: 0.6615 - val_loss: 0.8065 - learning_rate: 1.0000e-05\n",
      "Epoch 93/100\n",
      "14/14 - 1s - 85ms/step - loss: 0.6612 - val_loss: 0.8060 - learning_rate: 1.0000e-05\n",
      "Epoch 94/100\n",
      "14/14 - 1s - 82ms/step - loss: 0.6617 - val_loss: 0.8067 - learning_rate: 1.0000e-05\n",
      "Epoch 95/100\n",
      "14/14 - 1s - 81ms/step - loss: 0.6629 - val_loss: 0.7988 - learning_rate: 1.0000e-05\n",
      "Epoch 96/100\n",
      "14/14 - 1s - 81ms/step - loss: 0.6595 - val_loss: 0.8018 - learning_rate: 1.0000e-05\n",
      "Epoch 97/100\n",
      "14/14 - 1s - 82ms/step - loss: 0.6655 - val_loss: 0.8077 - learning_rate: 1.0000e-05\n",
      "Epoch 98/100\n",
      "14/14 - 1s - 82ms/step - loss: 0.6656 - val_loss: 0.8139 - learning_rate: 1.0000e-05\n",
      "Epoch 99/100\n",
      "14/14 - 1s - 81ms/step - loss: 0.6622 - val_loss: 0.8125 - learning_rate: 1.0000e-05\n",
      "Epoch 100/100\n",
      "14/14 - 1s - 91ms/step - loss: 0.6638 - val_loss: 0.8131 - learning_rate: 1.0000e-05\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ReduceLROnPlateau\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "models = {}\n",
    "predictions = []\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=10, min_lr=0.00001, verbose=1)\n",
    "\n",
    "# Preparar los datos por cluster\n",
    "for cluster in range(n_clusters):\n",
    "    print(f'Entrenando cluster numero: {cluster}')\n",
    "    cluster_data = grouped_df[grouped_df['cluster'] == cluster].copy()\n",
    "    cluster_data.sort_values(by='periodo', inplace=True)\n",
    "    \n",
    "    # Preparar los datos para LSTM\n",
    "    X, y = [], []\n",
    "    for key, data in cluster_data.groupby(['cat1', 'cat2', 'cat3', 'brand', 'customer_id']):\n",
    "        series = data[['cat1', 'cat2', 'cat3', 'brand', 'customer_id', 'tn_scaled']].values\n",
    "        if len(series) > 2:  # Asegurarse de que haya suficientes datos\n",
    "            X.append(series[:-2])  # Todos los datos excepto los últimos 2\n",
    "            y.append(series[-1, 0])  # Selecciona solo tn_scaled como objetivo\n",
    "\n",
    "    # Pad y reshape de X\n",
    "    max_len = max(len(seq) for seq in X)\n",
    "    X_padded = np.array([np.pad(seq, ((max_len - len(seq), 0), (0, 0)), mode='constant') for seq in X]).astype(np.float32)\n",
    "    y = np.array(y).astype(np.float32)\n",
    "    \n",
    "    if len(X_padded) == 0 or len(y) == 0:\n",
    "        continue\n",
    "\n",
    "    # Construir y entrenar el modelo\n",
    "    model = build_model((X_padded.shape[1], X_padded.shape[2]))\n",
    "    model.fit(X_padded, y, epochs=100, verbose=2, batch_size=128, validation_split=0.2, callbacks=[reduce_lr])\n",
    "    models[cluster] = model\n",
    "\n",
    "    # Hacer predicciones\n",
    "    for key, data in cluster_data.groupby(['cat1', 'cat2', 'cat3', 'brand', 'customer_id']):\n",
    "        series = data[['cat1', 'cat2', 'cat3', 'brand', 'customer_id', 'tn_scaled']].values\n",
    "        \n",
    "        if len(series) > 2:\n",
    "            max_len = len(series) - 1\n",
    "            X_pred = np.pad(series[1:], ((max_len - len(series[1:]), 0), (0, 0)), mode='constant').astype(np.float32)\n",
    "            X_pred = np.reshape(X_pred, (1, X_pred.shape[0], X_pred.shape[1]))\n",
    "            pred = model.predict(X_pred, verbose=0)\n",
    "            predictions.append([key[0], key[1], key[2], key[3], pred[0][0], key[4]])\n",
    "\n",
    "    # Guardar las predicciones en un DataFrame y exportar a CSV\n",
    "    pred_df_temp = pd.DataFrame(predictions, columns=['cat1', 'cat2', 'cat3', 'brand', 'prediccion', 'customer_id'])\n",
    "    pred_df_temp.to_csv(f\"predicciones_temporales_cluster_{cluster}.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cat1</th>\n",
       "      <th>cat2</th>\n",
       "      <th>cat3</th>\n",
       "      <th>brand</th>\n",
       "      <th>prediccion</th>\n",
       "      <th>customer_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>22</td>\n",
       "      <td>0.97414</td>\n",
       "      <td>10001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>22</td>\n",
       "      <td>0.97414</td>\n",
       "      <td>10032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>22</td>\n",
       "      <td>0.97414</td>\n",
       "      <td>10106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>22</td>\n",
       "      <td>0.97414</td>\n",
       "      <td>10144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>22</td>\n",
       "      <td>0.97414</td>\n",
       "      <td>10225</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cat1  cat2  cat3  brand  prediccion  customer_id\n",
       "0     0     0     4     22     0.97414        10001\n",
       "1     0     0     4     22     0.97414        10032\n",
       "2     0     0     4     22     0.97414        10106\n",
       "3     0     0     4     22     0.97414        10144\n",
       "4     0     0     4     22     0.97414        10225"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_df_temp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df_temp.to_csv(\"C:/Users/Usuario/desktop/vero2/pred_df_temp.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cat1</th>\n",
       "      <th>cat2</th>\n",
       "      <th>cat3</th>\n",
       "      <th>brand</th>\n",
       "      <th>prediccion</th>\n",
       "      <th>customer_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>22</td>\n",
       "      <td>8.196926</td>\n",
       "      <td>10001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>22</td>\n",
       "      <td>8.196926</td>\n",
       "      <td>10032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>22</td>\n",
       "      <td>8.196926</td>\n",
       "      <td>10106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>22</td>\n",
       "      <td>8.196926</td>\n",
       "      <td>10144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>22</td>\n",
       "      <td>8.196926</td>\n",
       "      <td>10225</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cat1  cat2  cat3  brand  prediccion  customer_id\n",
       "0     0     0     4     22    8.196926        10001\n",
       "1     0     0     4     22    8.196926        10032\n",
       "2     0     0     4     22    8.196926        10106\n",
       "3     0     0     4     22    8.196926        10144\n",
       "4     0     0     4     22    8.196926        10225"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_df = pd.DataFrame(predictions, columns=['cat1', 'cat2', 'cat3', 'brand', 'prediccion', 'customer_id'])\n",
    "# Suponiendo que `scaler` es el objeto StandardScaler que usaste para escalar `tn` originalmente\n",
    "\n",
    "# Desescalar las predicciones\n",
    "predicciones_desescaladas = scaler.inverse_transform(pred_df['prediccion'].values.reshape(-1, 1))\n",
    "\n",
    "# Reemplazar las predicciones escaladas con las desescaladas en el DataFrame\n",
    "pred_df['prediccion'] = predicciones_desescaladas.flatten()\n",
    "\n",
    "# Ahora pred_df tiene las predicciones desescaladas en la columna 'prediccion'\n",
    "pred_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   cat1  cat2  cat3  brand  prediccion  customer_id  product_id\n",
      "0     0     0     4     22    8.196926        10001       20609\n",
      "1     0     0     4     22    8.196926        10032       20609\n",
      "2     0     0     4     22    8.196926        10106       20609\n",
      "3     0     0     4     22    8.196926        10144       20609\n",
      "4     0     0     4     22    8.196926        10225       20609\n"
     ]
    }
   ],
   "source": [
    "# Obtener combinaciones únicas de 'product_id', 'cat1', 'cat2', 'cat3', 'brand' del DataFrame original\n",
    "distinct_combinations = df[['product_id', 'cat1', 'cat2', 'cat3', 'brand']].drop_duplicates()\n",
    "\n",
    "# Realizar un join con pred_df en las columnas correspondientes\n",
    "pred_df = pred_df.merge(distinct_combinations, on=['cat1', 'cat2', 'cat3', 'brand'], how='left')\n",
    "\n",
    "# Mostrar el DataFrame con las predicciones y las nuevas columnas agregadas\n",
    "print(pred_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   cat1  cat2  cat3  brand  prediccion  customer_id  product_id  \\\n",
      "0     0     0     4     22    8.196926        10001       20609   \n",
      "1     0     0     4     22    8.196926        10032       20609   \n",
      "2     0     0     4     22    8.196926        10106       20609   \n",
      "3     0     0     4     22    8.196926        10144       20609   \n",
      "4     0     0     4     22    8.196926        10225       20609   \n",
      "\n",
      "   prediccion_ajustada  \n",
      "0             8.196926  \n",
      "1             8.196926  \n",
      "2             8.196926  \n",
      "3             8.196926  \n",
      "4             8.196926  \n"
     ]
    }
   ],
   "source": [
    "# Inicializar una lista para almacenar las predicciones ajustadas\n",
    "predictions_adjusted = []\n",
    "\n",
    "# Iterar sobre las filas de pred_df\n",
    "for index, row in pred_df.iterrows():\n",
    "    key = (row['cat1'], row['cat2'], row['cat3'], row['brand'], row['product_id'])\n",
    "    \n",
    "    # Buscar el ratio correspondiente en ratio_dict utilizando la clave correcta\n",
    "    if key in ratio_dict:\n",
    "        ratio = ratio_dict[key]\n",
    "        # Calcular la predicción ajustada\n",
    "        prediccion_ajustada = row['prediccion'] * ratio\n",
    "        predictions_adjusted.append(prediccion_ajustada)\n",
    "    else:\n",
    "        predictions_adjusted.append(row['prediccion'])  # Mantener la predicción original si no hay ratio definido\n",
    "\n",
    "# Agregar las predicciones ajustadas al DataFrame pred_df\n",
    "pred_df['prediccion_ajustada'] = predictions_adjusted\n",
    "\n",
    "# Mostrar el DataFrame con las predicciones ajustadas\n",
    "print(pred_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     product_id  prediccion_ajustada\n",
      "0         20001          4254.694915\n",
      "1         20002          4301.131234\n",
      "2         20003          3624.426756\n",
      "3         20004          3624.426756\n",
      "4         20005          3624.426756\n",
      "..          ...                  ...\n",
      "775       21263           383.534721\n",
      "776       21265          1085.767240\n",
      "777       21266          1085.767240\n",
      "778       21267           228.564031\n",
      "779       21276           228.564031\n",
      "\n",
      "[780 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Sumarizar las predicciones ajustadas por product_id\n",
    "summarized_predictions = pred_df.groupby('product_id')['prediccion_ajustada'].sum().reset_index()\n",
    "\n",
    "# Mostrar el DataFrame con las predicciones sumarizadas\n",
    "print(summarized_predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar las predicciones finales en un archivo CSV\n",
    "summarized_predictions.to_csv(\"C:/Users/Usuario/desktop/vero2/modelodtw2000.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
